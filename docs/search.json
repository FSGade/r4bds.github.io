[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R for Bio Data Science",
    "section": "",
    "text": "A tidy approach to wrangling, exploring, visualising and communicating bio data with an emphasis on doing collaborative and reproducible bioinformatics projects \nLeon Eyrich Jessen & the TA team\n\nWelcome to R for Bio Data Science\nSo, you signed up for the 22100/22160 bioinformatics study line course - Congratulations! That was your first step towards getting a set of bio data science skills, which will serve you through your future career regardless of your path!\nInspirational quotes can be cliche, however this one hits the nail on the head:\n\n“Think about the readability of your code. Every project your work on is fundamentally collaborative. Even if you are not working with any other person, you are always working with future you and you really do not want to be in a situation where future you has no idea what past you was thinking, because past you will not respond to any emails!” Hadley Wickham\n\nBio Data Science in intrinsically collaborative (even if it’s just you working) and intrinsically interdisciplinary, so collaborative-, reproducibility- and communication- skills are key. In this course, you will learn how to do modern project oriented collaborative bio data science in tidyverse R - Welcome!"
  },
  {
    "objectID": "prologue.html",
    "href": "prologue.html",
    "title": "Prologue",
    "section": "",
    "text": "The course is designed as a semi-flipped classroom, with an emphasis on active learning. This means that during the 4h classes, the first hour will be dedicated to reviewing key points from last week and then a brief introduction to the topic of the day followed by a break. Hereafter, the students will work hands-on in groups on computational exercises using cloud computing infrastructure. The exercises will rely on relevant bioinformatics data from publicly available databases and gradually build the students toolbox with an emphasis on collaborative project work. This part will take up the first 9 labs. Each lab is defined by a set of specified learning objectives, it is essential that students continuously make sure, that they are on track with these LOs.\nThe fist hour of the 10th lab is dedicated to introducing the project part of the course and the subsequent 3h are dedicated to a mini symposium on “Application of R for Bio Data Science in Industry”. Here students will get a change to get insights into how the course topics are implemented in industry and get a glimpse into what options are available upon completing their education. This hybrid event typically attracts ~250 participants and have featured talks from major national and international Pharma/biotech companies, such as: Novo Nordisk, Lundbeck, Chr. Hansen, Bristol Meyer Squibb, a.o.\nIn the project part of the course, students will form groups of 4-5 students based on common interests. Hereafter, the students will seek out and select a data set, which will form the foundation for the project work. In the project work, the students will go through the entire data science cycle and produce the code base for a complete bioinformatics project. This entails a complete synthesis of all components of the exercise labs and supports the collaborative aspect. The groups must then condense the project into a presentation, thereby addressing communicative competencies as an essential part of being a modern bio data scientist."
  },
  {
    "objectID": "getting_started.html",
    "href": "getting_started.html",
    "title": "Getting Started",
    "section": "",
    "text": "This section contain essential information for getting up and running for the classes"
  },
  {
    "objectID": "getting_started.html#when-and-where",
    "href": "getting_started.html#when-and-where",
    "title": "Getting Started",
    "section": "When and Where",
    "text": "When and Where\nTeaching sessions will be E3A, Tuesday mornings 8 - 12 in building 358, room 060a (exercises: Also room 045) and the general schedule will be:\n\n08.00 - 08.30 Recap of key points from last weeks exercises\n08.30 - 09.00 Introduction to theme of the day\n09.00 - 12.00 Exercises"
  },
  {
    "objectID": "getting_started.html#logging-onto-cloud-server",
    "href": "getting_started.html#logging-onto-cloud-server",
    "title": "Getting Started",
    "section": "Logging onto Cloud Server",
    "text": "Logging onto Cloud Server\nFirst, make sure you have a working DTU account, either as a student id or employee initials (e.g. PhD-students or postdocs). In this course we will be using a cloud server infrastructure to perform our work. Click below to access the cloud server:\n\nR for Bio Data Science Cloud Server\n\nNote, that there is a 24h time out on the sessions, meaning that if you logon and forget to sign out, your session will be terminated after 24h."
  },
  {
    "objectID": "getting_started.html#setting-up-a-github-account",
    "href": "getting_started.html#setting-up-a-github-account",
    "title": "Getting Started",
    "section": "Setting up a GitHub account",
    "text": "Setting up a GitHub account\nPrior to class, please go to GitHub and setup and account, shouldn’t take long. During the registration process you can set up a student account, which will give you additional benefits, including GitHub Pro. In order to get it, you need to use your DTU email when setting account and select Apply for your GitHub student benefits when asked during the registration process. You’ll be then asked to apply for GitHub Student Developer Pack, which will require uploading your student id photo. The process of confirming a student account may take up to a few days (however, it can be almost instantaneous). In the meantime you can already use your free account. Free account should be sufficient for this class, so if you don’t want to set up a school account, you don’t need to. Please state your GitHub username in this google sheet."
  },
  {
    "objectID": "getting_started.html#class-communication",
    "href": "getting_started.html#class-communication",
    "title": "Getting Started",
    "section": "Class Communication",
    "text": "Class Communication\nThis course has grown from ~35 students in 2020 to ~150 students in 2023, therefore this term we will be using Piazza for class discussion. The system is highly catered to getting you help fast and efficiently from classmates, the TAs, and myself. Rather than emailing questions to the teaching staff, I encourage you to post your questions on Piazza. If you have any problems or feedback for the developers, email team@piazza.com.\nFind our class signup link at: https://piazza.com/dtu.dk/fall2023/22100 and see the Intro for Students video."
  },
  {
    "objectID": "getting_started.html#group-formation",
    "href": "getting_started.html#group-formation",
    "title": "Getting Started",
    "section": "Group Formation",
    "text": "Group Formation\nThe backbone of this course is modern collaborative data science and as such “active participation in the group work … [is an] indispensable prerequisites for exam participation” as stated in the course base. Furthermore, It is important that course participants prioritise to be present during classes as the course design is based on student-student interaction in an active learning environment.\nTherefore, students will work in groups of 4-5 students. Group formation sheet can be found here"
  },
  {
    "objectID": "lab00.html",
    "href": "lab00.html",
    "title": "Course Labs",
    "section": "",
    "text": "This chapter provides a complete overview of the course curriculum"
  },
  {
    "objectID": "lab01.html",
    "href": "lab01.html",
    "title": "Lab 1: Course Intro & the Very Basics",
    "section": "",
    "text": "Base"
  },
  {
    "objectID": "lab01.html#schedule",
    "href": "lab01.html#schedule",
    "title": "Lab 1: Course Intro & the Very Basics",
    "section": "Schedule",
    "text": "Schedule\n\n08.00 - 08.15: Arrival and 5 min. pre-course anonymous survey: Click here to answer\n08.15 - 08.45: Lecture: Course Introduction\n08.45 - 09.00: Break\n09.00 - 11.15: Exercises\n11.15 - 11.30: Break\n11.30 - 12.00: Lecture: Reproducibility in Modern Bio Data Science"
  },
  {
    "objectID": "lab01.html#learning-materials",
    "href": "lab01.html#learning-materials",
    "title": "Lab 1: Course Intro & the Very Basics",
    "section": "Learning Materials",
    "text": "Learning Materials\nPlease prepare the following materials:\n\nRead the full course description here: 22100 / 22160\nAnswer this brief anonymous R for Bio Data Science Pre-course Questionnaire\nRead course site sections: Welcome to R for Bio Data Science, Prologue and Getting Started and perform any small tasks mentioned\nR4DS2e Book: Welcome, Preface to the second edition, Chapter 1, Chapter 3, Chapter 29 (Don’t do the exercises)\nVideo: RStudio for the Total Beginner\nWeb: Read the detailed course description\nPaper: Ten Simple Rules for Effective Statistical Practice\nPaper: A Quick Guide to Organizing Computational Biology Projects"
  },
  {
    "objectID": "lab01.html#learning-objectives",
    "href": "lab01.html#learning-objectives",
    "title": "Lab 1: Course Intro & the Very Basics",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nA student who has met the objectives of the session will be able to:\n\nMaster the very basics of R\nNavigate the RStudio IDE\nCreate, edit and run a basic Quarto document\nExplain why reproducible data analysis is important, as well as identify relevant challenges and explain replicability versus reproducibility\nDescribe the components of a reproducible data analysis"
  },
  {
    "objectID": "lab01.html#sec-exercises",
    "href": "lab01.html#sec-exercises",
    "title": "Lab 1: Course Intro & the Very Basics",
    "section": "Exercises",
    "text": "Exercises\nToday, we will focused on getting you started and up and running with the first elements of the course, namely the RStudio IDE (Integrated Developer Environment) and Quarto. If the relationship between R and RStudio is unclear, think of it this way: Consider a car, in that case, R would be the engine and RStudio would be the rest of the car. Neither is particularly useful, but together they form a functioning unit. Before you continue, make sure you in fact did watch the “RStudio for the Total Beginner” video (See the Learning Materials for todays session).\n\nCloud server and the RStudio IDE\nGo to the R for Bio Data Science Cloud Server and follow the login procedure. Upon login, you will see this:\n\n\n\n\n\nThis is the RStudio IDE. It allows you to consolidate all features needed to develop R code for analysis. Now, click Tools \\(\\rightarrow\\) Global Options... \\(\\rightarrow\\) Pane Layout and you will see this:\n\n\n\n\n\nThis outlines the four panes you have in your RStudio IDE and allow you rearrange them as you please. Now, re-arrange them, so that they look like this:\n\n\n\n\n\nClick Apply \\(\\rightarrow\\) OK and you should see this:\n\n\n\n\n\n\n\nFirst steps\n\nThe Console\nNow, in the console, as you saw in the video, you can type commands like:\n\n2+2\n1:100\n3*3\nsample(1:9)\nX <- matrix(sample(1:9), nrow = 3, ncol = 3)\nX\nsum(X)\nmean(X)\n?sum\nsum\nnucleotides <- c(\"a\", \"c\", \"g\", \"t\")\nnucleotides\nsample(nucleotides, size = 100, replace = TRUE)\ntable(sample(nucleotides, size = 100, replace = TRUE))\npaste0(sample(nucleotides, size = 100, replace = TRUE), collapse = \"\")\nreplicate(n = 10, expr = paste0(sample(nucleotides, size = 100, replace = TRUE), collapse = \"\"))\ndf <- data.frame(id = paste0(\"seq\", 1:10), seq = replicate(n = 10, expr = paste0(sample(nucleotides, size = 100, replace = TRUE), collapse = \"\")))\ndf\nstr(df)\nls()\n\nTake some time and play around with these commands and other things you can come up with. Use the ?function to get help on what that function does. Be sure to discuss what you observe in the console. Do not worry too much on the details for now, we are just getting started. But as you hopefully can see, R is very flexible and basically the message is: “If you can think it, you can build it in R”.\n\nGo to Chapter 3 in R4DS2e and do the exercises\n\n\n\nThe Terminal\nNotice how in the console pane, you also get a Terminal, click and enter:\n\nls\nmkdir tmp\ntouch tmp/test.txt\nls tmp\nrm tmp/test.txt\nrmdir tmp\nls\necho $SHELL\n\nBasically, here you have access to a full terminal, which can prove immensely useful! Note, you may or may not be familiar with the concept of a terminal. Simply think of it as a way to interact with the computer using text command, rather than clicking on icons etc. Click back to the console.\n\n\nThe Source\nThe source is where you will write scripts. A script is a series of commands to be executed sequentially, i.e. first line 1, then line 2 and so on. Right now, you should have a open script called Untitled1. If not, you can create a new script by clicking white paper with a round green plus sign in the upper left corner.\nTaking inspiration from the examples above, try to write a series of commands and include a print()-statement at the very end. Click File \\(\\rightarrow\\) Save and save the file as e.g. my_first_script.R. Now, go to the console and type in the command source(\"my_first_script.R\"). Congratulations! You have now written your very first reproducible R-program!\n\n\n\nThe Whole Shebang\nEnough playing around, let us embark on our modern Bio Data Science in R journey.\n\nIn the Files pane, click New Folder and create a folder called projects\nIn the upper right corner, click where it says Project: (None) and then click New Project...\nClick New Directory and then New Project\nIn the Directory name:, enter e.g. r_for_bio_data_science\nClick the Browse... button and select your newly created projects directory and then click Choose\nClick Create Project and wait a bit for it to get created\n\n\nOn Working in Projects\nProjects allow you to create fully transferable bio data science projects, meaning that the root of the project will be where the .Rproj file is located. You can confirm this by entering getwd() in the console. This means that under no circumstance should ever not work in a project nor should ever use absolute paths. Every single path you state in your project must be relative to the project root.\nBut why? Imagine you have create a project, where you have indeed used absolute paths. Now you want to share that project with a colleague. Said colleague gets your project and tests the reproducibility by running the project end-to-end. But it completely fails because you have hardcoded your paths to be absolute, meaning that all files and project ressources locations points to locations on your laptop.\nProjects are a must and allows you to create reproducible encapsulated bio data science projects. Note, the concept of reproducibility is absolute central to this course and must be considered in all aspect of the life cycle of a project!\n\n\nQuarto\nWhile .R-scripts are a perfectly, there is another Skywalker:\n\nIn the upper left corner, again, click the white paper with the round green plus, but this time select Quarto Document\nEnter a Title:, e.g. “Lab 1 Exercises” and enter your name below in the box Author:\nClick Create\nImportant: Save your Quarto document! Click File \\(\\rightarrow\\) Save and name it e.g. lab_01_exercises.qmd\nMinimise the Environment-pane\n\nYou should now see something like this:\n\n\n\n\n\nTry clicking the Render button just above the quarto-document. This will create the HTML5 output file. Note! You may get a Connection Refused message. If so, don’t worry, just close the page to return to the cloud server and find the generated .html file, left-click and select View in Web Browser.\nIf you have previously worked with Rmarkdown, then many features of Quarto will be familiar. Think of Quarto as the complete rethink of Rmarkdown, i.e. based on all the experience gained, what would the optimal way of constructing an open-source scientific and technical publishing system?\nPerhaps you have previously encountered Jupyter notebooks, Quarto is similar. The basic idea is to have one document covering the entire project cycle.\nProceed R for Data Science (2e), chapter 29 and do the exercises.\n\n\n\nBio Data Science with a Virtual AI Assistant\nI am pretty sure you all know of chatGPT by now, so let us address the elephant in the room!\n\nGetting started\n\nGo to the ChatGPT site\nCreate a user and login\n\n\nLet us get acquainted\nNow, at the bottom it says “Send a message”, let us ask 3 simple question and see if we can find out what is what. Type the following questions in the prompt and read the answers:\n\nExplain in simple terms what you are\nExplain in simple terms how you work\nExplain in simple terms how you can be used to generate value as a virtual AI assistant, when doing Bio Data Science for R\n\n\n\nMoving onto R\nIn the upper left corner, it says + New chat, click it to start a new session.\nAgain, type the following questions in the prompt and read the answers:\n\nR\nWhat is R?\nGive a few simple examples\n\nIf you do get some code examples, try to copy/paste into the console in RStudio and see if they run\n\n\nPrompt Engineering\nStart a new chat and enter:\n\nGive a few simple examples\n\nCompare the response with the one from before, is it the same or different and why so?\nDiscuss in your group what is “Prompt Engineering” and how does it relate to the above few tests you did? (Bonus info: Prompt engineer is already a job and people are making money off of selling prompts)\n\n\n…a bit more\nStart a new chat and enter:\n\nTell me about DNA\n\nCheck if it gives you correct information?\nNow, write:\n\nGive a few fun examples on how to get started with the R programming language using DNA\n\nCopy/paste the code into the Console, do the examples all run?\n\nEarlier you were told to play around with some code snippets. Perhaps you didn’t fully catch what was going on? If so, try to type in e.g.:\n\nI'm new to R, please explain in simple terms, what the following code does:\n\n\"\nnucleotides <- c(\"a\", \"c\", \"g\", \"t\")\nreplicate(n = 10, expr = paste0(sample(nucleotides, size = 100, replace = TRUE), collapse = \"\"))\n\"\n\n\nSummary\nWhile chatGPT can be a powerful tool for code productivity, it comes with a major caveat: When it fails, it fails with confidence. This means that it will be equally confident whether it is right or wrong! The optimal yield is when you are working on a problem with a tool, where you already have a good knowledge of the problem and the tool. Here, you can see if you are heading in the right direction or if you’re being send on a wild goose chase.\nTherefore, in the beginning of the course, for your own sake, please refrain from using chatGPT!\nInstead solve the exercises based on the materials you have prepared, talk to you group members and discuss the challenges and check your understanding. Then later on, when you have gained initial experience, we can explore using chatGPT to augment your bio data science workflow to enhance productivity"
  },
  {
    "objectID": "lab02.html",
    "href": "lab02.html",
    "title": "Lab 2: Data Visualisation I",
    "section": "",
    "text": "ggplot2"
  },
  {
    "objectID": "lab02.html#schedule",
    "href": "lab02.html#schedule",
    "title": "Lab 2: Data Visualisation I",
    "section": "Schedule",
    "text": "Schedule\n\n08.00 - 08.15: Pre-course Survey Walk-through\n08.15 - 08.30: Recap: RStudio Cloud, RStudio and R - The Very Basics (Live session)\n08.30 - 09.00: Lecture\n09.00 - 09.15: Break\n09.00 - 12.00: Exercises"
  },
  {
    "objectID": "lab02.html#learning-materials",
    "href": "lab02.html#learning-materials",
    "title": "Lab 2: Data Visualisation I",
    "section": "Learning Materials",
    "text": "Learning Materials\nPlease prepare the following materials:\n\nBook: R4DS2e Chapter 2 Data Visualisation\nPaper: “A Layered Grammar of Graphics” by Hadley Wickham\nVideo: The best stats you’ve ever seen\nVideo: The SDGs aren’t the same old same old\nVideo: EMBL Keynote Lecture - “Data visualization and data science” by Hadley Wickham"
  },
  {
    "objectID": "lab02.html#learning-objectives",
    "href": "lab02.html#learning-objectives",
    "title": "Lab 2: Data Visualisation I",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nA student who has met the objectives of the session will be able to:\n\nExplains the basic theory of data visualisation\nDecipher the components of a simple ggplot\nUse ggplot to do basic data visualisation"
  },
  {
    "objectID": "lab02.html#sec-exercises",
    "href": "lab02.html#sec-exercises",
    "title": "Lab 2: Data Visualisation I",
    "section": "Exercises",
    "text": "Exercises"
  },
  {
    "objectID": "lab02.html#prelude",
    "href": "lab02.html#prelude",
    "title": "Lab 2: Data Visualisation I",
    "section": "Prelude",
    "text": "Prelude\nDiscuss these 4 visualisations with your group members\n\nWhat is problematic?\nWhat could be done to rectify?\n\n\n\n\nClick here for visualisation 1\n\n\nNote, AMR = Antimicrobial Resistance\n\n\n\n\n\nClick here for visualisation 2\n\n\n\n\n\n\n\nClick here for visualisation 3\n\n\n\n\n\n\n\nClick here for visualisation 4"
  },
  {
    "objectID": "lab02.html#getting-started",
    "href": "lab02.html#getting-started",
    "title": "Lab 2: Data Visualisation I",
    "section": "Getting Started",
    "text": "Getting Started\nFirst of all, make sure to read every line in these exercises carefully!\nIf you get stuck with Quarto, revisit R4DS2e, chapter 29 or take a look at the Comprehensive guide to using Quarto\n\nGo to the R for Bio Data Science RStudio Cloud Server session from last time and login and choose the project you created.\nCreate a new Quarto Document for todays exercises, e.g. lab02_exercises.qmd\n\nRecall the layout of the IDE (Integrated Development Environment)\n\n\n\n\n\nThen, before we start, we need to fetch some data to work on.\n\nSee if you can figure out how to create a new folder called “data”, make sure to place it the same place as your my_project_name.Rproj file.\n\nThen, without further ado, run each of the following lines separately in your console:\n\ntarget_url <- \"https://github.com/ramhiser/datamicroarray/raw/master/data/gravier.RData\"\noutput_file <- \"data/gravier.RData\"\ncurl::curl_download(url = target_url,\n                    destfile = output_file)\n\n\nUsing the files pane, check the folder you created to see if you managed to retrieve the file.\n\nRecall the syntax for a new code chunk:\n  ```{r}\n  #| echo: true\n  #| eval: true\n  # Here goes the code... Note how this part does not get executed because of the initial hashtag, this is called a code-comment\n  1 + 1\n  my_vector <- c(1, 2, 3)\n  my_mean <- mean(my_vector)\n  print(my_mean)\n  ```\nIMPORTANT! You are mixing code and text in a Quarto Document! Anything within a “chunk” as defined above will be evaluated as code, whereas anything outside the chunks is markdown. You can use shortcuts to insert new code chunks:\n\nMac: CMD + OPTION + i\nWindows: CTRL + ALT + i\n\nNote, this might not work, depending on your browser. In that case you can insert a new code chunk using  or You can change the shortcuts via “Tools” > “Modify Keyboard shortcuts…” > Filter for “Insert Chunk” and then choose the desired shortcut. E.g. change the shortcut for code chunks to Shift+Cmd+i or similar.\n\nAdd a new code chunk and use the load()-function to load the data you retrieved.\n\n\n\n\nClick here for a hint\n\n\nRemember, you can use ?load to get help on how the function works and remember your project root path is defined by the location of your .Rproj file, i.e. the path. A path is simply where R can find your file, e.g. /home/projects/r_for_bio_data_science/ or similar depending on your particular setup.\n\nNow, in the console, run the ls()-command and confirm, that you did indeed load the gravier data.\n\nRead the information about the gravier-data here\n\nNow, in your Quarto Document, add a new code chunk like so\n\nlibrary(\"tidyverse\")\n\nThis will load our data science toolbox, including ggplot."
  },
  {
    "objectID": "lab02.html#create-data",
    "href": "lab02.html#create-data",
    "title": "Lab 2: Data Visualisation I",
    "section": "Create data",
    "text": "Create data\nBefore we can visualise the data, we need to wrangle it a bit. Nevermind the details here, we will get to that later. Just create a new chunk, copy/paste the below code and run it:\n\nset.seed(676571)\ncancer_data=mutate(as_tibble(pluck(gravier,\"x\")),y=pluck(gravier,\"y\"),pt_id=1:length(pluck(gravier, \"y\")),age=round(rnorm(length(pluck(gravier,\"y\")),mean=55,sd=10),1))\ncancer_data=rename(cancer_data,event_label=y)\ncancer_data$age_group=cut(cancer_data$age,breaks=seq(10,100,by=10))\ncancer_data=relocate(cancer_data,c(pt_id,age,age_group,pt_id,event_label))\n\nNow we have the data set as an tibble, which is an augmented data frame (we will also get to that later):\n\ncancer_data\n\n# A tibble: 168 × 2,909\n   pt_id   age age_group event_label    g2E09    g7F07    g1A01   g3C09    g3H08\n   <int> <dbl> <fct>     <fct>          <dbl>    <dbl>    <dbl>   <dbl>    <dbl>\n 1     1  34.2 (30,40]   good        -0.00144 -0.00144 -0.0831  -0.0475  1.58e-2\n 2     2  47   (40,50]   good        -0.0604   0.0129  -0.00144  0.0104  3.16e-2\n 3     3  60.3 (60,70]   good         0.0398   0.0524  -0.0786   0.0635 -3.95e-2\n 4     4  57.8 (50,60]   good         0.0101   0.0314  -0.0218   0.0215  8.68e-2\n 5     5  54.9 (50,60]   good         0.0496   0.0201   0.0370   0.0311  2.07e-2\n 6     6  58.8 (50,60]   good        -0.0664   0.0468   0.00720 -0.370   2.88e-3\n 7     7  52.9 (50,60]   good        -0.00289 -0.0816  -0.0291  -0.0249 -1.74e-2\n 8     8  74.5 (70,80]   good        -0.198   -0.0499  -0.0634  -0.0298  3.00e-2\n 9     9  47.6 (40,50]   good         0.00288  0.0201   0.0272   0.0174 -7.89e-5\n10    10  55.8 (50,60]   good        -0.0574  -0.0574  -0.0831  -0.0897 -1.01e-1\n# ℹ 158 more rows\n# ℹ 2,900 more variables: g1A08 <dbl>, g1B01 <dbl>, g1int1 <dbl>, g1E11 <dbl>,\n#   g8G02 <dbl>, g1H04 <dbl>, g1C01 <dbl>, g1F11 <dbl>, g3F05 <dbl>,\n#   g3B09 <dbl>, g1int2 <dbl>, g2C01 <dbl>, g1A05 <dbl>, g1E01 <dbl>,\n#   g1B05 <dbl>, g3C05 <dbl>, g3A07 <dbl>, g1F01 <dbl>, g2D01 <dbl>,\n#   g1int3 <dbl>, g1int4 <dbl>, g1D05 <dbl>, g1E05 <dbl>, g1G05 <dbl>,\n#   g1C05 <dbl>, g1G11 <dbl>, g2D08 <dbl>, g2E06 <dbl>, g3H09 <dbl>, …\n\n\n\nQ1: What is this data?\n\n\n\n\nClick here for a hint\n\n\nWhere did the data come from?\n\n\nQ2: How many rows and columns are there in the data set in total?\n\n\n\n\nClick here for a hint\n\n\nDo you think you are the first person in the world to try to find out how many rows and columns are in a data set in R?\n\n\nQ3: Which are the variables and which are the observations in relation to rows and columns?"
  },
  {
    "objectID": "lab02.html#ggplot---the-very-basics",
    "href": "lab02.html#ggplot---the-very-basics",
    "title": "Lab 2: Data Visualisation I",
    "section": "ggplot - The Very Basics",
    "text": "ggplot - The Very Basics\n\nGeneral Syntax\nThe general syntax for a basic ggplot is:\n\nggplot(data = my_data,\n       mapping = aes(x = variable_1_name,\n                     y = variable_2_name)) +\n  geom_something() +\n  labs()\n\nNote the + for adding layers to the plot\n\nggplot the plotting function\nmy_data the data you want to plot\naes() the mappings of your data to the plot\nx data for the x-axis\ny data for the y-axis\ngeom_something() the representation of your data\nlabs() the x-/y-labels, title, etc.\n\nNow:\n\nReivisit this illustration and discuss in your group what is what:\n\n\nA very handy ggplot cheat-sheet can be found here\n\n\nBasic Plots\nRemember to write notes in your rmarkdown document. You will likely revisit these basic plots in future exercises.\nPrimer: Plotting 2 x 20 random normally distributed numbers, can be done like so:\n\nggplot(data = tibble(x = rnorm(20),\n                     y = rnorm(20)),\n       mapping = aes(x = x,\n                     y = y)) +\n  geom_point()\n\n\n\n\nUsing this small primer, the materials you read for today and the cancer_data you created, in separate code-chunks, create a:\n\nT1: scatterplot of one variable against another\nT2: linegraph of one variable against another\nT3: boxplot of one variable (Hint: Set x = \"my_gene\" in aes())\nT4: histogram of one variable\nT5: densitogram of one variable\n\nRemember to write notes to yourself, so you know what you did and if there is something in particular you want to remember.\n\nQ4: Do all geoms require both x and y?\n\n\n\nExtending Basic Plots\n\nT6: Pick your favourite gene and create a boxplot of expression levels stratified on the variable event_label\nT7: Like T6, but with densitograms GROUP ASSIGNMENT\nT8: Pick your favourite gene and create a boxplot of expression levels stratified on the variable age_group\n\nThen, add stratification on event_label\nThen, add transparency to the boxes\nThen, add some labels\n\nT9: Pick your favourite gene and create a scatter-plot of expression levels versus age\n\nThen, add stratification on event_label\nThen, add a smoothing line\nThen, add some labels\n\nT10: Pick your favourite two genes and create a scatter-plot of their expression levels\n\nThen, add stratification on event_label\nThen, add a smoothing line\nThen, show split into seperate panes based on the variable age_group\nThen, add some labels\nChange the event_label title of the legend\n\nT11: Recreate the following plot\n\n\n\n\n\n\n\nQ5: Using your biological knowledge, what is your interpretation of the plot?\nT12: Recreate the following plot\n\n\n\n\n\n\n\nQ6: Using your biological knowledge, what is your interpretation of the plot?\nT13: If you arrive here and there is still time left for the exercises, you are probably already familiar with ggplot - Use what time is left to challenge yourself to further explore the cancer_data and create some nice data visualisations - Show me what you come up with!"
  },
  {
    "objectID": "lab02.html#further-ressources-for-data-visualisation",
    "href": "lab02.html#further-ressources-for-data-visualisation",
    "title": "Lab 2: Data Visualisation I",
    "section": "Further ressources for data visualisation",
    "text": "Further ressources for data visualisation\n\nA very handy ggplot cheat-sheet can be found here\nSo which plot to choose? Check this handy guide\nExplore ways of plotting here"
  },
  {
    "objectID": "lab03.html",
    "href": "lab03.html",
    "title": "Lab 3: Data Visualisation II",
    "section": "",
    "text": "ggplot2\npatchwork\nscales\nggridges"
  },
  {
    "objectID": "lab03.html#schedule",
    "href": "lab03.html#schedule",
    "title": "Lab 3: Data Visualisation II",
    "section": "Schedule",
    "text": "Schedule\n\n08.00 - 08.45: Recap of Lab 2 and Lecture\n08.45 - 09.00: Break\n09.00 - 12.00: Exercises"
  },
  {
    "objectID": "lab03.html#learning-materials",
    "href": "lab03.html#learning-materials",
    "title": "Lab 3: Data Visualisation II",
    "section": "Learning Materials",
    "text": "Learning Materials\nPlease prepare the following materials\n\nBook: “Visualize”, chapters 10, 11 and 12\nVideo: William Chase | The Glamour of Graphics | RStudio (2020)\nWeb: Patchwork - Getting started\nWeb: Scales - Getting started"
  },
  {
    "objectID": "lab03.html#learning-objectives",
    "href": "lab03.html#learning-objectives",
    "title": "Lab 3: Data Visualisation II",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nA student who has met the objectives of the session will be able to:\n\nUse more advanced ggplot features\nCustomise the data visualisation\nCombine multiple plots into one pane\nLook at a more advanced ggplot and decipher the components used"
  },
  {
    "objectID": "lab03.html#sec-exercises",
    "href": "lab03.html#sec-exercises",
    "title": "Lab 3: Data Visualisation II",
    "section": "Exercises",
    "text": "Exercises\n\n\n\nRead the steps of this exercises carefully, while completing them\n\nIntroduction\nSome authors are kind enough to supply the data they used for their paper, e.g.:\n\n“Assessment of the influence of intrinsic environmental and geographical factors on the bacterial ecology of pit latrines”\n\nWhere the supporting data can be found here:\n\nhttp://userweb.eng.gla.ac.uk/umer.ijaz/bioinformatics/ecological.html\n\n\n\nGetting Started\nAgain, go to the R for Bio Data Science RStudio Cloud Server session from last time and login and choose the project you created\n\nCreate a new Quarto Document for todays exercises, e.g. lab03_exercises.qmd\nNB! The Quarto document MUST be placed together with your .Rproj file (defining, the project root - look in your Files-tab) and also there, the data-folder should be placed!\nREMEMBER paths are important! Also, R is case-sensitive, i.e. “data” is not the same as “Data”\n\nSee Paths and Projects\n\n\nGetting the data\nAdd a new code chunk and add the following code (Never mind the details, we will get back to this), remember you can use headers to nicely section your quarto Document.\n\nbase_url <- \"http://userweb.eng.gla.ac.uk/umer.ijaz/bioinformatics/ecological/\"\n\nSPE <- read_csv(file = str_c(base_url, \"SPE_pitlatrine.csv\"))\nwrite_csv(x = SPE,\n          file = \"data/SPE_pitlatrine.csv\")\n\nENV <- read_csv(file = str_c(base_url, \"ENV_pitlatrine.csv\"))\nwrite_csv(x = ENV,\n          file = \"data/ENV_pitlatrine.csv\")\n\nAdd the chunk settings #| echo: true and #| eval: true, then run the block and change the latter to #| eval: false.\n\nDiscuss in your group, what this means and why we do it\n\n\n\n\nClick here for hint\n\n\nFrom where do we retrieve the data and to where do we write it and what happens if we run the chunk more than one time?\n\n\n\nWrangling the data\n\nWhat is data wrangling?\n\nBefore we continue with plotting, we want to unify the data, so here again you will run some code, where the details are not important right now.\nBut… Make sure, that you have run library(\"tidyverse\") somewhere in your Quarto document - Perhaps under an initial header saying “Load Libraries” or similar?\n\nSPE |> \n  pivot_longer(cols = -Taxa,\n               names_to = \"Samples\",\n               values_to = \"OTU_Count\")  |> \n  full_join(ENV, by = \"Samples\") |> \n  mutate(site = case_when(str_detect(Samples, \"^T\") ~ \"Tanzania\",\n                          str_detect(Samples, \"^V\") ~ \"Vietnam\")) |>  \n  write_tsv(file = \"data/SPE_ENV.tsv\")\n\nChange the chunk settings as before"
  },
  {
    "objectID": "lab03.html#data-visualisation-ii",
    "href": "lab03.html#data-visualisation-ii",
    "title": "Lab 3: Data Visualisation II",
    "section": "Data Visualisation II",
    "text": "Data Visualisation II\n\nRead the data\n\nSPE_ENV <- read_tsv(file = \"data/SPE_ENV.tsv\")\nSPE_ENV\n\n# A tibble: 4,212 × 15\n   Taxa   Samples OTU_Count    pH  Temp    TS    VS   VFA  CODt  CODs perCODsbyt\n   <chr>  <chr>       <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>      <dbl>\n 1 Acido… T_2_1           0  7.82  25.1  14.5 71.3   71     874   311         36\n 2 Acido… T_2_10          0  9.08  24.2  37.8 31.5    2     102     9          9\n 3 Acido… T_2_12          0  8.84  25.1  71.1  5.94   1      35     4         10\n 4 Acido… T_2_2           0  6.49  29.6  13.9 64.9    3.7   389   180         46\n 5 Acido… T_2_3           0  6.46  27.9  29.4 26.8   27.5   161    35         22\n 6 Acido… T_2_6           0  7.69  28.7  65.5  7.03   1.5    57     3          6\n 7 Acido… T_2_7           0  7.48  29.8  36.0 34.1    1.1   107     9          8\n 8 Acido… T_2_9           0  7.6   25    46.9 19.6    1.1    62     8         13\n 9 Acido… T_3_2           0  7.55  28.8  12.6 51.8   30.9   384    57         15\n10 Acido… T_3_3           0  7.68  28.9  14.6 48.1   24.2   372    57         15\n# ℹ 4,202 more rows\n# ℹ 4 more variables: NH4 <dbl>, Prot <dbl>, Carbo <dbl>, site <chr>\n\n\n\n\nIMPORTANT INSTRUCTIONS - READ!\nFor these exercises, you will have to identify what you see in the plot!\nFor each plot, complete the following steps\n\nLook at this overview of the components of a ggplot (see below)\nLook at the plot you are to recreate and discuss in the group:\n\nWhat is the data? Take a look at it and understand what is in the data\nWhat are the mappings? I.e. what variables are on the x-/y-axis?\nAre there any colour-/fill-mappings?\nWhat are the geoms used?\nAre there any modifications to theme?\n\n\n\n\n\nClick here for hint\n\n\n\nConsult the Data visualization with ggplot2 cheatsheet\nCheck which options you have available\nConsult the chapters in the book you read, see preparation materials for labs 2 and 3\n\n\n\n\n\nTASKS\n\nTask 1 - Recreate the following plot\nDiscuss in your group, which ggplot elements can you identify?\n\n\n\n\n\n\n\nTask 2 - Recreate the following plot\nDiscuss in your group, which ggplot elements can you identify?\n\n\n\n\n\n\n\nTask 3 - Recreate the following plot\nDiscuss in your group, which ggplot elements can you identify?\n\n\n\n\n\n\n\nTask 4 - Recreate the following plot\nDiscuss in your group, which ggplot elements can you identify?\n\n\n\n\n\n\n\nTask 5 - Recreate the following plots\nDiscuss in your group, which ggplot elements can you identify?\n\n\n\n\n\n\n\n\n\n\n\n\n\nClick here for hint\n\n\nSame data, but a transformation happened, changing the representation of the data. Look carefully at the axes.\n\n\n\nTask 6 - Recreate the following plot\nDiscuss in your group, which ggplot elements can you identify?\n\n\n\n\n\n\n\n\nClick here for hint\n\n\nSee if you can find something online on geom_smooth()\n\n\n\nTask 7 - Recreate the following plot\nDiscuss in your group, which ggplot elements can you identify?\n\n\n\n\n\n\n\n\n\n\n\n\nClick here for hint\n\n\nThink about fill and then see if you can find something online on geom_tile(), scale_fill_gradient2 and how to ggplot rotate axis labels\n\n\n\nTask 8 - Recreate the following plot\nStart by running this code in a new chunk (ignore details for now)\n\ntargets <- c(\"Methanobacteria\", \"Clostridia\", \"Actinobacteria\",\n            \"Sphingobacteria\", \"Anaerolineae\")\nSPE_ENV_targets <- SPE_ENV |>\n  filter(Taxa %in% targets)\n\nand then use the created dataset SPE_ENV_targets to recreate this plot:\nDiscuss in your group, which ggplot elements can you identify?\n\n\n\n\n\n\n\n\nClick here for hint\n\n\nHere we need to use geom_density_ridges(), but which package contains this? Also we are using a colour scale called viridis, but how do we add this? Also, perhaps there are more themes we can use than just theme_classic()?\n\n\n\nTask 9 - GROUP ASSIGNMENT\nFor this assignment you and your group are to apply what you have learned in the two data visualisation labs. The task is to create a really nice plot using one of two datasets, the cancer_data or the SPE_ENV\nTry to play around with some custom colouring. There is a nice tool to aid in choosing colours for visualisations here\nBe sure to read the assignment instructions before submitting your solution."
  },
  {
    "objectID": "lab04.html",
    "href": "lab04.html",
    "title": "Lab 4: Data Wrangling I",
    "section": "",
    "text": "dplyr\nreadr\ntibble"
  },
  {
    "objectID": "lab04.html#schedule",
    "href": "lab04.html#schedule",
    "title": "Lab 4: Data Wrangling I",
    "section": "Schedule",
    "text": "Schedule\n\n08.00 - 08.15: Recap of Lab 3\n08.15 - 08.30: Assignment 2 walk-through\n08.30 - 09.00: Lecture\n09.00 - 09.15: Break\n09.00 - 12.00: Exercises"
  },
  {
    "objectID": "lab04.html#learning-materials",
    "href": "lab04.html#learning-materials",
    "title": "Lab 4: Data Wrangling I",
    "section": "Learning Materials",
    "text": "Learning Materials\nPlease prepare the following materials:\n\nR4DS2e book: Chapter 4, chapter 5, chapter 8, chapter 9\nWeb: What is data wrangling? Intro, Motivation, Outline, Setup – Pt. 1 Data Wrangling Introduction\nWeb: (NB! STOP at 7:45, i.e. skip tidyr) Tidy Data and tidyr – Pt 2 Intro to Data Wrangling with R and the Tidyverse\nWeb: Data Manipulation Tools: dplyr – Pt 3 Intro to the Grammar of Data Manipulation with R"
  },
  {
    "objectID": "lab04.html#learning-objectives",
    "href": "lab04.html#learning-objectives",
    "title": "Lab 4: Data Wrangling I",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nA student who has met the objectives of the session will be able to:\n\nUnderstand and apply the 6 basic dplyr verbs: filter(), arrange(), select(), mutate(), summarise() and group_by()\nConstruct and apply logical statements in context with dplyr pipelines\nUnderstand and apply the additional verbs count(), drop_na(), View()\nCombine dplyr verbs to form a data manipulation pipeline using the pipe |> operator\nDecipher the components and functions hereof in a dplyr pipeline"
  },
  {
    "objectID": "lab04.html#sec-exercises",
    "href": "lab04.html#sec-exercises",
    "title": "Lab 4: Data Wrangling I",
    "section": "Exercises",
    "text": "Exercises\n\n\n\nImportant: As we progress, avoid using black-box do-everything-with-one-command R-packages like e.g. ggpubr - I want you to learn the underlying technical bio data science! …and why is that? Because if you use these type of packages, you will be limited to their functionality, whereas if you truly understand ggplot - The sky is the limit! Basically, it the cliché that “If you give a man a fish, you feed him for a day. If you teach a man to fish, you feed him for a lifetime”\n\nGetting Started\nUse this link to go to the R for Bio Data Science RStudio Cloud Server\nFirst things first:\n\nCreate a new Quarto Document for todays exercises, e.g. lab04_exercises.qmd\n\nNote that: - The Quarto document MUST be placed together with your .Rproj file (defining, the project root - look in your Files-pane) and also there, the data-folder should be placed!\nUnderstanding how paths and projects work is important. In case this is no entirely clear, a new chapter has been added on Paths and Projects.\n\n\nBrief refresh of Quarto so far\nRecall the syntax for a new code chunk, where all your R code goes any text and notes must be outside the chunk tags:\n\n```{r}\n# Here the code goes\n1 + 1\nx <- c(1, 2, 3)\nmean(x)\n```\n\n[1] 2\n[1] 2\n\n\nOutside the code-chunks, go our markdown, e.g.:\n  # Header level 1\n  ## Header level 2\n  ### Header level 3\n  *A text in italics*\n  **A text in bold**\n  Normal text describing and explaining\nNow, in your new Quarto document, create a new Header level 2, e.g.:\n  ## Load Libraries\nand under your new header, add a new code chunk, like so\n\n```{r}\n#| message: false\nlibrary(\"tidyverse\")\n```\n\nAnd run the chunk. This will load our data science toolbox, including dplyr (and ggplot). But wait, what does the #| message: false-part do? 🤷️ 🤔\nTry to structure your Rmarkdown document as your course notes, i.e. add notes while solving the exercises aiming at creating a revisitable reference for your final project work\nBonus info: We are engineers, so of course, we love equations, we can include standard \\(\\LaTeX\\) syntax, e.g.:\n  $E(x) = \\frac{1}{n} \\cdot \\sum_{i=1}^{n} x_{i}$\nTry it!\n\n\nA few handy short cuts\nInsert new code chunk:\n\nMac: CTRL + OPTION + i\nWindows: CTRL + OPTION + i\n\nRender my Quarto document\n\nMac: CMD + SHIFT + k\nWin: CTRL + SHIFT + k\n\nRun line in chunk\n\nMac: CMD + ENTER\nWin: CTRL + ENTER\n\nRun entire chunk\n\nMac: CMD + SHIFT + ENTER\nWin: CTRL + SHIFT + ENTER\n\nInsert the pipe symbol |>\n\nMac: CMD + SHIFT + m\nWin: CTRL + SHIFT + m\n\nNote, if you’re trying this out and you see %>% instead of |>, then go to Tools, Global Options..., Code and check the box Use native pipeoperator"
  },
  {
    "objectID": "lab04.html#a-few-initial-questions",
    "href": "lab04.html#a-few-initial-questions",
    "title": "Lab 4: Data Wrangling I",
    "section": "A few initial questions",
    "text": "A few initial questions\nFirst, if you don’t feel completely comfortable with the group_by |> summarise-workflow, then no worries - Feel free to visit this short R Tutorial: Grouping and summarizing\nThen, in your groups, discuss the following primer questions. Note, when asked for “what is the output”, do not run the code in the console, instead try to talk and think about it and write your answers and notes in your Quarto document for the day:\nFirst, in a new chunk, run tibble(x = c(4, 3, 5, 1, 2)), so you understand what it does, then - Discuss in your group, what is the output of, remember first talk, then check understanding by running code:\n\nQ1: tibble(x = c(4, 3, 5, 1, 2)) |> filter(x > 2)?\nQ2: tibble(x = c(4, 3, 5, 1, 2)) |> arrange(x)?\nQ3: tibble(x = c(4, 3, 5, 1, 2)) |> arrange(desc(x))?\nQ4: tibble(x = c(4, 3, 5, 1, 2)) |> arrange(desc(desc(x)))?\nQ5: tibble(x = c(4, 3, 5, 1, 2), y = c(2, 4, 3, 5, 1)) |> select(x)?\nQ6: tibble(x = c(4, 3, 5, 1, 2), y = c(2, 4, 3, 5, 1)) |> select(y)?\nQ7: tibble(x = c(4, 3, 5, 1, 2), y = c(2, 4, 3, 5, 1)) |> select(-x)?\nQ8: tibble(x = c(4, 3, 5, 1, 2), y = c(2, 4, 3, 5, 1)) |> select(-x, -y)?\nQ9: tibble(x = c(4, 3, 5, 1, 2)) |> mutate(x_dbl = 2*x)?\nQ10: tibble(x = c(4, 3, 5, 1, 2)) |> mutate(x_dbl = 2 * x, x_qdr = 2*x_dbl)?\nQ11: tibble(x = c(4, 3, 5, 1, 2)) |> summarise(x_mu = mean(x))?\nQ12: tibble(x = c(4, 3, 5, 1, 2)) |> summarise(x_max = max(x))?\nQ13: tibble(lbl = c(\"A\", \"A\", \"B\", \"B\", \"C\"), x = c(4, NA, 5, 1, 2)) |> group_by(lbl) |> summarise(x_mu = mean(x), x_max = max(x))?\nQ14: tibble(lbl = c(\"A\", \"A\", \"B\", \"B\", \"C\"), x = c(4, 3, 5, 1, 2)) |> group_by(lbl) |> summarise(n = n())?\nQ15: tibble(lbl = c(\"A\", \"A\", \"B\", \"B\", \"C\"), x = c(4, 3, 5, 1, 2)) |> count(lbl)?\n\nIn the following, return to these questions and your answers for reference on the dplyr verbs!"
  },
  {
    "objectID": "lab04.html#load-data",
    "href": "lab04.html#load-data",
    "title": "Lab 4: Data Wrangling I",
    "section": "Load data",
    "text": "Load data\nAgain, add a new header to your Quarto document, e.g. ## Load Data, then:\n\nGo to the Vanderbilt Biostatistics Datasets site\nFind Diabetes data and download the diabetes.csv file\nYou should have a data-folder, if not, then in the Files pane, click the New Folder button, enter folder name data and click ok\nNow, click on the folder you created\nClick the  Upload-button and navigate to the diabetes.csv file you downloaded\nClicking the two dots .. above the file you uploaded, look for  .., will take you one level up in your project path\nInsert a new code chunk in your Quarto document\nAdd and then run the following code\n\n\ndiabetes_data <- read_csv(file = \"data/diabetes.csv\")\ndiabetes_data\n\nThen realise that we could simply have run the following code to do the exact same thing (Yes, readr is pretty nifty):\n\n# Create the data directory programmatically\ndir_create(x = \"data\")\n\n# Retrieve the data directly\ndiabetes_data <- read_csv(file = \"https://hbiostat.org/data/repo/diabetes.csv\")\n\n# Write the data to disk\nwrite_csv(x = diabetes_data,\n          file = \"data/diabetes.csv\")\n\nJust remember the echo/eval trick from last session to avoid retrieving online data each time you render your Quarto document"
  },
  {
    "objectID": "lab04.html#work-with-the-diabetes-data-set",
    "href": "lab04.html#work-with-the-diabetes-data-set",
    "title": "Lab 4: Data Wrangling I",
    "section": "Work with the diabetes data set",
    "text": "Work with the diabetes data set\nUse the pipe |> to use the View()-function to inspect the data set. Note, if you click the -button, you will get a spreadsheet-like view of the data, allowing you to get an overview.\n\nQ1: How many observations and how many variables?\nQ2: Is this a tidy data set? Which three rules must be satisfied?\nQ3: When you run the chunk, then underneath each column name is stated <chr> and <dbl> what is that?\n\nBefore we continue\n\nT1: Change the height, weight, waist and hip from inches/pounds to the metric system (cm/kg), rounding to 1 decimal\n\n\n\n\nLet us try to take a closer look at the data by various subsetting (How many… is equal to the number of rows in the subset of the data you created):\n\nQ4: How many weigh less than 100kg?\nQ5: How many weigh more than 100kg?\nQ6: How many weigh more than 100kg and are less than 1.6m tall?\nQ7: How many women are taller than 1.8m?\nQ8: How many men are taller than 1.8m?\nQ9: How many women in Louisa are older than 30?\nQ10: How many men in Buckingham are younger than 30 and taller than 1.9m?\nT2: Make a scatter plot of weight versus height and colour by sex for inhabitants of Louisa above the age of 40\nT3: Make a boxplot of height versus location stratified on sex for people above the age of 50\n\nSorting columns can aid in getting an overview of variable ranges (don’t use the summary function yet for this one)\n\nQ11: How old is the youngest person?\nQ12: How old is the oldest person?\nQ13: Of all the 20-year olds, what is the height of the tallest?\nQ14: Of all the 20-year olds, what is the height of the shortest?\n\nChoosing specific columns can be used to work with a subset of the data for a specific purpose\n\nQ15: How many columns (variables) starts_with a “b”?\nQ16: How many columns (variables) contains the word “eight”?\n\nCreating new variables is an integral part of data manipulation\n\nT4: Create a new variable, where you calculate the BMI\n\n\n\n\n\nT5: Create a BMI_class variable\n\nTake a look at the following code snippet to get you started:\n\ntibble(x = rnorm(10)) |> \n  mutate(trichotomised = case_when(\n    x < -1 ~ \"Less than -1\",\n    -1 <= x & x < 1 ~ \"larger than or equal to -1 and smaller than 1\",\n    1 <= x ~ \"Larger than or equal to 1\"))\n\nand then go read about BMI classification here and discuss in your group how to extract classifications from the Definition/Introduction section\nNote, the cut()-function could be used here, but you should try to use case_when() as illustrated in the example chunk above.\n\n\n\nOnce you have created the variable, you will need to convert it to a categorical variable, in R, these are called a factor and you can set the levels like so:\n\ndiabetes_data <- diabetes_data |>\n  mutate(BMI_class = factor(BMI_class,\n                            levels =  c(\"my 1st category\", \"my 2nd category\",\n                                        \"my 3rd category\", \"my nth category\")))\n\nThis is very important for plotting, as this will determine the order in which the categories appear on the plot!\n\nT6: Create a boxplot of hdl versus BMI_class\nQ17: What do you see?\nT7: Create a BFP (Body fat percentage) variable\n\n\n\n\nClick here for hint\n\n\nBFP can be calculated usin the below equation source:\n\\[BFP = 1.39 \\cdot BMI + 0.16 \\cdot age - 10.34 \\cdot sex - 9\\]\nWhere \\(sex\\) is defined as being \\(0\\) for female and \\(1\\) for male.\n\n\n\n\n\nT8: Create a WHR (waist-to-hip ratio) variable\nQ18: Which correlate better with BMI, WHR or BFP? GROUP ASSIGNMENT\n\n\n\n\nClick here for hint\n\n\nIs there a certain plot-type, which can visualise if the relationship between two variables and give insights to if they are correlated? Can you perhaps use an R-function to compute the “correlation coefficient”?. Do not use e.g. ggpubr, use only tidyverse and base)\n\nNow, with this augmented data set, let us create some summary statistics\n\nQ19: How many women and men are there in the data set?\nQ20: How many women and men are there from Buckingham and Louisa respectively in the data set?\nQ21: How many are in each of the BMI_class groups?\nQ22: Given the code below, explain the difference between A and B?\n\n\n# A\ndiabetes_data |>\n  ggplot(aes(x = BMI_class)) +\n  geom_bar()\n\n# B\ndiabetes_data |>\n  count(BMI_class) |>\n  ggplot(aes(x = BMI_class, y = n)) +\n  geom_col()\n\n\nT9: For each BMI_class group, calculate the average weight and associated standard deviation\nQ23: What was the average age of the women living in Buckingham in the study?\n\nFinally, if you reach this point and there is still time left. Take some time to do some exploratory plots of the data set and see if you can find something interesting."
  },
  {
    "objectID": "lab05.html",
    "href": "lab05.html",
    "title": "Lab 5: Data Wrangling II",
    "section": "",
    "text": "dplyr\nstringr\ntidyr\nforcats\npatchwork\nggseqlogo"
  },
  {
    "objectID": "lab05.html#schedule",
    "href": "lab05.html#schedule",
    "title": "Lab 5: Data Wrangling II",
    "section": "Schedule",
    "text": "Schedule\n\n08.00 - 08.30: Recap of Lab 4\n08.30 - 09.00: Introduction to Lab\n09.00 - 09.15: Break\n09.15 - 12.00: Exercises"
  },
  {
    "objectID": "lab05.html#learning-materials",
    "href": "lab05.html#learning-materials",
    "title": "Lab 5: Data Wrangling II",
    "section": "Learning Materials",
    "text": "Learning Materials\nPlease prepare the following materials\n\nR4DS2e book: Chapter 6: Data Tidying, Chapter 15: Strings, Chapter 17: Factors, Chapter 20: Joins\nVideo: Tidy Data and tidyr - NB! Start at 7:45 and please note: gather() is now pivot_longer() and spread() is now pivot_wider()\nVideo: Working with Two Datasets: Binds, Set Operations, and Joins\nVideo: stringr (Playlist with 7 short videos)"
  },
  {
    "objectID": "lab05.html#learning-objectives",
    "href": "lab05.html#learning-objectives",
    "title": "Lab 5: Data Wrangling II",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nA student who has met the objectives of the session will be able to:\n\nUnderstand and apply the various str_*()-functions for string manipulation\nUnderstand and apply the family of *_join()-functions for combining data sets\nUnderstand and apply pivot_wider() and pivot_longer()\nUse factors in context with plotting categorical data using ggplot"
  },
  {
    "objectID": "lab05.html#exercises",
    "href": "lab05.html#exercises",
    "title": "Lab 5: Data Wrangling II",
    "section": "Exercises",
    "text": "Exercises"
  },
  {
    "objectID": "lab05.html#intro",
    "href": "lab05.html#intro",
    "title": "Lab 5: Data Wrangling II",
    "section": "Intro",
    "text": "Intro\nWe are upping the game here, so expect to get stuck at some of the questions. Remember - Discuss with your group how to solve the task, revisit the materials you prepared for today and naturally, the TAs and I are happy to nudge you in the right direction. Finally, remember… Have fun!\nRemember what you have worked on so far:\n\nRStudio\nQuarto\nggplot\nfilter\narrange\nselect\nmutate\ngroup_by\nsummarise\nThe pipe and creating pipelines\nstringr\njoining data\npivotting data\n\nWell done! Remember to think about this in the following as we will synthesise the above into an analysis below!"
  },
  {
    "objectID": "lab05.html#getting-started",
    "href": "lab05.html#getting-started",
    "title": "Lab 5: Data Wrangling II",
    "section": "Getting Started",
    "text": "Getting Started\nToday, we will work with data from a recent study of T-cell receptors and SARS-CoV-2:\n\nA large-scale database of T-cell receptor beta (TCR\\(\\beta\\)) sequences and binding associations from natural and synthetic exposure to SARS-CoV-2\n\nBriefly, the virus invades the cells and takes over the intra-cellular machinery. Viral proteins are produced this way and the proteasome breaks down some of the proteins into smaller fragments called peptides. These peptides are transported into the endoplasmatic reticulum by the Transporter Associated with antigen Processing (TAP) protein complex. Here, they are aided by chaperones bound to the Major Histocompatilibty Complex class I (MHCI) and then across the Golgi Aparatus they finally get displayed on the surface of the cells. Note, in humans, MHC is also called Human Leukocyte Antigen (HLA). Once at the cell surface and exposed, the MHC-peptide complex can be recognised by CD8+ Cytotoxic T-Lymphocytes (CTLs) via the T-cell Receptor (TCR). The proces is summarised in the figure below. The data we will be working with today contains cohort data on sequenced T-cell receptors, viral antigens, HLA-haplotypes and clinical meta data.\n\n\n\n\n\nImage source: 10.3389/fmicb.2015.00021\nNow:\n\nMake sure you are in your r_for_bio_data_science-project, you can verify this in the upper right corner\nIn the same place as your r_for_bio_data_science.Rproj-file and existing data-folder, create a new folder and name it doc\nGo to the aforementioned manuscript. Download the PDF and upload it to your new doc-folder\nOpen the PDF and find the link to the data\nGo to the data site (Note, you may have to create and account to download, shouldn’t take too long)\nFind and download the file ImmuneCODE-MIRA-Release002.1.zip (CAREFUL, do not download the superseded files)\nUnpack, find the files peptide-detail-ci.csv and subject-metadata.csv and upload them to your data-folder in your RStudio Cloud session\nFinally, once again, create a new Quarto document for todays exercises"
  },
  {
    "objectID": "lab05.html#creating-one-data-set-from-two-data-sets",
    "href": "lab05.html#creating-one-data-set-from-two-data-sets",
    "title": "Lab 5: Data Wrangling II",
    "section": "Creating one data set from two data sets",
    "text": "Creating one data set from two data sets\nRemember to load libraries first and then read the two data sets into variables peptide_data and meta_data.\n\n\n\nClick here for hint\n\n\nThink about which Tidyverse package deals with reading data and what are the file types we want to read here?\n\n\n\n\n\nQ1: What are the dimensions of the peptide_data and meta_data respectively?, I.e. how many rows and columns corresponding to observations and varialbes?\nQ2: Which variable is shared between the two data sets?\n\nNow, join the two data sets into to one data set called peptide_meta_data using the variable from Q2 and create a pipeline, including your joining code and this bit-of-code select(-matches(\"D[RQP]\")) - Make sure to discuss in your group what this bit-of-code actually does?\n\n\n\nClick here for hint\n\n\nPlay around with the bit-of-code, e.g. change it to select(-matches(\"D[RQ]\")) and see what happens\n\n\n\n\n\nQ3: What are the dimensions of the joined data and how does this compare with Q1?"
  },
  {
    "objectID": "lab05.html#eda-exploraty-data-analysis-i---the-meta-data",
    "href": "lab05.html#eda-exploraty-data-analysis-i---the-meta-data",
    "title": "Lab 5: Data Wrangling II",
    "section": "EDA: Exploraty Data Analysis I - The meta data",
    "text": "EDA: Exploraty Data Analysis I - The meta data\nLet us ask the joined data (peptide_meta_data) some questions:\n\nQ4: How many study participants are denoted Healthy?\n\n\n\n\nClick here for hint\n\n\nFirst find out which variable identifies the study participants\n\n\nQ5: Actually, what are the study participants cohort groups and how many are in each?\n\n\n\n\nClick here for hint\n\n\nPerhaps there is a way to count the cohort groups?\n\nNow, create a histogram of the age of the study participants (Make sure to read any error-/warning-messages you may get_)\n\nQ6: Take a look at the age variable to understand what happened?\nQ7: How are NAs denoted in the data?\n\nSomething’s off… Remember you can get help on ANY R-function by typing ?function_name in the console. Now, let’s fix that from get-go. Go back and find the chunk, where you read the data into your session and see if you can fix the NA-problem, when you call the read_csv.\nOnce you have done that, re-create the histogram of the age of the study participants and play around with and understand the binwidth-parameter.\n\n\n\n\nQ8: From the histogram, approximately how many are study participants are 33 years old?\nQ9: Compare this number to the dimensions of the meta_data (see Q1), what happened?\n\nUsing the dplyr verbs select and distinct, re-re-create the histogram of the age of the study participants and again, play around with and understand the binwidth\n\n\n\n\nQ10: From the histogram, how many are participants are now 33 years old?\nQ11: How many of the participants are women? Men?\n\nRecreate the below visualisation, it does not have to be 100% identical, just make sure to discuss which ggplot-components carry the plot and get those replicated.\n\n\n\n\n\nTake some time to do some EDA, understand what is in the data, do some summaries, make some plots. Basically, you have to know the data you are working with"
  },
  {
    "objectID": "lab05.html#eda-exploraty-data-analysis-ii---the-sequence-data",
    "href": "lab05.html#eda-exploraty-data-analysis-ii---the-sequence-data",
    "title": "Lab 5: Data Wrangling II",
    "section": "EDA: Exploraty Data Analysis II - The Sequence Data",
    "text": "EDA: Exploraty Data Analysis II - The Sequence Data\n\nPart I\nThe first thing we will take a look at here, is how the Subject HLA-alleles are distributed. But wait, discuss in your group, what are HLA-alleles?\nNow, create subset the peptide_meta_data to the variables Subject, HLA- and save it into allele_data, like so:\n\n\n# A tibble: 127 × 7\n   Subject `HLA-A...9` `HLA-A...10` `HLA-B...11` `HLA-B...12` `HLA-C...13`\n     <dbl> <chr>       <chr>        <chr>        <chr>        <chr>       \n 1   20655 A*11:01     A*68:01      B*35:01      B*35:03      C*03:03     \n 2   14758 A*02:01     A*33:03      B*53:01      B*58:01      C*03:02     \n 3     361 A*01:01:01  A*02:01:01   B*15:01:01   B*51:01:01   C*01:02:01  \n 4    1528 A*02:01:01  A*02:01:01   B*13:02:01   B*18:01:01   C*06:02:01  \n 5     273 A*02:01:01  A*03:01:01   B*07:02:01   B*18:01:01   C*07:01:01  \n 6    1245 A*03:01:01  A*32:01:01   B*07:02:01   B*07:02:01   C*07:02:01  \n 7    2267 A*02:01:01  A*32:01:01   B*15:01:01   B*51:01:01   C*02:02:02  \n 8     242 A*01:01:01  A*02:01:01   B*37:01:01   B*44:03:01   C*06:02:01  \n 9   19943 A*02:01     A*02:01      B*35:03      B*44:02      C*04:01     \n10    3819 A*02:01     A*03:01      B*07:02      B*44:27      C*07:02     \n# ℹ 117 more rows\n# ℹ 1 more variable: `HLA-C...14` <chr>\n\n\n\n\n\nClick here for hint\n\n\nThe select()-verb can be combined with so-called selection helpers. In the console, enter ?select and perhaps you can find a helper, which selects variables, which starts_with or contains something? Also, make sure that you only have distinct observations of Subject\n\nBefore continuing, how many rows/observations do you see in the allele_data? Compare with the number of rows in the original meta_data, are they different and if so why?\n\n\n\nClick here for hint\n\n\nUse the View()-function to inspect the meta_data, click the -button and scroll through the data\n\nThen convert the data to long format and save it a new variable allele_data_long like so:\n\n\n# A tibble: 762 × 3\n   Subject Gene       Allele \n     <dbl> <chr>      <chr>  \n 1   20655 HLA-A...9  A*11:01\n 2   20655 HLA-A...10 A*68:01\n 3   20655 HLA-B...11 B*35:01\n 4   20655 HLA-B...12 B*35:03\n 5   20655 HLA-C...13 C*03:03\n 6   20655 HLA-C...14 C*04:01\n 7   14758 HLA-A...9  A*02:01\n 8   14758 HLA-A...10 A*33:03\n 9   14758 HLA-B...11 B*53:01\n10   14758 HLA-B...12 B*58:01\n# ℹ 752 more rows\n\n\n\nQ12: How many unique alleles are there?\n\n\n\n\nUsing the View()-function again, look at the unique alleles - Notice something? Some alleles are e.g. A*11:01, whereas others are B*51:01:02. You can find information on why, by visiting Nomenclature for Factors of the HLA System.\nLong story short, we only want to include Field 1 (allele group) and Field 2 (Specific HLA protein). You have prepared the stringr-package for today. See if you can find a way to reduce e.g. B*51:01:02 to B*51:01 and then create a new variable Allele_F_1_2 accordingly, while also removing the ...x (where x is a number) subscripts from the Gene-variable (It is an artifact from having the data in a wide format, where you cannot have two variables with the same name) and also, remove any NAs\n\n\n\nClick here for hint\n\n\nThere are several ways this can be achieved, the easiest being to consider if perhaps a part of the string based on indices could be of interest. This term “a part of a string” is called a substring, perhaps the stringr-package contains a function work with substring? In the console, type stringr:: and hit tab. This will display the functions available in the stringr-package. Scroll down and find the functionst starting with str_ and look for on, which might be relevant and remember you can use ?function_name to get more information on how a given function works.\n\n\n\n# A tibble: 684 × 4\n   Subject Gene  Allele  Allele_F_1_2\n     <dbl> <chr> <chr>   <chr>       \n 1   20655 HLA-A A*11:01 A*11:01     \n 2   20655 HLA-A A*68:01 A*68:01     \n 3   20655 HLA-B B*35:01 B*35:01     \n 4   20655 HLA-B B*35:03 B*35:03     \n 5   20655 HLA-C C*03:03 C*03:03     \n 6   20655 HLA-C C*04:01 C*04:01     \n 7   14758 HLA-A A*02:01 A*02:01     \n 8   14758 HLA-A A*33:03 A*33:03     \n 9   14758 HLA-B B*53:01 B*53:01     \n10   14758 HLA-B B*58:01 B*58:01     \n# ℹ 674 more rows\n\n\n\nQ13: How many unique alleles are there now?\n\n\n\n\n\nQ14: What are the top 3 alleles in terms of counts in the data?\nQ15: Per gene and in terms of percent, what are the 10 top alleles? Recreate this plot to answer the question GROUP ASSIGNMENT:\n\n\n\n\n\n\n\n\n\nClick here for hint\n\n\nWhat does fct_reorder()´do? Also, consider when working per gene, you will probably have to include that grouping in your pipeline - Remember we don't loop, we func! Also, you can use a combination of thearrange()- andslice()`-functions to get top or bottom something observations.\n\n\n\nPart II\nThis last part is rather tricky and therefore optional. It will take some time and trial-and-error to complete, so if you’re up for it, feel free to take on the challenge to test and expand your skills!\nNow, that we have worked with the HLA-alleles, we will take a look into how the peptides bind to the HLA-alleles.\nFirst, create this data set from your peptide_meta_data data set and save in a new variable sequence_data (drop ANY rows contaning NAs ):\n\n\n# A tibble: 148,489 × 8\n   `TCR BioIdentity`         `Amino Acids` `HLA-A...9` `HLA-A...10` `HLA-B...11`\n   <chr>                     <chr>         <chr>       <chr>        <chr>       \n 1 CASSAQGTGDRGYTF+TCRBV27-… ADAGFIKQY,AE… A*11:01     A*68:01      B*35:01     \n 2 CASSLVATGNTGELFF+TCRBV07… ADAGFIKQY,AE… A*02:01     A*33:03      B*53:01     \n 3 CASSKGTVSGLSG+TCRBV21-01… ADAGFIKQY,AE… A*11:01     A*68:01      B*35:01     \n 4 CALKVGADTQYF+TCRBV30-01+… ADAGFIKQY,AE… A*01:01:01  A*02:01:01   B*15:01:01  \n 5 CASSLWASGRGGTGELFF+TCRBV… ADAGFIKQY,AE… A*11:01     A*68:01      B*35:01     \n 6 CASSLLGWEQLDEQFF+TCRBV27… ADAGFIKQY,AE… A*02:01:01  A*02:01:01   B*13:02:01  \n 7 CASSSGTGVYGYTF+TCRBV12-X… ADAGFIKQY,AE… A*11:01     A*68:01      B*35:01     \n 8 CASSPLEWEGVTEAFF+TCRBV06… ADAGFIKQY,AE… A*02:01:01  A*03:01:01   B*07:02:01  \n 9 CASSFWSSGRGGTDTQYF+TCRBV… ADAGFIKQY,AE… A*11:01     A*68:01      B*35:01     \n10 CASSAGQGASDEQFF+TCRBV07-… ADAGFIKQY,AE… A*03:01:01  A*32:01:01   B*07:02:01  \n# ℹ 148,479 more rows\n# ℹ 3 more variables: `HLA-B...12` <chr>, `HLA-C...13` <chr>,\n#   `HLA-C...14` <chr>\n\n\n\nQ16: How many rows contained NAs?\nQ17: Is this data tidy? Explain why you answered yes or no\n\nNow, google tidyr separate and figure out how this works. Then fix the TCR BioIdentity-variable like so:\n\n\n# A tibble: 148,489 × 10\n   CDR3b       v_gene j_gene `Amino Acids` `HLA-A...9` `HLA-A...10` `HLA-B...11`\n   <chr>       <chr>  <chr>  <chr>         <chr>       <chr>        <chr>       \n 1 CASSAQGTGD… TCRBV… TCRBJ… ADAGFIKQY,AE… A*11:01     A*68:01      B*35:01     \n 2 CASSLVATGN… TCRBV… TCRBJ… ADAGFIKQY,AE… A*02:01     A*33:03      B*53:01     \n 3 CASSKGTVSG… TCRBV… TCRBJ… ADAGFIKQY,AE… A*11:01     A*68:01      B*35:01     \n 4 CALKVGADTQ… TCRBV… TCRBJ… ADAGFIKQY,AE… A*01:01:01  A*02:01:01   B*15:01:01  \n 5 CASSLWASGR… TCRBV… TCRBJ… ADAGFIKQY,AE… A*11:01     A*68:01      B*35:01     \n 6 CASSLLGWEQ… TCRBV… TCRBJ… ADAGFIKQY,AE… A*02:01:01  A*02:01:01   B*13:02:01  \n 7 CASSSGTGVY… TCRBV… TCRBJ… ADAGFIKQY,AE… A*11:01     A*68:01      B*35:01     \n 8 CASSPLEWEG… TCRBV… TCRBJ… ADAGFIKQY,AE… A*02:01:01  A*03:01:01   B*07:02:01  \n 9 CASSFWSSGR… TCRBV… TCRBJ… ADAGFIKQY,AE… A*11:01     A*68:01      B*35:01     \n10 CASSAGQGAS… TCRBV… TCRBJ… ADAGFIKQY,AE… A*03:01:01  A*32:01:01   B*07:02:01  \n# ℹ 148,479 more rows\n# ℹ 3 more variables: `HLA-B...12` <chr>, `HLA-C...13` <chr>,\n#   `HLA-C...14` <chr>\n\n\n\n\n\nClick here for hint\n\n\nWhat character seems to be separating the sequence from the TCRB-v-gene and TCRB-j-gene? Also, sometimes when you want to separate on characters, that can mean more than one thing, you will have to do what is called an escape, which is done using a double back-slash \\\\x, where x here denotes the aforementioned character with double meaning\n\n\nQ18: Is this data tidy now? Explain why you answered yes or no\n\nAdd a new variable n_peptides to your data set, which counts how many peptides are listed in Amino Acids variable\n\n\n\nClick here for hint\n\n\nIs there a package designed specifically for working with strings? If so perhaps it can be used for some trickery in connection with counting how many times “something” appears in a string?\n\n\n\n\nCreate a histogram of distribution of the n_peptides variable\n\n\n\n\n\n\nQ19: What is the maximum number of peptides seen for one observation?\n\nImportant: Now you can choose one of two paths in the exercises and either is fine! Either you proceed to Route A (a bit more difficult and with a larger dataset) or scroll down to Route B (a bit less difficult and with a smaller dataset)!\n\nRoute A\nNow, Using str_c() and seq(), see if you can re-create this:\n\n\n[1] \"peptide_1\" \"peptide_2\" \"peptide_3\" \"peptide_4\" \"peptide_5\"\n\n\nBut changing the last peptide_n, such that n is the maximum number of peptides from Q19, 5 won’t do. Then use that to fix the Amino Acids-variable, like so:\n\n\nWarning: Expected 13 pieces. Missing pieces filled with `NA` in 145021 rows [1, 2, 3, 4,\n5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...].\n\n\n# A tibble: 148,489 × 23\n   CDR3b         v_gene j_gene peptide_1 peptide_2 peptide_3 peptide_4 peptide_5\n   <chr>         <chr>  <chr>  <chr>     <chr>     <chr>     <chr>     <chr>    \n 1 CASSAQGTGDRG… TCRBV… TCRBJ… ADAGFIKQY AELEGIQY  LADAGFIK… TLADAGFIK <NA>     \n 2 CASSLVATGNTG… TCRBV… TCRBJ… ADAGFIKQY AELEGIQY  LADAGFIK… TLADAGFIK <NA>     \n 3 CASSKGTVSGLSG TCRBV… TCRBJ… ADAGFIKQY AELEGIQY  LADAGFIK… TLADAGFIK <NA>     \n 4 CALKVGADTQYF  TCRBV… TCRBJ… ADAGFIKQY AELEGIQY  LADAGFIK… TLADAGFIK <NA>     \n 5 CASSLWASGRGG… TCRBV… TCRBJ… ADAGFIKQY AELEGIQY  LADAGFIK… TLADAGFIK <NA>     \n 6 CASSLLGWEQLD… TCRBV… TCRBJ… ADAGFIKQY AELEGIQY  LADAGFIK… TLADAGFIK <NA>     \n 7 CASSSGTGVYGY… TCRBV… TCRBJ… ADAGFIKQY AELEGIQY  LADAGFIK… TLADAGFIK <NA>     \n 8 CASSPLEWEGVT… TCRBV… TCRBJ… ADAGFIKQY AELEGIQY  LADAGFIK… TLADAGFIK <NA>     \n 9 CASSFWSSGRGG… TCRBV… TCRBJ… ADAGFIKQY AELEGIQY  LADAGFIK… TLADAGFIK <NA>     \n10 CASSAGQGASDE… TCRBV… TCRBJ… ADAGFIKQY AELEGIQY  LADAGFIK… TLADAGFIK <NA>     \n# ℹ 148,479 more rows\n# ℹ 15 more variables: peptide_6 <chr>, peptide_7 <chr>, peptide_8 <chr>,\n#   peptide_9 <chr>, peptide_10 <chr>, peptide_11 <chr>, peptide_12 <chr>,\n#   peptide_13 <chr>, `HLA-A...9` <chr>, `HLA-A...10` <chr>,\n#   `HLA-B...11` <chr>, `HLA-B...12` <chr>, `HLA-C...13` <chr>,\n#   `HLA-C...14` <chr>, n_peptides <dbl>\n\n\nand convert the data and save it into sequence_data_long, like so:\n\n\n# A tibble: 1,930,357 × 12\n   CDR3b        v_gene j_gene `HLA-A...9` `HLA-A...10` `HLA-B...11` `HLA-B...12`\n   <chr>        <chr>  <chr>  <chr>       <chr>        <chr>        <chr>       \n 1 CASSAQGTGDR… TCRBV… TCRBJ… A*11:01     A*68:01      B*35:01      B*35:03     \n 2 CASSAQGTGDR… TCRBV… TCRBJ… A*11:01     A*68:01      B*35:01      B*35:03     \n 3 CASSAQGTGDR… TCRBV… TCRBJ… A*11:01     A*68:01      B*35:01      B*35:03     \n 4 CASSAQGTGDR… TCRBV… TCRBJ… A*11:01     A*68:01      B*35:01      B*35:03     \n 5 CASSAQGTGDR… TCRBV… TCRBJ… A*11:01     A*68:01      B*35:01      B*35:03     \n 6 CASSAQGTGDR… TCRBV… TCRBJ… A*11:01     A*68:01      B*35:01      B*35:03     \n 7 CASSAQGTGDR… TCRBV… TCRBJ… A*11:01     A*68:01      B*35:01      B*35:03     \n 8 CASSAQGTGDR… TCRBV… TCRBJ… A*11:01     A*68:01      B*35:01      B*35:03     \n 9 CASSAQGTGDR… TCRBV… TCRBJ… A*11:01     A*68:01      B*35:01      B*35:03     \n10 CASSAQGTGDR… TCRBV… TCRBJ… A*11:01     A*68:01      B*35:01      B*35:03     \n# ℹ 1,930,347 more rows\n# ℹ 5 more variables: `HLA-C...13` <chr>, `HLA-C...14` <chr>, n_peptides <dbl>,\n#   peptide_n <chr>, peptide <chr>\n\n\n\nQ20: How many observations are now in sequence_data_long?\n\nRemove NAs, fix the HLA-alleles, remove redundant columns and observations, like so:\n\n\n# A tibble: 3,242,120 × 5\n   CDR3b           v_gene     j_gene     peptide   allele \n   <chr>           <chr>      <chr>      <chr>     <chr>  \n 1 CASSAQGTGDRGYTF TCRBV27-01 TCRBJ01-02 ADAGFIKQY A*11:01\n 2 CASSAQGTGDRGYTF TCRBV27-01 TCRBJ01-02 ADAGFIKQY A*68:01\n 3 CASSAQGTGDRGYTF TCRBV27-01 TCRBJ01-02 ADAGFIKQY B*35:01\n 4 CASSAQGTGDRGYTF TCRBV27-01 TCRBJ01-02 ADAGFIKQY B*35:03\n 5 CASSAQGTGDRGYTF TCRBV27-01 TCRBJ01-02 ADAGFIKQY C*03:03\n 6 CASSAQGTGDRGYTF TCRBV27-01 TCRBJ01-02 ADAGFIKQY C*04:01\n 7 CASSAQGTGDRGYTF TCRBV27-01 TCRBJ01-02 AELEGIQY  A*11:01\n 8 CASSAQGTGDRGYTF TCRBV27-01 TCRBJ01-02 AELEGIQY  A*68:01\n 9 CASSAQGTGDRGYTF TCRBV27-01 TCRBJ01-02 AELEGIQY  B*35:01\n10 CASSAQGTGDRGYTF TCRBV27-01 TCRBJ01-02 AELEGIQY  B*35:03\n# ℹ 3,242,110 more rows\n\n\n\nQ21: How many observations now? Is this data tidy now?\n\n\n\nRoute B\nNow, let us proceed with the observations, where we just have a single peptide annotated, so subset your data accordingly, using the n_peptides variable you created, like so:\n\n\n# A tibble: 52,857 × 11\n   CDR3b       v_gene j_gene `Amino Acids` `HLA-A...9` `HLA-A...10` `HLA-B...11`\n   <chr>       <chr>  <chr>  <chr>         <chr>       <chr>        <chr>       \n 1 CASSLSAGFG… TCRBV… TCRBJ… SEVGPEHSLAEY  A*01:01:01  A*02:01:01   B*40:01:02  \n 2 CASSLTGQTD… TCRBV… TCRBJ… SEVGPEHSLAEY  A*02:01     A*26:01      B*44:02     \n 3 CASSLDVWET… TCRBV… TCRBJ… SEVGPEHSLAEY  A*01:01:01  A*24:02:01   B*08:01:01  \n 4 CASSASGTEE… TCRBV… TCRBJ… SEVGPEHSLAEY  A*02:01     A*26:01      B*44:02     \n 5 CASSEGTANT… TCRBV… TCRBJ… SEVGPEHSLAEY  A*11:01:01  A*24:02:01   B*15:01:01  \n 6 CASSLSGYQE… TCRBV… TCRBJ… SEVGPEHSLAEY  A*02:01     A*26:01      B*44:02     \n 7 CASTPGPSYE… TCRBV… TCRBJ… SEVGPEHSLAEY  A*02:01     A*03:01      B*40:01     \n 8 CASSLSGATD… TCRBV… TCRBJ… SEVGPEHSLAEY  A*02:01     A*26:01      B*44:02     \n 9 CASWKRGGRE… TCRBV… TCRBJ… SEVGPEHSLAEY  A*02:01     A*03:01      B*40:01     \n10 CASSSPGTGV… TCRBV… TCRBJ… SEVGPEHSLAEY  A*01:01     A*02:01      B*35:02     \n# ℹ 52,847 more rows\n# ℹ 4 more variables: `HLA-B...12` <chr>, `HLA-C...13` <chr>,\n#   `HLA-C...14` <chr>, n_peptides <dbl>\n\n\nThen collect all the alleles in one variable, like so:\n\n\n# A tibble: 297,910 × 5\n   CDR3b          v_gene     j_gene     `Amino Acids` allele    \n   <chr>          <chr>      <chr>      <chr>         <chr>     \n 1 CASSLSAGFGYTF  TCRBV27-01 TCRBJ01-02 SEVGPEHSLAEY  A*01:01:01\n 2 CASSLSAGFGYTF  TCRBV27-01 TCRBJ01-02 SEVGPEHSLAEY  A*02:01:01\n 3 CASSLSAGFGYTF  TCRBV27-01 TCRBJ01-02 SEVGPEHSLAEY  B*40:01:02\n 4 CASSLSAGFGYTF  TCRBV27-01 TCRBJ01-02 SEVGPEHSLAEY  B*52:01:02\n 5 CASSLSAGFGYTF  TCRBV27-01 TCRBJ01-02 SEVGPEHSLAEY  C*03:04:01\n 6 CASSLSAGFGYTF  TCRBV27-01 TCRBJ01-02 SEVGPEHSLAEY  C*16:01:01\n 7 CASSLTGQTDTQYF TCRBV07-09 TCRBJ02-03 SEVGPEHSLAEY  A*02:01   \n 8 CASSLTGQTDTQYF TCRBV07-09 TCRBJ02-03 SEVGPEHSLAEY  A*26:01   \n 9 CASSLTGQTDTQYF TCRBV07-09 TCRBJ02-03 SEVGPEHSLAEY  B*44:02   \n10 CASSLTGQTDTQYF TCRBV07-09 TCRBJ02-03 SEVGPEHSLAEY  B*52:01   \n# ℹ 297,900 more rows\n\n\n\n\n\nClick here for hint\n\n\nThink about the format of the data, is it wide or is it long? How do we convert between these formats?\n\n…and let’s also go ahead and change the name of the Amino Acids-variable to peptide\n\n\n\n\n\nCreating Sequence Logos\nBefore we continue, let’s just re-fix the alleles, such that e.g. A*02:01:01 becomes A*02:01, recall we did this earlier in today’s exercises. Also, this might create some multiplicates, so make sure to throw in a distinct() and finally add to your pipeline a new variable k_peptide, which determines the length of the peptide and a k_CDR3B likewise.\n\n\n\nAs we have touched upon multiple times, R is very flexible and naturally you can also create sequence logos. Finally, let us create a binding motif using the package ggseqlogo (More info here). Subset the final sequence_data_long-data to A*02:01 and unique observations of peptides of length 9\n\n\n\nClick here for hint\n\n\nYou can pipe a vector of peptides into ggseqlogo, but perhaps you first need to pull that vector from the relevant variable in your tibble? Also, consider before that, that you’ll need to make sure, you are only looking at peptides of length 9\n\n\n\n\n\n\nNote: Here, the A and B denote either route A or B through this last part\nIf you fancy, repeat for the most prevalent B-allele, see Q15\n\nQ22: Which positions in the peptide determines binding to HLA?\n\n\n\n\nClick here for hint\n\n\nRecall your Introduction to Bioinformatics course?\n\nNow finally, re-create this logo using the CDR3B-sequences and A*02:01-alleles:"
  },
  {
    "objectID": "lab05.html#epilogue",
    "href": "lab05.html#epilogue",
    "title": "Lab 5: Data Wrangling II",
    "section": "Epilogue",
    "text": "Epilogue\nThat’s it for today - I know this overwhelming now, but commit to it and you WILL be plenty rewarded! I hope today was at least a glimpse into the flexibility and capabilities of using tidyverse for applied Bio Data Science"
  },
  {
    "objectID": "lab06.html#packages",
    "href": "lab06.html#packages",
    "title": "Lab 6: (a bit on) Modelling in the Tidyverse",
    "section": "Package(s)",
    "text": "Package(s)\n\nbroom\npurrr\nvroom"
  },
  {
    "objectID": "lab06.html#schedule",
    "href": "lab06.html#schedule",
    "title": "Lab 6: (a bit on) Modelling in the Tidyverse",
    "section": "Schedule",
    "text": "Schedule\n\n08.00 - 08.10: Course midway evaluation\n08.10 - 08.30: Recap of exercises from last lab (Incl. assignment)\n08.30 - 09.00: Introduction to Lab\n09.00 - 09.15: Break\n09.00 - 12.00: Exercises, here is a walk-along-example"
  },
  {
    "objectID": "lab06.html#learning-materials",
    "href": "lab06.html#learning-materials",
    "title": "Lab 6: (a bit on) Modelling in the Tidyverse",
    "section": "Learning Materials",
    "text": "Learning Materials\nPlease prepare the following materials:\nBook: R4DS chapters 22 Introduction, 23 Model basics, 24 Model building, 25 Many models Video: Broom: Converting Statistical Models to Tidy Data Frames Video: Alex Hayes | Solving the model representation problem with broom | RStudio (2019) Video: “The Joy of Functional Programming (for Data Science)” with Hadley Wickham"
  },
  {
    "objectID": "lab06.html#learning-objectives",
    "href": "lab06.html#learning-objectives",
    "title": "Lab 6: (a bit on) Modelling in the Tidyverse",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nA student who has met the objectives of the session will be able to:\n\nUnderstand and apply simple purrr-functions for element-wise function application\nUnderstand and apply grouped supervised models to form nested model objects\nUnderstand and apply the broom-functions for tidying various model objects\nPerform a basic principal component analysis for dimension reduction of high dimensional data\nPerform a basic unsupervised k-means clustering of high dimensional data"
  },
  {
    "objectID": "lab07.html",
    "href": "lab07.html",
    "title": "Lab 7: Scripting in a Reproducible and Collaborative Framework using GitHub via RStudio",
    "section": "",
    "text": "Package(s)\n\nusethis\ngit (Actually not an R-package this time)"
  },
  {
    "objectID": "lab07.html#schedule",
    "href": "lab07.html#schedule",
    "title": "Lab 7: Scripting in a Reproducible and Collaborative Framework using GitHub via RStudio",
    "section": "Schedule",
    "text": "Schedule\n\n08.00 - 08.15: Recap of midway evaluation and exercises from last lab\n08.15 - 08.30: Assignment walk-through\n08.30 - 09.00: Introduction to Lab\n09.00 - 09.15: Break\n09.00 - 12.00: Exercises"
  },
  {
    "objectID": "lab07.html#learning-materials",
    "href": "lab07.html#learning-materials",
    "title": "Lab 7: Scripting in a Reproducible and Collaborative Framework using GitHub via RStudio",
    "section": "Learning Materials",
    "text": "Learning Materials\nPlease prepare the following materials\n\nBook: Happy Git and GitHub for the useR – Read chapters 1 (intro), 20 (basic terms), 22 (branching), 23 (remotes). Do not pay much attention to syntax of specific commands, because we are not going to use them during the exercises, focus on the idea.\nBook: Introduction to Data Science - Data Analysis and Prediction Algorithms with R by Rafael A. Irizarry: Chapter 40 Git and GitHub – Some of the information here is redundant with the previous book, but very important thing is a visualization of basic git actions and screenshots of how to perform them using RStudio.\nVideo: RStudio and Git - an Overview (Part 1) – Basic git concepts, for those who prefer listen rather than read. Books, however, contain more information.\nVideo: How to use Git and GitHub with R – Basic operating on git in RStudio. Complementary to second book. You can skip to 2:50, we are not going to link to git manually either way."
  },
  {
    "objectID": "lab07.html#learning-objectives",
    "href": "lab07.html#learning-objectives",
    "title": "Lab 7: Scripting in a Reproducible and Collaborative Framework using GitHub via RStudio",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nA student who has met the objectives of the session will be able to:\n\nExplain why reproducible data analysis is important\nIdentify associated relevant challenges\nExplain replicability versus reproducibility\nDescribe the components of a reproducible data analysis\nUse RStudio and GitHub (git) for collaborative bio data science projects"
  },
  {
    "objectID": "lab08.html#packages",
    "href": "lab08.html#packages",
    "title": "Lab 8: Creating a Simple R-package",
    "section": "Package(s)",
    "text": "Package(s)\n\ndevtools\nusethis\nroxygen2\ntestthat"
  },
  {
    "objectID": "lab08.html#schedule",
    "href": "lab08.html#schedule",
    "title": "Lab 8: Creating a Simple R-package",
    "section": "Schedule",
    "text": "Schedule\n\n08.00 - 08.15: Recap of exercises from last lab\n08.15 - 08.30: Assignment walk-through\n08.30 - 09.00: Lecture\n09.00 - 09.15: Break\n09.00 - 12.00: Exercises"
  },
  {
    "objectID": "lab08.html#learning-materials",
    "href": "lab08.html#learning-materials",
    "title": "Lab 8: Creating a Simple R-package",
    "section": "Learning Materials",
    "text": "Learning Materials\nPlease prepare the following materials:\n\nCheatsheet: Package development with devtools – When in doubt, check here first\nWeb: R Packages: A Beginner’s Tutorial – Read this before class\nWeb: Developing Packages with RStudio – Creating an R Package with RStudio\nWeb: R package primer a minimal tutorial – Brief but comprehensive R Package tutorial\nBook: R Packages - 1 Introduction – Everything you need to know about R Packages"
  },
  {
    "objectID": "lab08.html#learning-objectives",
    "href": "lab08.html#learning-objectives",
    "title": "Lab 8: Creating a Simple R-package",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nA student who has met the objectives of the session will be able to:\n\nPrepare a simple R package for distributing documented functions\nExplain the terms Repository, Dependencies, and Namespace\nImplement testing in an R package\nCollaboratively work on an R package on GitHub"
  },
  {
    "objectID": "lab08.html#sec-exercises",
    "href": "lab08.html#sec-exercises",
    "title": "Lab 8: Creating a Simple R-package",
    "section": "Exercises",
    "text": "Exercises\nRead the steps of this exercises carefully while completing them\n\nIntroduction\nThe aim of these exercises is to set up a collaborative coding project using GitHub and collaborate on creating a simple R package that replicates the central dogma of molecular biology.\nThe exercises uses what you learned in Lab 7 and its exercises. But don’t worry too much, the setup steps will be given here as well.\n\n\n\nHow to work with an R package\nThere are a few things to know when creating a package before you jump in. These are not strict rules, but they make your life easier when bug-fixing and make the package much easier to use for the users. To learn about those, click the foldout sections in the following topics. If you feel confident in the realm of R packages, feel free to skip ahead, but don’t leave your group too far behind.\n\nDependencies\n\n\nThe one strict rule is Never use library(“package”) within a package! \n\nInstead, add the packages your are going to use to the DESCRIPTION file and in the function descriptions. This is done by running usethis::use_package(\"packageName\") in the console and adding @import package (OK) or @importFrom package function1 function2 ... (Best). Using the functions in your package is then done with package::function() (e.g., dplyr::mutate()) or omitting the package::.\nThis way, it is easy to read what functions are from your package, and your package namespace does not get cluttered. Read more in the Namespace section.\nIt should also be a goal to make your package depend on as few other packages as possible. The user will need to install all packages your package depends on, but then also every package those depends on - that list quickly become quite long if you are not careful.\n\n\n\nFunctions\n\n\nA package is typically a collections of functions.\n\nThese functions are stored in .R files in the R folder. A good starting point is to create an .R file for each function. But, as the package becomes bigger, it often makes sense to combine related functions into bigger files.\nYou can quickly create a new .R file with usethis::use_r(\"function_name\"). Or do it manually, as you are used to.\n\n\n\nDocumenting functions\nTry running ?mean in the Console.\n\n\nIf you have every wondered how to write a manual like the one that pops up, please click here and read - if not, consider reading it anyway, as you will use it later.\n\nWhen you have made a function, or have at least defined one, you should describe what it does and how to use it. The manual you write for your function is the function documentation, and it should describe the purpose of the function and how to use it.\nYou can read extensively about it here, but I will give you the most essential information to get you started.\nThe R package roxygen2 makes this easy as 1-2-3. It is part of devtools and is already installed. It uses #' comments above the function. @ tags lets you add specific details to the function documentation.\nCreate an roxygen skeleton by clicking somewhere in your function. Go to the ‘Code’ tab in the top of your window and select ‘Insert Roxygen Skeleton’.\nThis will look something like this:\n\n#' Title\n#'\n#' @param foo \n#' @param bar \n#'\n#' @return\n#' @export\n#'\n#' @examples\nmyFunction <- function(foo, bar){\n  # Do stuff with foo and bar\n  foobar <- (foo * bar) / (foo + bar)\n  return(foobar)\n}\n\nThis allows you to add the most basic descriptions. To begin with, the Title, @param, and @export are the most important, you may remove the other tags for now. A more detailed example is given here. There, you can also read about documenting datasets and other object types - even the package itself.\n\n\n\nNamespace\n\n\nYour package namespace can quickly become very cluttered, if you are not careful.\n\nTherefore, follow these rules:\n\nOnly @export the functions the users will use. Removing the tag makes the function internal and hides it from your package namespace. It can still be freely used within your package and accessed outside your package with package:::internal_function()\nMake your code explicit with package::function().\n\nThis step is not mandatory, but makes reading the code easier.\n\nAdd your dependencies in the DESCRIPTION file with usethis::use_package(\"packageName\")\nOnly very rarely use the @import tag. Aim to use the @importFrom tags in your function descriptions instead.\n\nYou can read more extensively about namespace here.\n\n\n\nTesting\n\n\nTesting is essential\n\nto ensure your package runs smoothly and that no bugs are introduced when you make a seemingly minor change. It is handled with the testthat package, which is also installed with devtools.\nI will not go into too much detail here, but know that testing is an important, but often neglected, part of building a package. You can read more about it here.\nEvery time you run the usethis::use_r() function to create a new script, the function encourages you to create a test alongside the new function. I recommend you follow that advise.\nYou create a test by running usethis::use_test(\"function name\").\nThe function creates a new folder tests and creates a test script for the function. The good R package creator writes a few tests for every function.\nThe exercises will ask you to make a simple test for every function, introducing you to the concept.\n\n\n\nThe Package Workflow\nWhen creating a package, it is important to test your work along the way.\n\n\nYou can do that in many ways, but I recommend the following workflow:\n\n\nWrite a function / make a change\n\nIf it is a new function, document it\n\nSave your files: rstudioapi::documentSaveAll()\nCreate package documentation: devtools::document()\nLoad package: devtools::load_all()\nYour package is now loaded, and you can test that it works as intended.\n\nOptionally, you can save the three lines of code in dev/load.R and run the lines with source(\"dev/load.R\"). If you do, add the dev folder to the .Rbuildignore file.\n\n\n\n\n\nTASKS\nNow you know the basics of creating a package. And you are ready to begin.\n\nTask 1 - Setting up the R package\nIn the first task, one team member (you decide who) will initiate a package project and push it to Github. Then, when instructed, the remaining group members will connect to that repository, and the real package building will begin.\n\nTask 1.1 - Create R Package\n\nGo to R for Bio Data Science RStudio Cloud Server and login.\nClick Create a project in the top left and choose New Directory.\nSelect R Package and pick a fitting Package name.\n\nThe package you will create will replicate the central dogma of molecular biology. Let that inspire you\nLook up naming rules here\nThe most important rule: _, -, and ' are not allowed.\n\nClick “Create project”.\n\nRStudio will now create an R project for you that contains all necessary files and folders.\n\nOpen the DESCRIPTION file and write a title for your package, a small description, and add authors.\n\n\nWhen adding authors, the format is:\n\n\nAuthor@R:\n  c(person(given = \"firstname\",\n           family = \"lastname\",\n           role = c(\"aut\", \"cre\"), # There must be a \"cre\", but there can only be one\n           email = \"your@email.com\"), \n    person(given = \"firstname\",\n           family = \"lastname\",\n           role = \"aut\",\n           email = \"your@email.com\"))\n\n\nCreate an MIT license usethis::use_mit_license(\"Group name\")\n\n\nOptional setup steps (generally good, but not essential for this course)\n\n\n\nIf the “Git” tab is not in the lower left panel:\n\n\n\nRun usethis::use_git() and reopen the project to have it appear\n\n\nTo use GitHub, you create an empty repository there and link the account with gert::git_remote_add(\"link\") and gert::git_push(\"origin\")\n\n\ngit push will now push your committed changes to the GitHub repository\n\n\n\nAdd a lifecycle badge: usethis::use_lifecycle_badge( \"Experimental\" )\n\n\nWrite vignettes: usethis::use_vignette(\"Vignette name\")\n\n\nAdd a Readme file usethis::use_readme_rmd( open = FALSE ). You will do that in the Group Assignment later\n\n\n\n\n\n\nTask 1.2 - Setup GitHub Repository for your group’s R package\nStill only the first team member\n\nGo to https://github.com/rforbiodatascience22\nClick the green New-button\nCreate a new repository called group_X_package. Remember to replace the X\nSelect rforbiodatascience22 as owner\nMake the repository Public\nClick the green Create repository-button\nIn this new repository, click the settings tab\nClick Collaborators and Team\nClick the green Add people-button\nInvite the remaining group members\nAll other team members should now have access to the repository, but do not create your own project yet.\n\n\n\nTask 1.3 - Connect your RStudio Server Project to the GitHub Repository\nStill only the first team member\n\nFind your PAT key or create a new\n\n\nHow to create a new one\n\n\n\nType in the console usethis::create_github_token(). You’re going to be redirected to GitHub website.\n\nIn case you did that step manually, remember to give permission to access your repositories.\n\nYou need to type your password. Don’t change the default settings of creating the token except for the description – set ‘RStudio Cloud’ or something similar. Then hit Generate token.\n\nCopy the generated token (should start with ghp_) and store it securely (e.g., in a password manager). Do not keep it in a plain file.\n\n\nGo back to the RStudio Server project\nType in the console gitcreds::gitcreds_set() and paste the PAT key\nStage all files (in the git window in the top right) by ticking all boxes under Staged\nStill in the console, run the following commands. Replace your group number and use your GitHub username and email. You run these to link your project to the GitHub repository you created. Remember to replace the X.\n\n\nusethis::use_git_remote(name = \"origin\", \"https://github.com/rforbiodatascience22/group_X_package.git\", overwrite = TRUE)\nusethis::use_git_config(user.name = \"USERNAME\", user.email = \"USEREMAIL@EXAMPLE.ORG\")\ngert::git_commit_all(\"Package setup\")\ngert::git_push(\"origin\")\n\nAll other team members\nAfter your teammate has pushed to GitHub.\n\nIn the RStudio Server, create a new project based on the GitHub Repository just created by your teammate.\n\nClick Create a project in the top left.\nChoose Version Control and then Git.\nPaste in the repository URL: \"https://github.com/rforbiodatascience22/group_X_package.git\". Remember to replace the X.\nGive the directory a fitting name and click Create Project.\n\nFind your PAT key or create a new\n\n\nHow to create a new one\n\n\n\nType in the console usethis::create_github_token(). You’re going to be redirected to GitHub website.\n\nIn case you did it manually, remember to give permission to access your repositories.\n\nYou need to type your password. Don’t change the default settings of creating the token except for the description – set ‘RStudio Cloud’ or something similar. Then hit Generate token.\n\nCopy the generated token (should start with ghp_) and store it securely (e.g. in password manager). Do not keep it in a plain file.\n\n\nGo back to the RStudio Server project\nType in the console gitcreds::gitcreds_set() and paste the PAT key\nStill in the console, run the following commands. Replace your GitHub username and email.\n\n\nusethis::use_git_config(user.name = \"USERNAME\", user.email = \"USEREMAIL@EXAMPLE.ORG\")\n\nIf RStudio at any point asks you to log in to GitHub, redo step 4 and 5.\nNow you are ready to work on the R package.\n\n\n\nTask 2 - Build the package\n\nEach team member should build and implement their own function. The code will be given, but you will be asked to come up with a name for your function and many of the variables, so discuss in the team what naming convention you want to use. Do you want to use snake_case (common in tidyverse) or camelCase (common in Bioconductor)? It doesn’t really matter, but try to be consistent.\n\n\nTask 2.1 - Incorporate data\nIn this task you will include the following codon table in your package.\nThis task should be done by one team member. The rest should follow along.\n\nBelow is a standard codon table. Store it in an object with a name of your own choosing.\n\n\nc(\"UUU\" = \"F\", \"UCU\" = \"S\", \"UAU\" = \"Y\", \"UGU\" = \"C\",\n  \"UUC\" = \"F\", \"UCC\" = \"S\", \"UAC\" = \"Y\", \"UGC\" = \"C\",\n  \"UUA\" = \"L\", \"UCA\" = \"S\", \"UAA\" = \"_\", \"UGA\" = \"_\",\n  \"UUG\" = \"L\", \"UCG\" = \"S\", \"UAG\" = \"_\", \"UGG\" = \"W\",\n  \"CUU\" = \"L\", \"CCU\" = \"P\", \"CAU\" = \"H\", \"CGU\" = \"R\",\n  \"CUC\" = \"L\", \"CCC\" = \"P\", \"CAC\" = \"H\", \"CGC\" = \"R\",\n  \"CUA\" = \"L\", \"CCA\" = \"P\", \"CAA\" = \"Q\", \"CGA\" = \"R\",\n  \"CUG\" = \"L\", \"CCG\" = \"P\", \"CAG\" = \"Q\", \"CGG\" = \"R\",\n  \"AUU\" = \"I\", \"ACU\" = \"T\", \"AAU\" = \"N\", \"AGU\" = \"S\",\n  \"AUC\" = \"I\", \"ACC\" = \"T\", \"AAC\" = \"N\", \"AGC\" = \"S\",\n  \"AUA\" = \"I\", \"ACA\" = \"T\", \"AAA\" = \"K\", \"AGA\" = \"R\",\n  \"AUG\" = \"M\", \"ACG\" = \"T\", \"AAG\" = \"K\", \"AGG\" = \"R\",\n  \"GUU\" = \"V\", \"GCU\" = \"A\", \"GAU\" = \"D\", \"GGU\" = \"G\",\n  \"GUC\" = \"V\", \"GCC\" = \"A\", \"GAC\" = \"D\", \"GGC\" = \"G\",\n  \"GUA\" = \"V\", \"GCA\" = \"A\", \"GAA\" = \"E\", \"GGA\" = \"G\",\n  \"GUG\" = \"V\", \"GCG\" = \"A\", \"GAG\" = \"E\", \"GGG\" = \"G\")\n\n\nRun usethis::use_data(name_of_object, overwrite = TRUE, internal = TRUE)\nYou have now made the data available to our functions, but we also want to make it visible for our users.\n\nRun usethis::use_data(name_of_object, overwrite = TRUE).\n\nWrite a data manual (document the data).\n\nAll non-internal data should be documented in a data.R file in the R folder. Create it with usethis::use_r(\"data\")\nAdd the following scaffold and write a very brief description of the data (see an example here). Don’t spend a lot of time here.\n\n\n\n#' Title\n#' \n#' Description\n#' \n#' \n#' @source \\url{https://www.ncbi.nlm.nih.gov/Taxonomy/Utils/wprintgc.cgi?chapter=tgencodes#SG1}\n\"name_of_object\"\n\nNormally, you should also describe how the raw data was cleaned. You would do that in the file that opens after running usethis::use_data_raw( name = \"name_of_object\", open = TRUE ), but that is less relevant here, so we will skip that part.\nYour package now includes some data.\nRestart R, clean your Environment (small broom in the Environment tab), run the three lines of code from The Package Workflow section, and run ?name_of_object. Your manual should pop up. Try printing the object as well to see what it looks like print(name_of_object).\nPush your changes to GitHub. The other team members pull the changes to have the data available to you as well.\n\n\n\nTask 2.2 - Implement functions\nIn this task you will be working individually to implement a function each. If you are fewer in the team than the number of functions. The quickest to finish can implement the remaining, or separate them out as you see fit.\nIf you want an additional challenge, each team member can create their own Git branch gert::git_branch_checkout(\"branch_name\") and work there. When done, merge your branch with the main branch. That is a more clean and ‘proper’ workflow, but completely optional.\nIf you are in doubt what the underlying functions do, run ?function_name to get a hint about their purpose. Also, remember the functions are replicating the central dogma. Let that inspire you, when naming the functions and variables. If you get stuck, ask your teammates about their functions.\nFunction five is a bit more involved. Do it together or help your teammate out if it causes problems.\nFor each function, complete the following steps:\n\nLook carefully at your function. Choose a fitting name for it\nRun usethis::use_r(\"function_name\") to create an .R file for the function\nPaste in the function and rename all places it says name_me with fitting names\nClick somewhere in the function. In the toolbar at the very top of the page, choose Code and click Insert Roxygen Skeleton\nFill out the function documentation\n\nGive the function a title\nDo not write anything after @export\nThe parameters should have the format: @param param_name description of parameter\nThe return has the format: @return description of function output\nExamples can span multiple lines and what you write will be run.\nImportant! Either fill out everything or delete what you don’t describe. Otherwise, the package check will fail (Do not delete @export for these functions).\n\nRun the three lines of codes from The Package Workflow section\n\n\nrstudioapi::documentSaveAll()  # Saves all you files\ndevtools::document()  # Writes all your manuals for you\ndevtools::load_all()  # Simulates library(\"your package\"), allowing you to use your functions\n\n\nView your function documentation with ?function_name\nDefining a test or a series of tests around your newly created function ensures future corrections will not yield undesired results. Create such a test for your function. Run usethis::use_test(\"function_name\") and write a test. Draw some inspiration from here or from running ?testthat::expect_equal.\n\nSkip this step for function five. Instead, write inline code comments for each chunk of code. Press Cmd+Shift+c / Ctrl+Shift+C to comment your currently selected line.\n\nRerun the three lines from The Package Workflow section and check that the package works with devtools::check()\n\n\n\nBriefly about check\n\ndevtools::check() will check every aspect of your package and run the tests you created. You will likely get some warnings or notes like ‘No visible binding for global variables’. They are often harmless, but, if you like, you can get rid of them as described here. The check will tell you what might cause problems with your package and often also how to fix it. If there are any errors, fix those. Warnings and notes are also good to address. Feel free to do that if any pops up.\n\n\nIf it succeeds without errors, push your changes to GitHub\n\nUse the RStudio GUI if you prefer\nRemember to pull first\nIf you chose to create your own branch, merge it with master/main.\n\n\n\n\nFunction one\n\n\nname_me1 <- function(name_me2){\n  name_me3 <- sample(c(\"A\", \"T\", \"G\", \"C\"), size = name_me2, replace = TRUE)\n  name_me4 <- paste0(name_me3, collapse = \"\")\n  return(name_me4)\n}\n\n\n\n\nFunction two\n\n\nname_me1 <- function(name_me2){\n  name_me3 <- gsub(\"T\", \"U\", name_me2)\n  return(name_me3)\n}\n\n\n\n\nFunction three\n\n\nname_me1 <- function(name_me2, start = 1){\n  name_me3 <- nchar(name_me2)\n  codons <- substring(name_me2,\n                      first = seq(from = start, to = name_me3-3+1, by = 3),\n                      last = seq(from = 3+start-1, to = name_me3, by = 3))\n  return(codons)\n}\n\n\n\n\nFunction four\n\nname_of_your_object refers to the codon table you stored in Task 2.\n\nname_me <- function(codons){\n  name_me2 <- paste0(name_of_your_object[codons], collapse = \"\")\n  return(name_me2)\n}\n\n\n\n\nFunction five\n\nThis function will be the first to use dependencies. As a reminder, a dependency is a package that your package depends on. In this case, it will be magrittr, stringr, and ggplot2. They are already installed, so you don’t need to do that. The best way to add these packages to your own is to first add them to your package dependencies with usethis::use_package(\"package_name\"). Do that with all three.\nFor magrittr it is a good idea to add the Tidyverse pipe %>% to your package namespace. When writing your function documentation, add a line with @importFrom magrittr %>%. For the ggplot2 functions, we will use ggplot2::function_name everywhere a ggplot2 function is used. Also add @import ggplot2 to the function description. The same applies for stringr, but since we only use a few functions, add @importFrom stringr str_split boundary str_count to the function description.\n\nname_me1 <- function(name_me2){\n  name_me3 <- name_me2 |>  \n    stringr::str_split(pattern = stringr::boundary(\"character\"), simplify = TRUE) %>%\n    as.character() |> \n    unique()\n  \n  counts <- sapply(name_me3, function(amino_acid) stringr::str_count(string = name_me2, pattern =  amino_acid)) |>  \n    as.data.frame()\n  \n  colnames(counts) <- c(\"Counts\")\n  counts[[\"Name_me2\"]] <- rownames(counts)\n  \n  name_me4 <- counts |>  \n    ggplot2::ggplot(ggplot2::aes(x = Name_me2, y = Counts, fill = Name_me2)) +\n    ggplot2::geom_col() +\n    ggplot2::theme_bw() +\n    ggplot2::theme(legend.position = \"none\")\n  \n  return(name_me4)\n}\n\n\n\n\n\n\nTask 3 - Group discussion\n\nDescribe each function to each other in order - both what it does and which names you gave them and their variables.\nThe person(s) responsible for function five, describe how you added the three packages as dependencies and included the pipe in the package namespace.\nDiscuss why it is a good idea to limit the number of dependencies your package has. When can’t it be avoided?\nDiscuss the difference between adding an @importFrom package function tag to a function description compared to using package::function(). Read this section if you are not sure or just want to learn more.\n\n\n\n\nGROUP ASSIGNMENT\n\nFor this week’s group assignment, write a vignette (user guide) for your package (max 2 pages). The vignette should include a brief description of what the package is about and demonstrate how each function in the package is used (individually and in conjunction with each other). As a final section, discuss use cases for the package and what other functions could be included. Also include the main points from your discussion in Task 3.\nInclude a link to your group’s GitHub repository at the top of the vignette. Hand it in as a pdf in DTU Learn, as you did the previous weeks.\n\nCreate a vignette with usethis::use_vignette(\"package name\").\nWhen you are done writing it, run devtools::build_vignettes().\nAt the top line of your vignette, change rmarkdown::html_vignette to rmarkdown::pdf_document\nRerun devtools::build_vignettes() - the created pdf-file in the doc-folder is the document to hand it.\nLastly, duplicate the vignette as the GitHub README\n\nCreate a README with usethis::use_readme_rmd( open = TRUE ).\nCopy the content of the vignette Rmarkdown into the readme Keep the top part of the README as is. If you overwrote it anyway, change rmarkdown::pdf_document to rmarkdown::github_document.\nRun devtools::build_readme()\nPush the changes to GitHub\n\n\n\n\nLast tip on packages\n\nNext week, I will introduce the golem package for building production-grade Shiny apps. However, I personally also use it to quickly get going with packages.\nWhen starting out with an R package, it may seem complicated with a lot of things to remember. golem remembers these things for you. When setting up your package / Shiny app with golem::create_golem(\"Your awesome package/app name\"), it creates a dev folder with a few files listing all you need to get started with an R package.\nIt does also give you a lot of other things that you will rarely use, and it also sets up some basic structures for Shiny apps. These can simply be deleted if you are not also building a Shiny app."
  },
  {
    "objectID": "lab09.html#packages",
    "href": "lab09.html#packages",
    "title": "Lab 9 Creating a Simple Shiny Application",
    "section": "Package(s)",
    "text": "Package(s)\n\nshiny\ngolem"
  },
  {
    "objectID": "lab09.html#schedule",
    "href": "lab09.html#schedule",
    "title": "Lab 9 Creating a Simple Shiny Application",
    "section": "Schedule",
    "text": "Schedule\n\n08.00 - 08.15: Recap of exercises from last lab\n08.15 - 08.30: Assignment walk-through\n08.30 - 09.00: Slides\n09.00 - 09.15: Break\n09.00 - 12.00: Exercises"
  },
  {
    "objectID": "lab09.html#learning-materials",
    "href": "lab09.html#learning-materials",
    "title": "Lab 9 Creating a Simple Shiny Application",
    "section": "Learning Materials",
    "text": "Learning Materials\nPlease prepare the following materials\n\nBook: Mastering Shiny by Hadley Wickham – Read Chapter 1 (Chapter 2 and 3 are good to read as well, if you want).\nBook: Engineering Production-Grade Shiny Apps – Read Chapter 2 - 5 (they are fairly short, but if you don’t find Shiny Apps super cool, feel free to skip Chapter 3 and 5 and Sections 2.2.2 and 4.2.3 - 4.2.4), the rest are quite important for the exercises.\nCheatsheet: Shiny – This cheatsheet is a bit cluttered, but useful\nCheatsheet: Golem – Look through this after reading the chapters in “Engineering Production-Grade Shiny Apps” - the exercises will remind you to look at the cheatsheet as well.\n\nNote: The following are suggested learning materials, i.e., do not go over everything, but poke around. You will use these materials as a point of reference for the group exercises\n\nShiny Input Gallery\nWeb: Shiny from RStudio\nWeb: RStudio tutorials on Shiny\nVideo: Playlist: Web Apps in R: Building your First Web Application in R | Shiny Tutorial\nExample: nnvizRt\nMore inspiration: Shiny Gallery"
  },
  {
    "objectID": "lab09.html#learning-objectives",
    "href": "lab09.html#learning-objectives",
    "title": "Lab 9 Creating a Simple Shiny Application",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nA student who has met the objectives of the session will be able to:\n\nPrepare a simple shiny application\nUsing relevant online ressources to autonomously identify and obtain new and expand on existing knowledge of R"
  },
  {
    "objectID": "lab10.html#schedule",
    "href": "lab10.html#schedule",
    "title": "Lab 10 Project Startup & Industry Talks",
    "section": "Schedule",
    "text": "Schedule\n\n08.00 - 08.15: Recap and Assignment\n08.15 - 08.45: Introduction to Project Period and Exam\n08.45 - 09.00: Break\n09.00 - 10.00: Mini Symposium (See below)"
  },
  {
    "objectID": "lab10.html#mini-symposium-applications-of-r-for-bio-data-science-in-industry",
    "href": "lab10.html#mini-symposium-applications-of-r-for-bio-data-science-in-industry",
    "title": "Lab 10 Project Startup & Industry Talks",
    "section": "Mini Symposium: Applications of R for Bio Data Science in Industry",
    "text": "Mini Symposium: Applications of R for Bio Data Science in Industry\nThis mini symposium on Applications of R for Bio Data Science in Industry aims to give students a glimpse into how modern data science is transforming value creation in the pharmaceutical industry and healthcare sector.\n\n2023\n\nCompanies Represented\n\nTBA\n\n\n\nSpeaker List\n\nTBA\n\n\n\n\n2022\n\nCompanies Represented\n\nAbzu\nBristol Myers Squibb\nClinical Microbiomics\nNovo Nordisk Bioinformatics\nNovo Nordisk Biostatistics\nSteno Diabetes Center Copenhagen\n\n\n\nSpeaker List\n\nAndrea Marquard, Head of Data Science and Automation, Clinical Microbiomics: “How we use internal R packages, and why you should learn to make one”\nAnders Gorst-Rasmussen, Statistical Director, Novo Nordisk Biostatistics, Novo Nordisk: “How we use R in Novo Nordisk Biostatistics”\nAnne-Mette Bjerregaard, Senior Scientist in Computational Biology, Novo Nordisk: “The Evolution of a Computational Biologist”\nSam Demharter, Bioinformatics Specialist, Abzu: “Explainable AI in Precision Medicine - Closing the Loop from Patient to Drug”\nLykke Pedersen, Head of RNA Therapeutics, Abzu: “Explainable AI in Precision Medicine - Closing the Loop from Patient to Drug”\nSimon Papillon-Cavanagh, Principal Scientist, Bristol Myers Squibb (USA): “A Career Built on Mistakes”\nSofie Olund Villumsen, Bioinformatician, Steno Diabetes Center Copenhagen: “Using R for Data Analysis in Clinical Studies”\nTarun Veer Singh Ahluwalia, Assoc. Prof., Steno Diabetes Center Copenhagen: “Using R for Data Analysis in Clinical Studies”\n\n\n\n\n2021\n\nCompanies Represented\n\nAbzu\nALK\nChr. Hansen\nLundbeck\nNovozymes\nTeraData\n\n\n\nSpeaker List\n\nSamuel Demharter, Senior Bioinformatician, Abzu\nLykke Pedersen, Senior Bioinformatician, Abzu\nMarie-Catherine Le Bihan, Senior Data Scientist, Chr. Hansen\nThomas Strantzl, Head of Bioinformatics, ALK\nMaria Dalby, Postdoctoral Researcher, Lundbeck\nThomas Poulsen, Science Manager, Novozymes\nMikkel Freltoft Krogsholm, Team lead, Senior Data Scientist, TeraData"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "Various resources pertaining to the course"
  },
  {
    "objectID": "paths_and_projects.html",
    "href": "paths_and_projects.html",
    "title": "Paths & Projects",
    "section": "",
    "text": "You step onto the road, and if you don’t keep your feet, there’s no knowing where you might be swept off to\nIn context of R, a path is a way to tell R, where to look for a file. First, let us familiarise us a bit with paths in RStudio."
  },
  {
    "objectID": "paths_and_projects.html#getting-familiar-with-paths-in-rstudio",
    "href": "paths_and_projects.html#getting-familiar-with-paths-in-rstudio",
    "title": "Paths & Projects",
    "section": "Getting Familiar with Paths in RStudio",
    "text": "Getting Familiar with Paths in RStudio\nLog on to the RStudio Cloud Server and in case you do so for the first time, your files-pane should look something like:\n Here,  Home defines your home, that is where you “live” on the server. Now, click the button  New Folder and create a new folder called projects. Hereafter, your files-pane should look something like:\n\nNow, click the projects folder you created and then you should see:\n\nNote how the Home now is extended to  Home > projects. This signifies, that you are looking at the projects folder in your home.\nTry to click on the 2 dots in .. (the green arrow won’t do it, so hit those dots!), this will take you one level up, so you again see:\n\nNote, that you are now back in  Home"
  },
  {
    "objectID": "paths_and_projects.html#intermezzo-creating-a-project",
    "href": "paths_and_projects.html#intermezzo-creating-a-project",
    "title": "Paths & Projects",
    "section": "Intermezzo: Creating a Project",
    "text": "Intermezzo: Creating a Project\nOk, so far so good. Now again click into projects and click  Project: (None) and from here select  New Project.... Now you will se a dialogue window open, i.e. RStudio requires input from you:\n\nClick  New Directory and you should see:\n\nClick  New Project:\n\nIn the Directory name:, enter e.g. r_for_bio_data_science and note how we are creating the folder (In this case Directory name, which is equivalent) as a sub-folder of projects. The funny wavy symbol followed by a slash ~/ is simply a short hand for “in this users home folder”. So let us proceed:\n\nand then click Create Project. Now, depending on your choice of directory name, you should see:\n\nBriefly, the created r_for_bio_data_science.Rproj file contains the settings for your project. You can verify this, by clicking on the file and you should see:\n\nWe will leave this as is for now, so go ahead and click OK.\nNow, back to folders and paths - note how you now see  Home > projects > r_for_bio_data_science, this means that you are now in the r_for_bio_data_science folder, which is inside the projects folder which in turn is inside the Home folder. If you take a look at the  Home > projects > r_for_bio_data_science, you can in fact also click directly on e.g. projects - Try it!\nBut why? Don’t worry, we will return to why RStudio Projects are indispensable when working with reproducible Bio Data Science"
  },
  {
    "objectID": "paths_and_projects.html#locating-data",
    "href": "paths_and_projects.html#locating-data",
    "title": "Paths & Projects",
    "section": "Locating Data",
    "text": "Locating Data\nLet’s move on. Now, again click the  New Folder-button and create a data-folder, make sure it ends up in the r_for_bio_data_science-folder. This should result in:\n\nNote here how we now have  data and  r_for_bio_data_science.Rproj. These are different, one is a folder, data, and the other is a file, r_for_bio_data_science.Rproj, containing settings for your RStudio Project.\nLet us try to put som data into the data-folder. In the console window, run the following command\n\nwrite.table(x = datasets::Puromycin, file = \"data/puromycin.tsv\", sep = \"\\t\")\n\nThis should look like so:\n\nThis command write a table containing the Puromycin from an R-package named datasets, this is done using the x-parameter. The next paramter is file and we set that to indicate, that the file should go into the data-folder we created and that we would like the file to be named puromycin.tsv, where tsv is an abbreviation for tab-separated-values and then the last parameter sep is set to \"\\t\" indicating, that we want the values to be separated by a tab, as indicated, when we named the file.\nOnce you have run the command, click the data-folder and you should now see:\n\nAgain, click .., this will take you one level up, so you again see:\n\nNow, we have a data file called puromycin.tsv. Let us read that file into R. We can do that like so:\n\nmy_data <- read.table(file = \"puromycin.tsv\")\n\nEnter the command into the console and run it like we did before. You will now see the following:\n\nSo, what happend? The blue writing is your command and the red is an error message from R. Always read error messages carefully, they will inform you what went wrong. In this case, we can see that cannot open file 'puromycin.tsv': No such file or directory.\nThis happened because we forgot to specify where the puromycin.tsv-file is located. R is very picky here, you have to specify exactly where R should find things. Recall, that we decided to create a data-folder and that we placed the puromycin.tsv-file into that folder. This we have to specify, when we use the file parameter in the read.table()-function. So, let us fix that:\n\nmy_data <- read.table(file = \"data/puromycin.tsv\")\n\nThis data/puromycin.tsv is the path to the file and now, that we have got that correct, you will see no error message and furthermore, you will see in the environment-pane, that we now have an object called my_data, containing 23 obs. of 3 varibles, i.e. a data set with 23 rows and 3 columns."
  },
  {
    "objectID": "paths_and_projects.html#absolute-versus-relative-paths",
    "href": "paths_and_projects.html#absolute-versus-relative-paths",
    "title": "Paths & Projects",
    "section": "Absolute versus Relative Paths",
    "text": "Absolute versus Relative Paths\nLet us get back to why we have to work using RStudio Projects, recall we created the r_for_bio_data_science.Rproj-file, defining out project. You can verify, that we are indeed working in that project, by looking in the upper right corner of the RStudio IDE and you should see  r_for_bio_data_science.\nGood, now in the console, enter the command:\n\ngetwd()\n\nYou should see something along the lines of:\n\n\"/net/pupilx/home/people/student_id/projects/r_for_bio_data_science\"\n\nSo, when we read the puromycin.tsv-file using the path data/puromycin.tsv, we specify, that R should look for the file puromycin.tsv in the data folder. So why did we not have to specify /net/pupilx/home/people/student_id/projects/r_for_bio_data_science? Well indeed, we could have specified the full location of the puromycin.tsv-file, which would be:\n\n\"/net/pupilx/home/people/student_id/projects/r_for_bio_data_science/data/puromycin.tsv\"\n\nThis is called the absolute path and here you should note, that it begins with a /. But let us say, that we had indeed in our code stated:\n\nmy_data <- read.table(file = \"/net/pupilx/home/people/student_id/projects/r_for_bio_data_science/data/puromycin.tsv\")\n\nThen that would work… On OUR computer. If we were to share our code to a colleague or a collaborator, then that would not work, because that person would have a different path, e.g. a different student_id. The code would break! Imagine that you have thousands of line of code with hundreds of absolute paths - You would spend hours-and-hours on fixing all the absolute paths, so they matched that particular computer. Then every time we would want to share the analysis project, we would have to redo this tedious proces!\nThis is why we work in RStudio Projects! RStudio Projects allows us to specifiy where everything is located relative to where the .Rproj-file is. So in our case, the r_for_bio_data_science.Rproj-file is located in the same place as the data-folder, namely in the folder containing our entire project, the r_for_bio_data_science-folder, which in turn is located in the projects-folder.\nThis means, that all paths in the analysis project, can be stated relative to the location of the .Rproj-file and hence we have relative paths, meaning that anyone can receive the project and run it straight-out-of-the-box!"
  },
  {
    "objectID": "paths_and_projects.html#working-in-multiple-projects",
    "href": "paths_and_projects.html#working-in-multiple-projects",
    "title": "Paths & Projects",
    "section": "Working in Multiple Projects",
    "text": "Working in Multiple Projects\nNow, we did add that plural s, when we created the projects-folder. When you have completed this course, perhaps you want to attend the “Introduction to Systems Biology”-course. In that case, we would setup a new project, so use the Files-pane to navigate to the projects-folder:\n\nThen, we simply repeat the proces: Click  r_for_bio_data_science in the upper right corner and from here select  New Project.... Now you will se a dialogue window open, i.e. RStudio requires input from you:\n\nClick  New Directory and you should see:\n\nClick  New Project:\n\nIn the Directory name:, enter e.g. introduction_to_systems_biology:\n\nand then click Create Project. Now, you should see:\n\nNow, note how you now see  Home > projects > introduction_to_systems_biology, meaning that you are now in your Home and then in your folder containing projects, one of which is your introduction_to_systems_biology project.\nClick .. and you will see:\n\nThis is now your two project folders and you can add others, such as yet another course or e.g. special_course, bachelor_thesis or master_thesis.\nNow, we can easily switch between different projects. In the upper right corner you will see, that you are currently in the introduction_to_systems_biology project, meaning that R will look for all files relative to the introduction_to_systems_biology.Rproj-file. Naturally, we would want to switch back to the project, we created for the “R for Bio Data Science”-course. To do this, we simply click  introduction_to_systems_biology and if you look at the drop-down menu, you should see r_for_bio_data_science - Click it! Notice how R automatically restarts and you are moved to the correct folder for this project."
  },
  {
    "objectID": "paths_and_projects.html#learning-objectives",
    "href": "paths_and_projects.html#learning-objectives",
    "title": "Paths & Projects",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nIf you made it this far, you should now be able to:\n\nNavigate the RStudio IDE in context of folders and projects\nCreate a new project\nCreate a new folder\nRead and write data files from relative paths\nWork in and switch between different projects\nExplain the difference between a folder, a data file and a Rproj-file\nExplain the difference between absolute and relative paths\nExplain why RStudio Projects are an essential part of doing reproducible bio data science"
  },
  {
    "objectID": "paths_and_projects.html#epilogue",
    "href": "paths_and_projects.html#epilogue",
    "title": "Paths & Projects",
    "section": "Epilogue",
    "text": "Epilogue\nThat’s all folks! I hope this cleared up some things - Please feel free to revisit this chapter, as needed!\nRemember - Have fun! No one ever got really good at something they didn’t think was fun!"
  },
  {
    "objectID": "variable_assignment_in_r.html",
    "href": "variable_assignment_in_r.html",
    "title": "Variable Assignment in R",
    "section": "",
    "text": "In R we operate with variables. A variable can be seen as a container for a value. To get a better conceptual understanding of this, you can go through the following and code-along in your own R-session."
  },
  {
    "objectID": "variable_assignment_in_r.html#assigning-a-value-to-a-variable",
    "href": "variable_assignment_in_r.html#assigning-a-value-to-a-variable",
    "title": "Variable Assignment in R",
    "section": "Assigning a Value to a Variable",
    "text": "Assigning a Value to a Variable\n\nIn R, we state values directly in the chunk or the console, e.g.:\n\n\n3\n\n[1] 3\n\n\n\nHere, we just state 3, so R simply “throws” that right back at you!\nNow, if want to “catch” that 3 we have to assign it to a variable, e.g.:\n\n\nx <- 3\n\n\nNotice how now we “catch” the 3 and nothing is “thrown” back to you, because we now have the 3 stored in x:\n\n\nx\n\n[1] 3"
  },
  {
    "objectID": "variable_assignment_in_r.html#updating-the-value-of-a-variable",
    "href": "variable_assignment_in_r.html#updating-the-value-of-a-variable",
    "title": "Variable Assignment in R",
    "section": "Updating the Value of a Variable",
    "text": "Updating the Value of a Variable\n\nNow, we can of course use x moving forward, e.g. by adding 2:\n\n\nx + 2\n\n[1] 5\n\n\n\nNotice how this does not change x and the result is simply “thrown” right-back-at-ya\n\n\nx\n\n[1] 3\n\n\n\nIf we wanted to update x by adding 2, we would have to “catch” the result as before:\n\n\nx <- x + 2\n\n\nNow, we have updated x:\n\n\nx\n\n[1] 5"
  },
  {
    "objectID": "variable_assignment_in_r.html#use-one-variable-in-the-creation-of-another",
    "href": "variable_assignment_in_r.html#use-one-variable-in-the-creation-of-another",
    "title": "Variable Assignment in R",
    "section": "Use one Variable in the Creation of Another",
    "text": "Use one Variable in the Creation of Another\n\nAnalogue, we can create a new variable using x:\n\n\ny <- x + 3\n\n\nAgain, this does not change x\n\n\nx\n\n[1] 5\n\n\n\nBut rather the result is now stored in y\n\n\ny\n\n[1] 8"
  },
  {
    "objectID": "variable_assignment_in_r.html#summary",
    "href": "variable_assignment_in_r.html#summary",
    "title": "Variable Assignment in R",
    "section": "Summary",
    "text": "Summary\n\nIn R, we use the assignment operator <- to perform assignment\nVariables are not change in place, but needs to be stored\nNote, this also applies to running e.g. a dplyr-pipeline, where we do not change the dataset by running the pipeline, but we must store the result of the pipeline\n\nBefore continuing, make sure that you are on track with the above concepts!\n\nCreate a new variable my_age containing… You guessed it!\nAdd 0.5 to the variable (I.e. your age, when you’re done with this course)\nCheck the value of my_age, did you remember to assign, thereby updating?"
  },
  {
    "objectID": "variable_assignment_in_r.html#pipeline-example",
    "href": "variable_assignment_in_r.html#pipeline-example",
    "title": "Variable Assignment in R",
    "section": "Pipeline Example",
    "text": "Pipeline Example\n\n\n\n\nLet us create some example sequence data:\n\n\ntibble(sequence = c(\"aggtgtgag\", \"tggaatgaaccgcctacc\",\n                    \"aagaatgga\", \"tct\", \"tgtatt\", \"tgg\",\n                    \"accttcaacgagtcccactgt\", \"cgt\",\n                    \"gaggctgagctggttgta\", \"ggggaacag\"))\n\n# A tibble: 10 × 1\n   sequence             \n   <chr>                \n 1 aggtgtgag            \n 2 tggaatgaaccgcctacc   \n 3 aagaatgga            \n 4 tct                  \n 5 tgtatt               \n 6 tgg                  \n 7 accttcaacgagtcccactgt\n 8 cgt                  \n 9 gaggctgagctggttgta   \n10 ggggaacag            \n\n\n\nNotice, that our data creation is just “thrown” back at us, we forgot something!\n\n\nmy_dna_data <- tibble(sequence = c(\"aggtgtgag\", \"tggaatgaaccgcctacc\",\n                                   \"aagaatgga\", \"tct\", \"tgtatt\", \"tgg\",\n                                   \"accttcaacgagtcccactgt\", \"cgt\",\n                                   \"gaggctgagctggttgta\", \"ggggaacag\"))\n\n\nNow, we have stored the data in the variable my_dna_data\n\n\nmy_dna_data\n\n# A tibble: 10 × 1\n   sequence             \n   <chr>                \n 1 aggtgtgag            \n 2 tggaatgaaccgcctacc   \n 3 aagaatgga            \n 4 tct                  \n 5 tgtatt               \n 6 tgg                  \n 7 accttcaacgagtcccactgt\n 8 cgt                  \n 9 gaggctgagctggttgta   \n10 ggggaacag            \n\n\n\nNote here, that a variable can as we saw before with x and y store a single value, e.g. 2, but here, we are storing a tibble-object in the variable my_dna_data and in that tibble-object, we have a variable sequence, which contains some randomly generated dna.\nBut what if we wanted to add a new variable to the tibble-object, which is the lenght of each of the dna-sequences?\n\n\nmy_dna_data |>\n  mutate(dna_length = str_length(sequence))\n\n# A tibble: 10 × 2\n   sequence              dna_length\n   <chr>                      <int>\n 1 aggtgtgag                      9\n 2 tggaatgaaccgcctacc            18\n 3 aagaatgga                      9\n 4 tct                            3\n 5 tgtatt                         6\n 6 tgg                            3\n 7 accttcaacgagtcccactgt         21\n 8 cgt                            3\n 9 gaggctgagctggttgta            18\n10 ggggaacag                      9\n\n\nNice! Let’s see that data again then:\n\nmy_dna_data\n\n# A tibble: 10 × 1\n   sequence             \n   <chr>                \n 1 aggtgtgag            \n 2 tggaatgaaccgcctacc   \n 3 aagaatgga            \n 4 tct                  \n 5 tgtatt               \n 6 tgg                  \n 7 accttcaacgagtcccactgt\n 8 cgt                  \n 9 gaggctgagctggttgta   \n10 ggggaacag            \n\n\n\nWait! What? Where is the variable we literally just created?\nWe forgot something… We did not update the my_dna_data, let’s fix that:\n\n\nmy_dna_data <- my_dna_data |>\n  mutate(dna_length = str_length(sequence))\n\n\nNote, nothing is “trown” back at us! Let’s verify, that we did indeed update the my_dna_data:\n\n\nmy_dna_data\n\n# A tibble: 10 × 2\n   sequence              dna_length\n   <chr>                      <int>\n 1 aggtgtgag                      9\n 2 tggaatgaaccgcctacc            18\n 3 aagaatgga                      9\n 4 tct                            3\n 5 tgtatt                         6\n 6 tgg                            3\n 7 accttcaacgagtcccactgt         21\n 8 cgt                            3\n 9 gaggctgagctggttgta            18\n10 ggggaacag                      9\n\n\nDid it make sense? Check yourself, add a new variable to my_dna_data called sequence_capital by using the function str_to_upper()\nThat’s it - Hope it helped and remember… Bio data science in R is really fun!"
  },
  {
    "objectID": "code_styling.html",
    "href": "code_styling.html",
    "title": "Code Styling",
    "section": "",
    "text": "This is a condensed primer on code styling, based on The tidyverse style guide"
  },
  {
    "objectID": "code_styling.html#why",
    "href": "code_styling.html#why",
    "title": "Code Styling",
    "section": "Why?",
    "text": "Why?\n“Good coding style is like correct punctuation: you can manage without it, butitsuremakesthingseasiertoread” source\nIt is not uncommon in a bio data science industry setting, where there is an aspect of production code, i.e. the code you are writing is being used professionally by other users either in an organisation or as an actual software product, that you will have to adhere to a certain style, when coding. This facilitates lower maintanence on code. Imagine the case, where you are perhaps 10 bio data scientists working on e.g. an R-package, which will used downstream by another department. You really need to make sure, that everything is top notch, so you decide to do code reviewing. You write your code up and then your colleague will go over the code to check it. But you and your colleague have completely different opinions on how the code should be styled. This will result in an unnecessary time overhead. Another case, could be a colleague leaving for another position, where you then have to take over that colleague’s code base and you end up re-styling the code, so it matches your preferences, again this will increase maintenance unnecessarily. The solution is to agree on a set of rules and principles on how to style your code - This is code styling!\nBelow follows the code styling you will have to adhere to in this course"
  },
  {
    "objectID": "code_styling.html#so-how-should-we-style-the-code",
    "href": "code_styling.html#so-how-should-we-style-the-code",
    "title": "Code Styling",
    "section": "So, how should we style the code?",
    "text": "So, how should we style the code?\nIn this course, we will use principles from the The tidyverse style guide. At first, it may seem constraining, but you will quickly get used to it and then it will be easier moving forward. Note, for your project, being able to review consistant code, will save you valuable time!\nRecall the cancer_data (gravier) dataset, we worked with:\n\nlibrary(\"tidyverse\")\nlibrary(\"curl\")\nbase_url <- \"https://github.com/\"\ntarget_file <- \"ramhiser/datamicroarray/raw/master/data/gravier.RData\"\noutput_file <- \"data/gravier.RData\"\ncurl_download(url = str_c(base_url,\n                          target_file),\n              destfile = output_file)\n\nPrinciples:\n\nQuote the packages you load using the library-function\nUse the proper variable assignment in R, namely <-\nStay within 80 characters width. Note, you can set a “help line”: Tools \\(\\rightarrow\\) Global Options... \\(\\rightarrow\\) Code \\(\\rightarrow\\) Display \\(\\rightarrow\\) Show margin \\(\\rightarrow\\) Margin column: 80\nUse double quotes. This is for consistency with other languages\nTab out parameters of functions\nDo line breaks after commas\nDo one space on each side of =, when assigning arguments to parameters, e.g. my_function(parameter_1 = argument_1), etc.\nMatch indentations, this RStudio will do for you in most cases\n\nOk, a bit of data wrangling:\n\nload(file = \"data/gravier.RData\")\ncancer_data <- gravier |> \n  bind_cols() |> \n  rename(early_metastasis = y) |> \n  mutate(pt_id = str_c(\"pt_\", row_number()),\n         pt_has_early_metastasis = case_when(\n    early_metastasis == \"good\" ~ \"No\",\n    early_metastasis == \"poor\" ~ \"Yes\"))\n\nPrinciples:\n\nLine break after each pipe |>, recall we prononuce the pipe as “then”\nLine break after commas inside functions, such as here with mutate()\nIf the line in mutate() becomes wide, then consider using a single linebreak after opening the function call\nuse proper descriptive variable names in snake case like pt_has_early_metastasis, there is no overhead in understanding what this variable means\n\nLet’s do a simple plot:\n\ncancer_data |>\n  ggplot(aes(x = early_metastasis,\n             y = g8A08)) +\n  geom_hline(yintercept = 0,\n             linetype = \"dashed\") +\n  geom_boxplot() +\n  scale_y_continuous(limits = c(-0.5, 0.5)) +\n  theme_bw() +\n  labs(x = \"Early Metastasis\")\n\n\n\n\nPrinciples:\n\nLinebreak after +, just like with the pipe\nSpace after comma inside a vector, like when we define the limits\n\nDo it - It’ll be fun and it does not take a long time to adapt!"
  },
  {
    "objectID": "external_resources.html",
    "href": "external_resources.html",
    "title": "External Resources",
    "section": "",
    "text": "Here, you will find various valuable resources, to aid your bio data science workflow"
  },
  {
    "objectID": "external_resources.html#a-few-quick-ones",
    "href": "external_resources.html#a-few-quick-ones",
    "title": "External Resources",
    "section": "A few quick ones…",
    "text": "A few quick ones…\n\nA very handy ggplot cheat-sheet can be found here\nSo which plot to choose? Check this handy guide\nExplore ways of plotting here\nThere is a nice tool to aid in choosing colours for visualisations here\nThe Posit community pages is a very nice place to get help if you’re stuck"
  },
  {
    "objectID": "external_resources.html#open-source-data-science-books",
    "href": "external_resources.html#open-source-data-science-books",
    "title": "External Resources",
    "section": "Open source data science books",
    "text": "Open source data science books\n\nHands-On Programming with R by Garrett Grolemund\nStatistical Inference via Data Science - A moderndive into R and the tidyverse by Chester Ismay and Albert Y. Kim\nIntroduction to Data Science, Data Analysis and Prediction Algorithms with R by Rafael A. Irizarry\nMastering Shiny by Hadley Wickham\nAn Introduction to Statistical Learning with Applications in R by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani\nSTAT 545 - Data wrangling, exploration, and analysis with R by Jenny Bryan\nHappy Git and GitHub for the useR by Jenny Bryan, the STAT 545 TAs, Jim Hester"
  },
  {
    "objectID": "external_resources.html#software-links",
    "href": "external_resources.html#software-links",
    "title": "External Resources",
    "section": "Software Links",
    "text": "Software Links\n\nThe R Project for Statistical Computing\nRStudio - Open Source and Enterprise-ready professional software for R\nTidyverse website"
  },
  {
    "objectID": "external_resources.html#some-useful-links",
    "href": "external_resources.html#some-useful-links",
    "title": "External Resources",
    "section": "Some Useful Links",
    "text": "Some Useful Links\n\nFrom data to Viz: Find the graphic you need\nR for Data Science: Exercise Solutions\nR colour guide by Tian Zheng\nThe tidyverse style guide - By Hadley Wickham\nRStudio Primers - Learn data science basics with the interactive tutorials\nThe tidyverse style guide\nswirl - Learn R, in R\nRStudio Cheat Sheets\nRStudio Community - Stuck? Ask a question and get help moving on\nHarvardX Biomedical Data Science Open Online Training\nData Analysis Playlist"
  },
  {
    "objectID": "external_resources.html#on-data-science",
    "href": "external_resources.html#on-data-science",
    "title": "External Resources",
    "section": "On Data Science",
    "text": "On Data Science\n\nThe Role of Academia in Data Science Education"
  },
  {
    "objectID": "external_resources.html#guides-on-good-data-practices",
    "href": "external_resources.html#guides-on-good-data-practices",
    "title": "External Resources",
    "section": "Guides on Good Data Practices",
    "text": "Guides on Good Data Practices\n\nA Guide to Reproducible Code by the British Ecology Society\nA Quick Guide to Organizing Computational Biology Projects\nHow to pick more beautiful colors for your data visualizations\nTalk: Steps toward reproducible research by Karl Broman"
  },
  {
    "objectID": "course_elements.html",
    "href": "course_elements.html",
    "title": "Course Elements",
    "section": "",
    "text": "Various elements central to the course"
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignments",
    "section": "",
    "text": "As part of this course, starting from Lab 2, there will be a weekly hand in. Here, follows the instructions for creating and handing in course assignments."
  },
  {
    "objectID": "assignments.html#assignment-instructions",
    "href": "assignments.html#assignment-instructions",
    "title": "Assignments",
    "section": "Assignment Instructions",
    "text": "Assignment Instructions\nThe assignment will be marked “Group Assignment” with red font in the exercises. In your group, you are to prepare an answer to just this one question. Think about reproducibility from the get-go, so include in your assignment, what is needed to re-create your micro-report, e.g. if you’re using external data, from where and how did you get it? You will then receive group feedback on your assignment, which you should make sure to go over in your group.\nPlease note, that in order to include all elements in a self-contained html file, you will have to use the following YAML-header in your Quarto document:\n\n---\ntitle: \"Lab 2 Assignment: Group 02\"\nformat:\n  html:\n    embed-resources: true\neditor: visual\n---\n\nOr at least one similar, format title and other elements as you see fit, key here is the html-format with embedded resources."
  },
  {
    "objectID": "assignments.html#how-to-hand-in",
    "href": "assignments.html#how-to-hand-in",
    "title": "Assignments",
    "section": "How to hand in",
    "text": "How to hand in\n\nCheck that your assignment conforms to the assignment checklist, as defined in the next section\nGo to DTU Learn\nFind and click your R for Bio Data Science course\nMake sure you are enrolled in the correct group, as defined by the Group Formation Sheet (see the Getting Started Section)\nIn case groups consists of a mix of BSc. and MSc. students, then enroll under your respective courses\nOnly hand in one assignment, meaning either under the BSc. or the MSc. course, not both\nYou should hand in the rendered html-file, make sure to compress it to a zip-file prior to upload"
  },
  {
    "objectID": "assignments.html#assignment-checklist",
    "href": "assignments.html#assignment-checklist",
    "title": "Assignments",
    "section": "Assignment Checklist",
    "text": "Assignment Checklist\nDid you?\n\nMatch your group number with DTU Learn groups\nJust answer the one task marked as “Group Assignment”\nCreate the assignment using Quarto\nModify the YAML-header to ensure encapsulation\nInclude Group number, names and student ids\nUse proper markdown headers as defined by #, ##, ###\nWrite a few sentences under each section\nSeparate text clearly from code chunks\nFollow course code styling\nThink about reproducibility with respect to data and libraries?\nRender to html\nCompress the html-file to a zip-file, before upload to DTU Learn\nMake sure to download the upload’ed zip-file and check that everything looks right?"
  },
  {
    "objectID": "project_faq.html",
    "href": "project_faq.html",
    "title": "Project FAQ",
    "section": "",
    "text": "Where can I find data? Rethink the question: Discuss in your group what are your interests and then find data related to your problem, there are literally terabytes of publicly available data, i.e. don’t just google “data”, be specific\nIn order for you to demonstrate that you master the entire bio data science cycle, you must choose a bio data set, which requires cleaning and tidying\nIt would be good, if the data set requires joining, if not, consider artificially splitting it, to demonstrate that you master joining\nOne approach could be to work on reproducing results from a paper. Here, you can even consider improving the data visualisations or adding something extra\nDo not use a data set from one of the course exercises. Doing so would not allow you to demonstrate that you are independently capable of performing a bio data science analysis\nYou are 100% free to choose bio data from any resource as long as it meets the above requirements\n\n\n\n\n\nDepends, does your data set come with a readme, which allows you to make a decision regarding NAs?\nBe careful not to simply drop all NAs as you might drop observations, where columns of interest have complete data\n\n\n\n\n\nIn case your variable contains categories, i.e. values, where the question “Is one larger than the other” is nonsensical, then encode as factors\n\n\n\n\n\nIf you believe the data points are nonsensical, e.g. manual typing errors, then exclude them, but be very clear about which data (groups of) points were excluded and why\n\n\n\n\n\nYes, if you are particularly interested in a subset of the data, then that is perfectly fine. Just be aware, that any choice you take with the data, you must be able to account for why you took that choice\nYou should NOT just sample 100 observations as was done in the exercises to reduce runtime. However, if your data set is large, consider down-sampling either randomly or by some metric of association. For the latter e.g. perform a test and identify the top X observations, save those to file and continue from there.\nFor large data, try appending “.gz” to your files, when you write them using write_tsv(), this will invoke gzip-compression"
  },
  {
    "objectID": "project_faq.html#inputoutput-files",
    "href": "project_faq.html#inputoutput-files",
    "title": "Project FAQ",
    "section": "Input/output files",
    "text": "Input/output files\n\nHow can we get a better overview of the data file flow?\n\nConsider creating a flow chart of “your data journey”. It will force you to think about how files are connected and how input/output flows\n\n\n\nHow can we write a file with e.g. factor encoding or a nested tibble?\n\nThis can only be done by writing an R-object. However, this is for future reference - in this course stick to flat text files, e.g. .tsv or .csv\n\n\n\nHow do we handle different naming conventions?\n\nDO NOT do a manual search and replace in Excel. That defeats the whole purpose of this course\nFix names using a programmatic approach. The stringr-package is extremely useful in this context\n\n\n\nWhere should we place external files?\n\nConsider creating an “images” folder in the “doc” folder, from where you can input images to your presentation"
  },
  {
    "objectID": "project_faq.html#modelling",
    "href": "project_faq.html#modelling",
    "title": "Project FAQ",
    "section": "Modelling",
    "text": "Modelling\n\nWhat should we include in the modelling part?\n\nWe have worked with fitting a logistic regression, we have done a PCA and we have performed clustering using k-means. You could do something along those lines or something of similar complexity\nThis is not a modelling course. We briefly visited modelling to bridge the process of going from the raw data to analysis ready and then communication via data visualisation. Therefore, do not start fitting a full fledged machine/deep learning model, it is a time-void, which you cannot “afford” to get sucked into\nAlso, mind that the focus of this course is to make you realise that even though you have been trained in delivering results, then the process of arriving at the results in a reproducible manner is equally important\n\n\n\nDo we HAVE to do a PCA?\n\nDoes it make sense to do a PCA-analysis in your project? If you have group labels and you want to visualise to see if there is a separation, then a PCA is a good first step\n\n\n\nOur model is not performing very well. What should we do?\n\nLeave it as is. The focus of this course is not on the results, but on the reproducible process of arriving and communicating said results"
  },
  {
    "objectID": "project_faq.html#coding",
    "href": "project_faq.html#coding",
    "title": "Project FAQ",
    "section": "Coding",
    "text": "Coding\n\nWhat goes in the “augment” script?\n\nIf you google “Augment“, you will get “make (something) greater by adding to it; increase”, in other words, when you add e.g. variables to your data, which was not there initially, e.g. like we did, when we calculated the BMI from existing information on weight and height\nYou should think of the augment script as the place, where you create your database for everything that happens afterwards, i.e. all your analyses and ideas\nCreate that “database” and then load it into your downstream scripts\nAugment == Adding something\n\n\n\nCan we mix base R and tidyverse?\n\nNo, you might as well get used to it - Tidyverse all the way! (This is a tidyverse course)\n\n\n\nWhat if we can’t make it work in tidyverse but only in base R?\n\nIf you can make it work in base R, you can make it work in tidyverse\n\n\n\nIs it okay to use e.g. the base function sum()?\n\nYes, think of it this way: R has as core functionality to do statistics. Tidyverse is for performing the data manipulation surrounding these calculations. Therefore, using functions such as sum(), mean(), sd(), etc. is naturally fine\n\n\n\nHow do we know if there is a tidyverse function we should use rather than base?\n\nIdentify the general area of what you’re working with. E.g. if strings, then go to your RStudio session and find the console and type “stringr::” and hit tab, then you can look through the functions\nLook in the R-for-Data-Science book https://r4ds.had.co.nz\nAsk on the community pages https://community.rstudio.com\n\n\n\nCan we use package X for analysis/visualisation?\n\nIf the package performs a lot of the work, which you are to demonstrate that you can do, then no. Do not use packages, where you call a plot-my-data-function and the ggplot-magick happens that will not allow you to demonstrate that you have met the course learning objectives\n\n\n\nHow do we run the entire project incl. the presentation?\n\nMake sure to include a programmatic call to knitr at the end of your doit-script\n\n\n\nShould we create a Shiny app?\n\nThe project deliverables are the GitHub repo and your presentation. Remember, you do this project not for me as a teacher, but for you to internalize the knowledge you have been exposed to during the initial 10 weeks of teaching. If you find Shiny interesting/fun, then by all means, please do create an app. Shiny apps are optional\n\n\n\nShould we create a package?\n\nOptional, if you do, be careful with your time usage. You should focus on the data science cycle\n\n\n\nWhen should we create functions?\n\nRemember DRY (Dont-Repeat-Yourself), so generally, if you do something more than once, it is a function. However, we do not focus much on functions in this course, so don’t put too much effort into creating functions\nPlace functions in 99_proj_functions.R as illustrated in the overview\nDO NOT hide your code away in functions, so that your main script just becomes 10 function calls. For this process-oriented course, show the code in your main scripts, i.e. 01_, 02_, …\n\n\n\nCan we use loops?\n\nNo, you should instead embrace functional programming and use functions from the “purrr”-package. Revisit lab 6, if needed\n\n\n\nCan we directly copy/paste a code chunk from an online source?\n\nNo, that would be plagiarism. Understand the steps in the chunk and make the code your own\nI acknowledge that for coding this is not completely black and white, but please refrain from a direct copy/paste Coding style\n\n\n\nHow should we comment on our code?\n\nRemember, the point of writing verbose tidyverse code is that the code-becomes-the-comments. Think of it this way: The pipeline is the text on a page in a book, so before your pipeline, put a header/title on what is happening below, just as a title/header in a book\nThe title/header will be what is generally going on, e.g. “Normalise all gene expression values using standard score approach” and the pipeline will be how that is actually done\nThe pipe “%>%” is pronounced as “then”, when you “read” your code\n\n\n\nHow should we style our code?\n\nUse the tidyverse style guide as introduced in the course: https://style.tidyverse.org/index.html\nMake sure that all scripts are styled the same way and be consistent in your coding style\nYour code should not be >80 chars wide, follow the vertical line in your editor\n\n\n\nHow should we style our plots?\n\nBe concise, “less is more”\nMake some nice and relevant plots. Show us that you’ve learned data visualisation. Remember legends, titles etc.\nDo not put 3 messages in 1 plot. Instead put each message into a different plot\nBe careful with matching the text size in your plots to that of your presentation (trial-and-error)"
  },
  {
    "objectID": "project_faq.html#github",
    "href": "project_faq.html#github",
    "title": "Project FAQ",
    "section": "GitHub",
    "text": "GitHub\n\nShould our GitHub be public or private?\n\nThat is completely up to you. As students, you “own” anything you create while studying. The teaching staff must however have complete access.\n\n\n\nShould we keep all the data on GitHub?\n\nYes, for this course. However, be aware that GitHub is meant for code, not data.\n\n\n\nWhat goes in the “doc” folder?\n\nThe project organisation chart is a generic figure. You should not hand in a report. Your deliverable/product outcome for the project period is: 1) Your GitHub repository and 2) A presentation. Therefore, the “doc” folder would in this case contain your presentation\n\n\n\nWhy are there multiple “reports” in the “doc” folder?\n\nIn case you have a computationally intensive part of the project it can be an advantage to split into sub-reports and then collect in a master report (think large LaTeX reports)\nOverview, even if your report is not computationally intensive, then it may be long and splitting into sub-reports facilitate better overview\n\n\n\nShould we include a README on GitHub?\n\nThat would be a good way to briefly introduce what the contents of this repo is and something one would usually do\n\n\n\nShould everything be on Github, also plots we don’t present?\n\nYes, everything!"
  },
  {
    "objectID": "project_faq.html#examhand-in-deliverables",
    "href": "project_faq.html#examhand-in-deliverables",
    "title": "Project FAQ",
    "section": "Exam/hand-in deliverables",
    "text": "Exam/hand-in deliverables\n\nWhat is the final product?\n\nA GitHub repository organised according to principles of reproducible data analysis\nA ioslides/rmarkdown HTML-presentation following the IMRAD structure as elaborated in the project introduction slides (see lab 10)\nThis final presentation in HTML-format should be uploaded to DTU Learn\n\n\n\nDo we need to hand in a report?\n\nNo, no report is required!"
  },
  {
    "objectID": "project_faq.html#presentation",
    "href": "project_faq.html#presentation",
    "title": "Project FAQ",
    "section": "Presentation",
    "text": "Presentation\n\nShould we include code in our presentation?\n\nYour presentation should follow the standard scientific IMRAD-structure, i.e. introduction, materials-and-methods, results, and discussion.\nInclude certain decisions you took with the data and your reasoning herfore.\nIf you found a particular challenging problem in coding, to which you found an elegant solution, include that in your presentation as an example\nThe presentation is your chance to practice communicating insights to stakeholders\nYour audience will be same-level bioinformaticians\nPerhaps consider a graphical representation of your process going from raw to analysis-ready data\n\n\n\nShould we include tables or plots?\n\nWhat makes sense? If you only have two numerical values, then perhaps a table is fine. If you have 100 observations, then a plot is likely better\nRemember, we are as humans evolutionary encoded to interpret visual information, not numbers\n\n\n\nHow do we add plots to the rmarkdown presentation?\n\nOutput the plot as a png file using the function ggsave and include that png in your presentation. Think dynamically, we don’t want to type anything manually in our presentation\n\n\n\nHow do we get the presentation in wide-/full screen?\n\nHit w and f while the HTML presentation is loaded\n\n\n\nShould we split our presentation into sub-presentations?\n\nNo, this is not necessary given the extend/size of this project. Just create one Rmd file, which outputs an HTML-presentation\n\n\n\nWe are working on re-creating paper results. Should we re-create the exact same plots?\n\nIdeally, you re-create the plots and then you create your own improved version of the visualisation.\n\n\n\nWhere should we “place” our Shiny app in our presentation?\n\nDemo it briefly at the end\n\n\n\nHow can we illustrate our data handling?\n\nConsider creating a flow chart, what are input files and how are they connected to final output?\n\n\n\nHow much code should we include in the presentation?\n\nThe exam deliverables are two-fold. Code is the GitHub repo and your ability to communicate biological insights is in the presentation. Therefore, code could be included in the presentation if you faced and solved a particularly challenging problem\n\n\n\nHow do we include data numbers in the presentation?\n\nYou could from your script output a results table with relevant numbers as a .tsv file and then read that into the presentation and extract the numbers\nRemember, think dynamical reporting, what if your input data changes and you manually entered the numbers in your presentation? Then you wouldn’t be much farther than a powerpoint\n\n\n\nWhat goes into the materials and methods section?\n\nMaterials: What data did you use and where did you get it from?\nMethods: Which modelling did you use? Think of the methods section as a recipe for how to go from raw to results => Flow chart?\n\n\n\nShould we interpret our results?\n\nYes, you have to think about it as a “normal” project presentation\n\n\n\nWhat about all the stuff we tried, which did not work?\n\nIn the presentation, you should focus on what worked and what results you arrived at\nExclude dead-ends from the presentation, but… Leave them in the repo, perhaps with an initial comment signifying that the following turned out to be a dead-end\nThink about this - Scenario: You’re working in a company and you and your team of 3 spend 6 months on a project, which turns out to be a dead-end. For future reference: Would the company be interested in knowing that this project was a dead end or should you delete everything and never speak of it again?"
  },
  {
    "objectID": "project_faq.html#project-check-up-and-summary",
    "href": "project_faq.html#project-check-up-and-summary",
    "title": "Project FAQ",
    "section": "Project Check Up and Summary",
    "text": "Project Check Up and Summary\n\nIMPORTANT: Ask yourselves:\n\n\n“Does our presentation follow the IMRAD structure?”\n\nIs the presentation created as one ioslides Rmd file and output to a HTML?\nIs the presentation clear and concise?\nAre we doing good data communication via good visualisations?\nDo we present a clear overview of the data process incl. any decisions made, e.g. using a flow chart?\nAre we clearly communicating a biological insight?\nAre we following std guidelines? Sources, references, etc.\n\n\n\n\n\n\n\n\n“Does our project include all components of the data science cycle?”\n\n\n\n\n\n\n\n“Are we aware of and have included learning objectives as appropriate in the project?”\n\n\n\n\n\n\n\n“Is our project-GitHub organised as instructed and can it run end-to-end via doit?”\n(Note, this is a generic representation, your doc folder will contain your presentation)\n\n\n\n\n\n\n\n“Does our code in all our scripts follow the Tidyverse style guide?”\n\nRecall what we discussed in the course on styling\nAlso, see: https://style.tidyverse.org/index.html\nE.g.:\n\n\n\n\n\n\n\n\n“Are we using base-R, where we should use tidyverse-R?”\n\nE.g. think about the following:\n\n\n\n\n\n\n\n\n“Can we explain and justify the data decisions in the project?”\n\nIMPORTANT: In essence it does not matter which decision you took, what matters is your ability to explain and justify why you decided on that particular path in your analysis"
  },
  {
    "objectID": "exam.html",
    "href": "exam.html",
    "title": "Exam",
    "section": "",
    "text": "The exam consists of 3 components:\n\nA group project, where all members are responsible for all parts of the project. This is handed in as a code base on GitHub\nAn oral group presentation of the project, also to be handed in on GitHub\n2 hour MCQ exam, where general course learning objectives are examined, see course description\n\nDeadline for completing the project code base and presentation is 23:59 on the day before lab 13\nPlease note that active participation in the group work and timely submission of project and code base are both indispensable prerequisites for exam participation. The final grade is based on an overall assessment of all three components.\n\n\n\nBe sure that everyone understands ALL code in the project as all group members are responsible for ALL code\nThe point of the project is to cover more or less the entire course cycle, so if you have decided to leave out some parts, then you are also expected to be able to answer questions relating to these\nExpect a few overall questions regarding the decisions you have made throughout your project\nBe sure to read Project FAQ\n\n\n\n\n\nThe format is a 10-slides-in-10-mins and everyone in the group must present a part\nThe group presentations will be on the last day of the course, i.e. lab 13\n\n\n\n\n\nA 2-hour individual multiple choice exam\nIn 2022 the exam contained 60 questions, expect a similar number of questions\nAll aids are allowed, but no open internet\nEach question will have 4 possible answers and only 1 is the right one and you can only choose one answer per question"
  }
]