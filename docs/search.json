[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R for Bio Data Science",
    "section": "",
    "text": "A tidy approach to wrangling, exploring, visualising and communicating bio data with an emphasis on doing collaborative and reproducible bioinformatics projects \nLeon Eyrich Jessen & the TA team\n\nWelcome to R for Bio Data Science\nSo, you signed up for the 22100/22160 bioinformatics study line course - Congratulations! That was your first step towards getting a set of bio data science skills, which will serve you through your future career regardless of your path!\nInspirational quotes can be cliche, however this one hits the nail on the head:\n\n“Think about the readability of your code. Every project your work on is fundamentally collaborative. Even if you are not working with any other person, you are always working with future you and you really do not want to be in a situation where future you has no idea what past you was thinking, because past you will not respond to any emails!” Hadley Wickham\n\nBio Data Science in intrinsically collaborative (even if it’s just you working) and intrinsically interdisciplinary, so collaborative-, reproducibility- and communication- skills are key. In this course, you will learn how to do modern project oriented collaborative bio data science in tidy R - Welcome!\n\n\nCourse Essentials\n\nBefore First Class\nPlease go and answer this brief anonymous R for Bio Data Science Pre-course Questionnaire\n\n\nDescription and Prerequisites\nSee full course description here: 22100 / 22160 and please do note that it is assumed that the student has existing knowledge of mathematics, statistics, basic programming (language irrelevant), life science and bioinformatics corresponding to bachelor level. Be aware that you can still attend the course regardless, but in that case extra lifting during the course is to be expected.\n\n\nWhen and Where\nTeaching sessions will be E3A, Tuesday mornings 8 - 12 in building 358, room 060a (exercises: Also room 045) and the general schedule will be:\n\n08.00 - 08.30 Recap of key points from last weeks exercises\n08.30 - 09.00 Introduction to theme of the day\n09.00 - 12.00 Exercises\n\n\n\nCurriculum\nThe course curriculum is available by using the table of content on the left. Please note that this course is designed as a semi-flipped classroom, meaning that you will prepare materials from home and then I will cover selected key points and then the emphasis will be on hands on. Please note, this means that you cannot expect that all preparation materials will be re-iterated in class. This entails, that you have to make sure to prepare, as having prepared the materials is a prerequisite for working hands on with the exercises.\n\n\nCourse Materials\nThe teaching will largely follow “R for Data Science (2e)” by Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund, but also other open source learning materials will be used. There will be a mixture of videos and reading materials.\n\n\n\nGetting Started\nPlease proceed to the Getting started section"
  },
  {
    "objectID": "prologue.html",
    "href": "prologue.html",
    "title": "Prologue",
    "section": "",
    "text": "The course is designed as a semi-flipped classroom, with an emphasis on active learning. This means that during the 4h classes, the first hour will be dedicated to reviewing key points from last week and then a brief introduction to the topic of the day followed by a break. Hereafter, the students will work hands-on in groups on computational exercises using cloud computing infrastructure. The exercises will rely on relevant bioinformatics data from publicly available databases and gradually build the students toolbox with an emphasis on collaborative project work. This part will take up the first 9 labs. Each lab is defined by a set of specified learning objectives, it is essential that students continuously make sure, that they are on track with these LOs.\nThe fist hour of the 10th lab is dedicated to introducing the project part of the course and the subsequent 3h are dedicated to a mini symposium on “Application of R for Bio Data Science in Industry”. Here students will get a change to get insights into how the course topics are implemented in industry and get a glimpse into what options are available upon completing their education. This hybrid event typically attracts ~250 participants and have featured talks from major national and international Pharma/biotech companies, such as: Novo Nordisk, Lundbeck, Chr. Hansen, Bristol Meyer Squibb, a.o.\nIn the project part of the course, students will form groups of 4-5 students based on common interests. Hereafter, the students will seek out and select a data set, which will form the foundation for the project work. In the project work, the students will go through the entire data science cycle and produce the code base for a complete bioinformatics project. This entails a complete synthesis of all components of the exercise labs and supports the collaborative aspect. The groups must then condense the project into a presentation, thereby addressing communicative competencies as an essential part of being a modern bio data scientist.\nFinally, the exam will be an overall assessment of the project code base as delivered on Github, the condensation of the project work into a presentation and an individual 2h MCQ exam."
  },
  {
    "objectID": "getting_started.html",
    "href": "getting_started.html",
    "title": "Getting Started",
    "section": "",
    "text": "This section contain essential information for getting up and running for the classes"
  },
  {
    "objectID": "getting_started.html#logging-onto-cloud-server",
    "href": "getting_started.html#logging-onto-cloud-server",
    "title": "Getting Started",
    "section": "Logging onto Cloud Server",
    "text": "Logging onto Cloud Server\nFirst, make sure you have a working DTU account, either as a student id or employee initials (e.g. PhD-students or postdocs). In this course we will be using a cloud server infrastructure to perform our work. Click below to access the cloud server:\n\nR for Bio Data Science Cloud Server\n\nNote, that there is a 24h time out on the sessions, meaning that if you logon and forget to sign out, your session will be terminated after 24h."
  },
  {
    "objectID": "getting_started.html#setting-up-a-github-account",
    "href": "getting_started.html#setting-up-a-github-account",
    "title": "Getting Started",
    "section": "Setting up a GitHub account",
    "text": "Setting up a GitHub account\nPrior to class, please go to GitHub and setup and account, shouldn’t take long. During the registration process you can set up a student account, which will give you additional benefits, including GitHub Pro. In order to get it, you need to use your DTU email when setting account and select Apply for your GitHub student benefits when asked during the registration process. You’ll be then asked to apply for GitHub Student Developer Pack, which will require uploading your student id photo. The process of confirming a student account may take up to a few days (however, it can be almost instantaneous). In the meantime you can already use your free account. Free account should be sufficient for this class, so if you don’t want to set up a school account, you don’t need to. Please state your GitHub username in this google sheet."
  },
  {
    "objectID": "getting_started.html#class-communication",
    "href": "getting_started.html#class-communication",
    "title": "Getting Started",
    "section": "Class Communication",
    "text": "Class Communication\nThis course has grown from ~35 students in 2020 to ~150 students in 2023, therefore this term we will be using Piazza for class discussion. The system is highly catered to getting you help fast and efficiently from classmates, the TAs, and myself. Rather than emailing questions to the teaching staff, I encourage you to post your questions on Piazza. If you have any problems or feedback for the developers, email team@piazza.com.\nFind our class signup link at: https://piazza.com/dtu.dk/fall2023/22100 and see the Intro for Students video."
  },
  {
    "objectID": "getting_started.html#group-formation",
    "href": "getting_started.html#group-formation",
    "title": "Getting Started",
    "section": "Group Formation",
    "text": "Group Formation\nThe backbone of this course is modern collaborative data science and as such “active participation in the group work … [is an] indispensable prerequisites for exam participation” as stated in the course base. Furthermore, It is important that course participants prioritise to be present during classes as the course design is based on student-student interaction in an active learning environment.\nTherefore, students will work in groups of 4-5 students. Group formation sheet can be found here"
  },
  {
    "objectID": "lab00.html",
    "href": "lab00.html",
    "title": "Course Labs",
    "section": "",
    "text": "This section provides a complete overview of the course curriculum"
  },
  {
    "objectID": "lab01.html",
    "href": "lab01.html",
    "title": "Lab 1: Course Intro & the Very Basics",
    "section": "",
    "text": "Base"
  },
  {
    "objectID": "lab01.html#schedule",
    "href": "lab01.html#schedule",
    "title": "Lab 1: Course Intro & the Very Basics",
    "section": "Schedule",
    "text": "Schedule\n\n08.00 - 08.15: Arrival and 5 min. pre-course anonymous survey: Click here to answer\n08.15 - 08.45: Lecture: Course Introduction\n08.45 - 09.00: Break\n09.00 - 11.15: Exercises\n11.15 - 11.30: Break\n11.30 - 12.00: Lecture: Reproducibility in Modern Bio Data Science"
  },
  {
    "objectID": "lab01.html#learning-materials",
    "href": "lab01.html#learning-materials",
    "title": "Lab 1: Course Intro & the Very Basics",
    "section": "Learning Materials",
    "text": "Learning Materials\nPlease prepare the following materials:\n\nRead course site sections: Welcome to R for Bio Data Science, Prologue and Getting Started and perform any small tasks mentioned\nR4DS2e Book: Welcome, Preface to the second edition, Chapter 1, Chapter 3, Chapter 29 (Don’t do the exercises)\nVideo: RStudio for the Total Beginner\nWeb: Read the detailed course description\nPaper: Ten Simple Rules for Effective Statistical Practice\nPaper: A Quick Guide to Organizing Computational Biology Projects"
  },
  {
    "objectID": "lab01.html#learning-objectives",
    "href": "lab01.html#learning-objectives",
    "title": "Lab 1: Course Intro & the Very Basics",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nA student who has met the objectives of the session will be able to:\n\nMaster the very basics of R\nNavigate the RStudio IDE\nCreate, edit and run a basic Quarto document\nExplain why reproducible data analysis is important, as well as identify relevant challenges and explain replicability versus reproducibility\nDescribe the components of a reproducible data analysis"
  },
  {
    "objectID": "lab01.html#sec-exercises",
    "href": "lab01.html#sec-exercises",
    "title": "Lab 1: Course Intro & the Very Basics",
    "section": "Exercises",
    "text": "Exercises\nToday, we will focused on getting you started and up and running with the first elements of the course, namely the RStudio IDE (Integrated Developer Environment) and Quarto. If the relationship between R and RStudio is unclear, think of it this way: Consider a car, in that case, R would be the engine and RStudio would be the rest of the car. Neither is particularly useful, but together they form a functioning unit. Before you continue, make sure you in fact did watch the “RStudio for the Total Beginner” video (See the Learning Materials for todays session).\n\nCloud server and the RStudio IDE\nGo to the R for Bio Data Science Cloud Server and follow the login procedure. Upon login, you will see this:\n\n\n\n\n\nThis is the RStudio IDE. It allows you to consolidate all features needed to develop R code for analysis. Now, click Tools \\(\\rightarrow\\) Global Options... \\(\\rightarrow\\) Pane Layout and you will see this:\n\n\n\n\n\nThis outlines the four panes you have in your RStudio IDE and allow you rearrange them as you please. Now, re-arrange them, so that they look like this:\n\n\n\n\n\nClick Apply \\(\\rightarrow\\) OK and you should see this:\n\n\n\n\n\n\n\nFirst steps\n\nThe Console\nNow, in the console, as you saw in the video, you can type commands like:\n\n2+2\n1:100\n3*3\nsample(1:9)\nX <- matrix(sample(1:9), nrow = 3, ncol = 3)\nX\nsum(X)\nmean(X)\n?sum\nsum\nnucleotides <- c(\"a\", \"c\", \"g\", \"t\")\nnucleotides\nsample(nucleotides, size = 100, replace = TRUE)\ntable(sample(nucleotides, size = 100, replace = TRUE))\npaste0(sample(nucleotides, size = 100, replace = TRUE), collapse = \"\")\nreplicate(n = 10, expr = paste0(sample(nucleotides, size = 100, replace = TRUE), collapse = \"\"))\ndf <- data.frame(id = paste0(\"seq\", 1:10), seq = replicate(n = 10, expr = paste0(sample(nucleotides, size = 100, replace = TRUE), collapse = \"\")))\ndf\nstr(df)\nls()\n\nTake some time and play around with these commands and other things you can come up with. Use the ?function to get help on what that function does. Be sure to discuss what you observe in the console. Do not worry too much on the details for now, we are just getting started. But as you hopefully can see, R is very flexible and basically the message is: “If you can think it, you can build it in R”.\n\nGo to Chapter 3 in R4DS2e and do the exercises\n\n\n\nThe Terminal\nNotice how in the console pane, you also get a Terminal, click and enter:\n\nls\nmkdir tmp\ntouch tmp/test.txt\nls tmp\nrm tmp/test.txt\nrmdir tmp\nls\necho $SHELL\n\nBasically, here you have access to a full terminal, which can prove immensely useful! Note, you may or may not be familiar with the concept of a terminal. Simply think of it as a way to interact with the computer using text command, rather than clicking on icons etc. Click back to the console.\n\n\nThe Source\nThe source is where you will write scripts. A script is a series of commands to be executed sequentially, i.e. first line 1, then line 2 and so on. Right now, you should have a open script called Untitled1. If not, you can create a new script by clicking white paper with a round green plus sign in the upper left corner.\nTaking inspiration from the examples above, try to write a series of commands and include a print()-statement at the very end. Click File \\(\\rightarrow\\) Save and save the file as e.g. my_first_script.R. Now, go to the console and type in the command source(\"my_first_script.R\"). Congratulations! You have now written your very first reproducible R-program!\n\n\n\nThe Whole Shebang\nEnough playing around, let us embark on our modern Bio Data Science in R journey.\n\nIn the Files pane, click New Folder and create a folder called projects\nIn the upper right corner, click where it says Project: (None) and then click New Project...\nClick New Directory and then New Project\nIn the Directory name:, enter e.g. r_for_bio_data_science\nClick the Browse... button and select your newly created projects directory and then click Choose\nClick Create Project and wait a bit for it to get created\n\n\nOn Working in Projects\nProjects allow you to create fully transferable bio data science projects, meaning that the root of the project will be where the .Rproj file is located. You can confirm this by entering getwd() in the console. This means that under no circumstance should ever not work in a project nor should ever use absolute paths. Every single path you state in your project must be relative to the project root.\nBut why? Imagine you have create a project, where you have indeed used absolute paths. Now you want to share that project with a colleague. Said colleague gets your project and tests the reproducibility by running the project end-to-end. But it completely fails because you have hardcoded your paths to be absolute, meaning that all files and project ressources locations points to locations on your laptop.\nProjects are a must and allows you to create reproducible encapsulated bio data science projects. Note, the concept of reproducibility is absolute central to this course and must be considered in all aspect of the life cycle of a project!\n\n\nQuarto\nWhile .R-scripts are a perfectly, there is another Skywalker:\n\nIn the upper left corner, again, click the white paper with the round green plus, but this time select Quarto Document\nEnter a Title:, e.g. “Lab 1 Exercises” and enter your name below in the box Author:\nClick Create\nImportant: Save your Quarto document! Click File \\(\\rightarrow\\) Save and name it e.g. lab_01_exercises.qmd\nMinimise the Environment-pane\n\nYou should now see something like this:\n\n\n\n\n\nTry clicking the Render button just above the quarto-document. This will create the HTML5 output file. Note! You may get a Connection Refused message. If so, don’t worry, just close the page to return to the cloud server and find the generated .html file, left-click and select View in Web Browser.\nIf you have previously worked with Rmarkdown, then many features of Quarto will be familiar. Think of Quarto as the complete rethink of Rmarkdown, i.e. based on all the experience gained, what would the optimal way of constructing an open-source scientific and technical publishing system?\nPerhaps you have previously encountered Jupyter notebooks, Quarto is similar. The basic idea is to have one document covering the entire project cycle.\nProceed R for Data Science (2e), chapter 29 and do the exercises.\n\n\n\nBio Data Science with a Virtual AI Assistant\nI am pretty sure you all know of chatGPT by now, so let us address the elephant in the room!\n\nGetting started\n\nGo to the ChatGPT site\nCreate a user and login\n\n\nLet us get acquainted\nNow, at the bottom it says “Send a message”, let us ask 3 simple question and see if we can find out what is what. Type the following questions in the prompt and read the answers:\n\nExplain in simple terms what you are\nExplain in simple terms how you work\nExplain in simple terms how you can be used to generate value as a virtual AI assistant, when doing Bio Data Science for R\n\n\n\nMoving onto R\nIn the upper left corner, it says + New chat, click it to start a new session.\nAgain, type the following questions in the prompt and read the answers:\n\nR\nWhat is R?\nGive a few simple examples\n\nIf you do get some code examples, try to copy/paste into the console in RStudio and see if they run\n\n\nPrompt Engineering\nStart a new chat and enter:\n\nGive a few simple examples\n\nCompare the response with the one from before, is it the same or different and why so?\nDiscuss in your group what is “Prompt Engineering” and how does it relate to the above few tests you did? (Bonus info: Prompt engineer is already a job and people are making money off of selling prompts)\n\n\n…a bit more\nStart a new chat and enter:\n\nTell me about DNA\n\nCheck if it gives you correct information?\nNow, write:\n\nGive a few fun examples on how to get started with the R programming language using DNA\n\nCopy/paste the code into the Console, do the examples all run?\n\nEarlier you were told to play around with some code snippets. Perhaps you didn’t fully catch what was going on? If so, try to type in e.g.:\n\nI'm new to R, please explain in simple terms, what the following code does:\n\n\"\nnucleotides <- c(\"a\", \"c\", \"g\", \"t\")\nreplicate(n = 10, expr = paste0(sample(nucleotides, size = 100, replace = TRUE), collapse = \"\"))\n\"\n\n\nSummary\nWhile chatGPT can be a powerful tool for code productivity, it comes with a major caveat: When it fails, it fails with confidence. This means that it will be equally confident whether it is right or wrong! The optimal yield is when you are working on a problem with a tool, where you already have a good knowledge of the problem and the tool. Here, you can see if you are heading in the right direction or if you’re being send on a wild goose chase.\nTherefore, in the beginning of the course, for your own sake, please refrain from using chatGPT!\nInstead solve the exercises based on the materials you have prepared, talk to you group members and discuss the challenges and check your understanding. Then later on, when you have gained initial experience, we can explore using chatGPT to augment your bio data science workflow to enhance productivity"
  },
  {
    "objectID": "lab02.html",
    "href": "lab02.html",
    "title": "Lab 2: Data Visualisation I",
    "section": "",
    "text": "ggplot2"
  },
  {
    "objectID": "lab02.html#schedule",
    "href": "lab02.html#schedule",
    "title": "Lab 2: Data Visualisation I",
    "section": "Schedule",
    "text": "Schedule\n\n08.00 - 08.15: Pre-course Survey Walk-through\n08.15 - 08.30: Recap: RStudio Cloud, RStudio and R - The Very Basics (Live session)\n08.30 - 09.00: Lecture\n09.00 - 09.15: Break\n09.00 - 12.00: Exercises"
  },
  {
    "objectID": "lab02.html#learning-materials",
    "href": "lab02.html#learning-materials",
    "title": "Lab 2: Data Visualisation I",
    "section": "Learning Materials",
    "text": "Learning Materials\nPlease prepare the following materials:\n\nBook: R4DS2e Chapter 2 Data Visualisation\nPaper: “A Layered Grammar of Graphics” by Hadley Wickham\nVideo: The best stats you’ve ever seen\nVideo: The SDGs aren’t the same old same old\nVideo: EMBL Keynote Lecture - “Data visualization and data science” by Hadley Wickham"
  },
  {
    "objectID": "lab02.html#learning-objectives",
    "href": "lab02.html#learning-objectives",
    "title": "Lab 2: Data Visualisation I",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nA student who has met the objectives of the session will be able to:\n\nExplains the basic theory of data visualisation\nDecipher the components of a ggplot\nUse ggplot to do basic data visualisation"
  },
  {
    "objectID": "lab02.html#sec-exercises",
    "href": "lab02.html#sec-exercises",
    "title": "Lab 2: Data Visualisation I",
    "section": "Exercises",
    "text": "Exercises"
  },
  {
    "objectID": "lab02.html#prelude",
    "href": "lab02.html#prelude",
    "title": "Lab 2: Data Visualisation I",
    "section": "Prelude",
    "text": "Prelude\nDiscuss these 4 visualisations with your group members\n\nWhat is problematic?\nWhat could be done to rectify?\n\n\n\n\nClick here for visualisation 1\n\n\nNote, AMR = Antimicrobial Resistance\n\n\n\n\n\nClick here for visualisation 2\n\n\n\n\n\n\n\nClick here for visualisation 3\n\n\n\n\n\n\n\nClick here for visualisation 4"
  },
  {
    "objectID": "lab02.html#getting-started",
    "href": "lab02.html#getting-started",
    "title": "Lab 2: Data Visualisation I",
    "section": "Getting Started",
    "text": "Getting Started\nFirst of all, make sure to read every line in these exercises carefully!\nIf you get stuck with Quarto, revisit R4DS2e, chapter 29 or take a look at the Comprehensive guide to using Quarto\n\nGo to the R for Bio Data Science RStudio Cloud Server session from last time and login and choose the project you created.\nCreate a new Quarto Document for todays exercises, e.g. lab02_exercises.qmd\n\nRecall the layout of the IDE (Integrated Development Environment)\n\n\n\n\n\nThen, before we start, we need to fetch some data to work on.\n\nSee if you can figure out how to create a new folder called “data”, make sure to place it the same place as your my_project_name.Rproj file.\n\nThen, without further ado, run each of the following lines separately in your console:\n\ntarget_url <- \"https://github.com/ramhiser/datamicroarray/raw/master/data/gravier.RData\"\noutput_file <- \"data/gravier.RData\"\ncurl::curl_download(url = target_url,\n                    destfile = output_file)\n\n\nUsing the files pane, check the folder you created to see if you managed to retrieve the file.\n\nRecall the syntax for a new code chunk:\n  ```{r}\n  #| echo: true\n  #| eval: true\n  # Here goes the code... Note how this part does not get executed because of the initial hashtag, this is called a code-comment\n  1 + 1\n  my_vector <- c(1, 2, 3)\n  my_mean <- mean(my_vector)\n  print(my_mean)\n  ```\nIMPORTANT! You are mixing code and text in a Quarto Document! Anything within a “chunk” as defined above will be evaluated as code, whereas anything outside the chunks is markdown. You can use shortcuts to insert new code chunks:\n\nMac: CMD + OPTION + i\nWindows: CTRL + ALT + i\n\nNote, this might not work, depending on your browser. In that case you can insert a new code chunk using  or You can change the shortcuts via “Tools” > “Modify Keyboard shortcuts…” > Filter for “Insert Chunk” and then choose the desired shortcut. E.g. change the shortcut for code chunks to Shift+Cmd+i or similar.\n\nAdd a new code chunk and use the load()-function to load the data you retrieved.\n\n\n\n\nClick here for a hint\n\n\nRemember, you can use ?load to get help on how the function works and remember your project root path is defined by the location of your .Rproj file, i.e. the path. A path is simply where R can find your file, e.g. /home/projects/r_for_bio_data_science/ or similar depending on your particular setup.\n\nNow, in the console, run the ls()-command and confirm, that you did indeed load the gravier data.\n\nRead the information about the gravier-data here\n\nNow, in your Quarto Document, add a new code chunk like so\n\nlibrary(\"tidyverse\")\n\nThis will load our data science toolbox, including ggplot."
  },
  {
    "objectID": "lab02.html#create-data",
    "href": "lab02.html#create-data",
    "title": "Lab 2: Data Visualisation I",
    "section": "Create data",
    "text": "Create data\nBefore we can visualise the data, we need to wrangle it a bit. Nevermind the details here, we will get to that later. Just create a new chunk, copy/paste the below code and run it:\n\nset.seed(676571)\ncancer_data=mutate(as_tibble(pluck(gravier,\"x\")),y=pluck(gravier,\"y\"),pt_id=1:length(pluck(gravier, \"y\")),age=round(rnorm(length(pluck(gravier,\"y\")),mean=55,sd=10),1))\ncancer_data=rename(cancer_data,event_label=y)\ncancer_data$age_group=cut(cancer_data$age,breaks=seq(10,100,by=10))\ncancer_data=relocate(cancer_data,c(pt_id,age,age_group,pt_id,event_label))\n\nNow we have the data set as an tibble, which is an augmented data frame (we will also get to that later):\n\ncancer_data\n\n# A tibble: 168 × 2,909\n   pt_id   age age_group event_label    g2E09    g7F07    g1A01   g3C09    g3H08\n   <int> <dbl> <fct>     <fct>          <dbl>    <dbl>    <dbl>   <dbl>    <dbl>\n 1     1  34.2 (30,40]   good        -0.00144 -0.00144 -0.0831  -0.0475  1.58e-2\n 2     2  47   (40,50]   good        -0.0604   0.0129  -0.00144  0.0104  3.16e-2\n 3     3  60.3 (60,70]   good         0.0398   0.0524  -0.0786   0.0635 -3.95e-2\n 4     4  57.8 (50,60]   good         0.0101   0.0314  -0.0218   0.0215  8.68e-2\n 5     5  54.9 (50,60]   good         0.0496   0.0201   0.0370   0.0311  2.07e-2\n 6     6  58.8 (50,60]   good        -0.0664   0.0468   0.00720 -0.370   2.88e-3\n 7     7  52.9 (50,60]   good        -0.00289 -0.0816  -0.0291  -0.0249 -1.74e-2\n 8     8  74.5 (70,80]   good        -0.198   -0.0499  -0.0634  -0.0298  3.00e-2\n 9     9  47.6 (40,50]   good         0.00288  0.0201   0.0272   0.0174 -7.89e-5\n10    10  55.8 (50,60]   good        -0.0574  -0.0574  -0.0831  -0.0897 -1.01e-1\n# ℹ 158 more rows\n# ℹ 2,900 more variables: g1A08 <dbl>, g1B01 <dbl>, g1int1 <dbl>, g1E11 <dbl>,\n#   g8G02 <dbl>, g1H04 <dbl>, g1C01 <dbl>, g1F11 <dbl>, g3F05 <dbl>,\n#   g3B09 <dbl>, g1int2 <dbl>, g2C01 <dbl>, g1A05 <dbl>, g1E01 <dbl>,\n#   g1B05 <dbl>, g3C05 <dbl>, g3A07 <dbl>, g1F01 <dbl>, g2D01 <dbl>,\n#   g1int3 <dbl>, g1int4 <dbl>, g1D05 <dbl>, g1E05 <dbl>, g1G05 <dbl>,\n#   g1C05 <dbl>, g1G11 <dbl>, g2D08 <dbl>, g2E06 <dbl>, g3H09 <dbl>, …\n\n\n\nQ1: What is this data?\n\n\n\n\nClick here for a hint\n\n\nWhere did the data come from?\n\n\nQ2: How many rows and columns are there in the data set in total?\n\n\n\n\nClick here for a hint\n\n\nDo you think you are the first person in the world to try to find out how many rows and columns are in a data set in R?\n\n\nQ3: Which are the variables and which are the observations in relation to rows and columns?"
  },
  {
    "objectID": "lab02.html#ggplot---the-very-basics",
    "href": "lab02.html#ggplot---the-very-basics",
    "title": "Lab 2: Data Visualisation I",
    "section": "ggplot - The Very Basics",
    "text": "ggplot - The Very Basics\n\nGeneral Syntax\nThe general syntax for a basic ggplot is:\n\nggplot(data = my_data,\n       mapping = aes(x = variable_1_name,\n                     y = variable_2_name)) +\n  geom_something() +\n  labs()\n\nNote the + for adding layers to the plot\n\nggplot the plotting function\nmy_data the data you want to plot\naes() the mappings of your data to the plot\nx data for the x-axis\ny data for the y-axis\ngeom_something() the representation of your data\nlabs() the x-/y-labels, title, etc.\n\nNow:\n\nReivisit this illustration and discuss in your group what is what:\n\n\nA very handy ggplot cheat-sheet can be found here\n\n\nBasic Plots\nRemember to write notes in your rmarkdown document. You will likely revisit these basic plots in future exercises.\nPrimer: Plotting 2 x 20 random normally distributed numbers, can be done like so:\n\nggplot(data = tibble(x = rnorm(20),\n                     y = rnorm(20)),\n       mapping = aes(x = x,\n                     y = y)) +\n  geom_point()\n\n\n\n\nUsing this small primer, the materials you read for today and the cancer_data you created, in separate code-chunks, create a:\n\nT1: scatterplot of one variable against another\nT2: linegraph of one variable against another\nT3: boxplot of one variable (Hint: Set x = \"my_gene\" in aes())\nT4: histogram of one variable\nT5: densitogram of one variable\n\nRemember to write notes to yourself, so you know what you did and if there is something in particular you want to remember.\n\nQ4: Do all geoms require both x and y?\n\n\n\nExtending Basic Plots\n\nT6: Pick your favourite gene and create a boxplot of expression levels stratified on the variable event_label\nT7: Like T6, but with densitograms GROUP ASSIGNMENT\nT8: Pick your favourite gene and create a boxplot of expression levels stratified on the variable age_group\n\nThen, add stratification on event_label\nThen, add transparency to the boxes\nThen, add some labels\n\nT9: Pick your favourite gene and create a scatter-plot of expression levels versus age\n\nThen, add stratification on event_label\nThen, add a smoothing line\nThen, add some labels\n\nT10: Pick your favourite two genes and create a scatter-plot of their expression levels\n\nThen, add stratification on event_label\nThen, add a smoothing line\nThen, show split into seperate panes based on the variable age_group\nThen, add some labels\nChange the event_label title of the legend\n\nT11: Recreate the following plot\n\n\n\n\n\n\n\nQ5: Using your biological knowledge, what is your interpretation of the plot?\nT12: Recreate the following plot\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\nQ6: Using your biological knowledge, what is your interpretation of the plot?\nT13: If you arrive here and there is still time left for the exercises, you are probably already familiar with ggplot - Use what time is left to challenge yourself to further explore the cancer_data and create some nice data visualisations - Show me what you come up with!"
  },
  {
    "objectID": "lab02.html#further-ressources-for-data-visualisation",
    "href": "lab02.html#further-ressources-for-data-visualisation",
    "title": "Lab 2: Data Visualisation I",
    "section": "Further ressources for data visualisation",
    "text": "Further ressources for data visualisation\n\nA very handy ggplot cheat-sheet can be found here\nSo which plot to choose? Check this handy guide\nExplore ways of plotting here"
  },
  {
    "objectID": "lab03.html#packages",
    "href": "lab03.html#packages",
    "title": "Lab 3: Data Visualisation II",
    "section": "Package(s)",
    "text": "Package(s)\n\nggplot2\npatchwork\nscales\nggridges"
  },
  {
    "objectID": "lab03.html#schedule",
    "href": "lab03.html#schedule",
    "title": "Lab 3: Data Visualisation II",
    "section": "Schedule",
    "text": "Schedule\n\n08.00 - 08.30: Recap of Lab 2\n08.30 - 09.00: Introduction to Lab 3\n09.00 - 09.15: Break\n09.00 - 12.00: Exercises"
  },
  {
    "objectID": "lab03.html#learning-materials",
    "href": "lab03.html#learning-materials",
    "title": "Lab 3: Data Visualisation II",
    "section": "Learning Materials",
    "text": "Learning Materials\nPlease prepare the following materials\n\nBook: “Visualize”, chapters 10, 11 and 12\nVideo: William Chase | The Glamour of Graphics | RStudio (2020)\nWeb: Patchwork - Getting started\nWeb: Scales - Getting started"
  },
  {
    "objectID": "lab03.html#learning-objectives",
    "href": "lab03.html#learning-objectives",
    "title": "Lab 3: Data Visualisation II",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nA student who has met the objectives of the session will be able to:\n\nUse more advanced ggplot features\nCustomise the data visualisation\nCombine multiple plots into one pane\nLook at a more advanced ggplot and decipher the components used"
  },
  {
    "objectID": "lab03.html#exercises",
    "href": "lab03.html#exercises",
    "title": "Lab 3: Data Visualisation II",
    "section": "Exercises",
    "text": "Exercises\n\n\n\nRead the steps of this exercises carefully, while completing them\n\nIntroduction\nSome authors are kind enough to supply the data they used for their paper, e.g.:\n\n“Assessment of the influence of intrinsic environmental and geographical factors on the bacterial ecology of pit latrines”\n\nWhere the supporting data can be found here:\n\nhttp://userweb.eng.gla.ac.uk/umer.ijaz/bioinformatics/ecological.html\n\n\n\nGetting Started\nAgain, go to the R for Bio Data Science RStudio Cloud Server session from last time and login and choose the project you created\n\nCreate a new Quarto Document for todays exercises, e.g. lab03_exercises.qmd\nNB! The rmarkdown document MUST be placed together with your .Rproj file (defining, the project root - look in your Files-tab) and also there, the data-folder should be placed!\nREMEMBER paths are important! Also, R is case-sensitive, i.e. “data” is not the same as “Data”\n\n\n\nGetting the data\nAdd a new code chunk and add the following code (Never mind the details, we will get back to this), remember you can use headers to nicely section your quarto Document.\n\nbase_url <- \"http://userweb.eng.gla.ac.uk/umer.ijaz/bioinformatics/ecological/\"\n\nSPE <- read_csv(file = str_c(base_url, \"SPE_pitlatrine.csv\"))\nwrite_csv(x = SPE, file = \"data/SPE_pitlatrine.csv\")\n\nENV <- read_csv(file = str_c(base_url, \"ENV_pitlatrine.csv\"))\nwrite_csv(x = ENV, file = \"data/ENV_pitlatrine.csv\")\n\nAdd the chunk settings #| echo: true and #| eval: true, then run the block and change the latter to #| eval: false.\n\nDiscuss in your group, what this means and why we do it\n\n\n\n\nClick here for hint\n\n\nFrom where do we retrieve the data and to where do we write it and what happens if we run the chunk more than one time?\n\n\n\nWrangling the data\n\nWhat is data wrangling?\n\nBefore we continue with plotting, we want to unify the data, so here again you will run some code, where the details are not important right now.\nBut… Make sure, that you have run library(\"tidyverse\") somewhere in your rmarkdown document - Perhaps under an initial header saying “Load Libraries” or similar?\n\nSPE |> \n  pivot_longer(cols = -Taxa,\n               names_to = \"Samples\",\n               values_to = \"OTU_Count\")  |> \n  full_join(ENV, by = \"Samples\") |> \n  mutate(site = case_when(str_detect(Samples, \"^T\") ~ \"Tanzania\",\n                          str_detect(Samples, \"^V\") ~ \"Vietnam\")) |>  \n  write_tsv(file = \"data/SPE_ENV.tsv\")\n\nChange the chunk settings as before"
  },
  {
    "objectID": "lab03.html#data-visualisation-ii",
    "href": "lab03.html#data-visualisation-ii",
    "title": "Lab 3: Data Visualisation II",
    "section": "Data Visualisation II",
    "text": "Data Visualisation II\n\nRead the data\n\nSPE_ENV <- read_tsv(file = \"data/SPE_ENV.tsv\")\nSPE_ENV\n\n# A tibble: 4,212 × 15\n   Taxa   Samples OTU_Count    pH  Temp    TS    VS   VFA  CODt  CODs perCODsbyt\n   <chr>  <chr>       <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>      <dbl>\n 1 Acido… T_2_1           0  7.82  25.1  14.5 71.3   71     874   311         36\n 2 Acido… T_2_10          0  9.08  24.2  37.8 31.5    2     102     9          9\n 3 Acido… T_2_12          0  8.84  25.1  71.1  5.94   1      35     4         10\n 4 Acido… T_2_2           0  6.49  29.6  13.9 64.9    3.7   389   180         46\n 5 Acido… T_2_3           0  6.46  27.9  29.4 26.8   27.5   161    35         22\n 6 Acido… T_2_6           0  7.69  28.7  65.5  7.03   1.5    57     3          6\n 7 Acido… T_2_7           0  7.48  29.8  36.0 34.1    1.1   107     9          8\n 8 Acido… T_2_9           0  7.6   25    46.9 19.6    1.1    62     8         13\n 9 Acido… T_3_2           0  7.55  28.8  12.6 51.8   30.9   384    57         15\n10 Acido… T_3_3           0  7.68  28.9  14.6 48.1   24.2   372    57         15\n# ℹ 4,202 more rows\n# ℹ 4 more variables: NH4 <dbl>, Prot <dbl>, Carbo <dbl>, site <chr>\n\n\n\n\nIMPORTANT INSTRUCTIONS - READ!\nFor these exercises, you will have to identify what you see in the plot!\nFor each plot, complete the following steps\n\nLook at this overview of the components of a ggplot (see below)\nLook at the plot you are to recreate and discuss in the group:\n\nWhat is the data? Take a look at it and understand what is in the data\nWhat are the mappings? I.e. what variables are on the x-/y-axis?\nAre there any colour-/fill-mappings?\nWhat are the geoms used?\nAre there any modifications to theme?\n\n\nHints\n\nConsult the Data visualization with ggplot2 cheatsheet\nCheck which options you have available\nConsult the chapters in the book you read, see preparation materials for labs 2 and 3\n\n\n\n\nTASKS\n\nTask 1 - Recreate the following plot\nDiscuss in your group, which ggplot elements can you identify?\n\n\n\n\n\n\n\nTask 2 - Recreate the following plot\nDiscuss in your group, which ggplot elements can you identify?\n\n\n\n\n\n\n\nTask 3 - Recreate the following plot\nDiscuss in your group, which ggplot elements can you identify?\n\n\n\n\n\n\n\nTask 4 - Recreate the following plot\nDiscuss in your group, which ggplot elements can you identify?\n\n\n\n\n\n\n\nTask 5 - Recreate the following plot\nDiscuss in your group, which ggplot elements can you identify?\n\n\n\n\n\n\n\nTask 6 - Recreate the following plot\nDiscuss in your group, which ggplot elements can you identify?\n\n\n\n\n\n\n\n\nClick here for hint\n\n\nSee if you can find something online on geom_smooth()\n\n\n\nTask 7 - Recreate the following plot\nDiscuss in your group, which ggplot elements can you identify?\n\n\n\n\n\n\n\n\n\n\n\n\nClick here for hint\n\n\nThink about fill and then see if you can find something online on geom_tile(), scale_fill_gradient2 and how to ggplot rotate axis labels\n\n\n\nTask 8 - Recreate the following plot\nStart by running this code in a new chunk (ignore details for now)\n\ntargets <- c(\"Methanobacteria\", \"Clostridia\", \"Actinobacteria\",\n            \"Sphingobacteria\", \"Anaerolineae\")\nSPE_ENV_targets <- SPE_ENV |>\n  filter(Taxa %in% targets)\n\nand then use the created dataset SPE_ENV_targets to recreate this plot:\nDiscuss in your group, which ggplot elements can you identify?\n\n\n\n\n\n\n\n\nClick here for hint\n\n\nHere we need to use geom_density_ridges(), but which package contains this? Also we are using a colour scale called viridis, but how do we add this? Also, perhaps there are more themes we can use than just theme_classic()?\n\n\n\nTask 9 - GROUP ASSIGNMENT\nFor this assignment you and your group are to apply what you have learned in the two data visualisation labs. The task is to create a really nice plot using one of two datasets, the cancer_data or the SPE_ENV\n\nInstructions\n\nThis time, submit one PDF file per group\nSubmit only this assignment, not the entire exercises\nMake it nice, add a title, your group number and names and a bit of text to along with your data visualisation\nDeadline is Thursday 23:59 as usual"
  },
  {
    "objectID": "lab04.html#packages",
    "href": "lab04.html#packages",
    "title": "Lab 4: Data Wrangling I",
    "section": "Package(s)",
    "text": "Package(s)\n\ndplyr\nreadr\ntibble\nmagrittr"
  },
  {
    "objectID": "lab04.html#schedule",
    "href": "lab04.html#schedule",
    "title": "Lab 4: Data Wrangling I",
    "section": "Schedule",
    "text": "Schedule\n08.00 - 08.15: Recap of Lab 3 08.15 - 08.30: Assignment 2 walk-through 08.30 - 09.00: Introduction to Lab 4 09.00 - 09.15: Break 09.00 - 12.00: Exercises"
  },
  {
    "objectID": "lab04.html#learning-materials",
    "href": "lab04.html#learning-materials",
    "title": "Lab 4: Data Wrangling I",
    "section": "Learning Materials",
    "text": "Learning Materials\nPlease prepare the following materials:\n\nBook: R4DS chapters 2, 7, 5, 9, 10, 11, 12.1-12.2\nWeb: What is data wrangling? Intro, Motivation, Outline, Setup – Pt. 1 Data Wrangling Introduction\nWeb: (NB! STOP at 7:45, i.e. skip tidyr) Tidy Data and tidyr – Pt 2 Intro to Data Wrangling with R and the Tidyverse\nWeb: Data Manipulation Tools: dplyr – Pt 3 Intro to the Grammar of Data Manipulation with R"
  },
  {
    "objectID": "lab04.html#learning-objectives",
    "href": "lab04.html#learning-objectives",
    "title": "Lab 4: Data Wrangling I",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nA student who has met the objectives of the session will be able to:\n\nUnderstand and apply the 6 basic dplyr verbs: filter(), arrange(), select(), mutate(), summarise() and group_by()\nConstruct and apply logical tests in context with dplyr pipelines\nUnderstand and apply the additional verbs count(), drop_na(), View()\nCombine dplyr verbs to form a data manipulation pipeline using the pipe %>% operator\nDecipher the components and functions hereof in a dplyr pipeline"
  },
  {
    "objectID": "lab05.html#packages",
    "href": "lab05.html#packages",
    "title": "Lab 5: Data Wrangling II",
    "section": "Package(s)",
    "text": "Package(s)\n\ndplyr\nstringr\ntidyr\nforcats"
  },
  {
    "objectID": "lab05.html#schedule",
    "href": "lab05.html#schedule",
    "title": "Lab 5: Data Wrangling II",
    "section": "Schedule",
    "text": "Schedule\n\n08.00 - 08.15: Exercises recap\n08.15 - 08.30: Assignment walk-through\n08.30 - 09.00: Introduction to Lab\n09.00 - 09.15: Break\n09.00 - 12.00: Exercises, (Do not use this unless you are told to: data_files)"
  },
  {
    "objectID": "lab05.html#learning-materials",
    "href": "lab05.html#learning-materials",
    "title": "Lab 5: Data Wrangling II",
    "section": "Learning Materials",
    "text": "Learning Materials\nPlease prepare the following materials\n\nBook: R4DS: 12.3-12.7: “Tidy Data”, 13: “Relational Data”, 14: “Strings”, 15: “Factors”\nVideo: Tidy Data and tidyr - NB! Start at 7:45 and please note: gather() is now pivot_longer() and spread() is now pivot_wider()\nVideo: Working with Two Datasets: Binds, Set Operations, and Joins\nVideo: stringr (Playlist with 7 short videos)"
  },
  {
    "objectID": "lab05.html#learning-objectives",
    "href": "lab05.html#learning-objectives",
    "title": "Lab 5: Data Wrangling II",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nA student who has met the objectives of the session will be able to:\n\nUnderstand and apply the various str_*() functions for string manipulation\nUnderstand and apply the family of *_join() functions for combining data sets\nUnderstand and apply pivot_wider() and pivot_longer()\nUse factors in conjugation with plotting categorical data using ggplot"
  },
  {
    "objectID": "lab06.html#packages",
    "href": "lab06.html#packages",
    "title": "Lab 6: (a bit on) Modelling in the Tidyverse",
    "section": "Package(s)",
    "text": "Package(s)\n\nbroom\npurrr\nvroom"
  },
  {
    "objectID": "lab06.html#schedule",
    "href": "lab06.html#schedule",
    "title": "Lab 6: (a bit on) Modelling in the Tidyverse",
    "section": "Schedule",
    "text": "Schedule\n\n08.00 - 08.10: Course midway evaluation\n08.10 - 08.30: Recap of exercises from last lab (Incl. assignment)\n08.30 - 09.00: Introduction to Lab\n09.00 - 09.15: Break\n09.00 - 12.00: Exercises, here is a walk-along-example"
  },
  {
    "objectID": "lab06.html#learning-materials",
    "href": "lab06.html#learning-materials",
    "title": "Lab 6: (a bit on) Modelling in the Tidyverse",
    "section": "Learning Materials",
    "text": "Learning Materials\nPlease prepare the following materials:\nBook: R4DS chapters 22 Introduction, 23 Model basics, 24 Model building, 25 Many models Video: Broom: Converting Statistical Models to Tidy Data Frames Video: Alex Hayes | Solving the model representation problem with broom | RStudio (2019) Video: “The Joy of Functional Programming (for Data Science)” with Hadley Wickham"
  },
  {
    "objectID": "lab06.html#learning-objectives",
    "href": "lab06.html#learning-objectives",
    "title": "Lab 6: (a bit on) Modelling in the Tidyverse",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nA student who has met the objectives of the session will be able to:\n\nUnderstand and apply simple purrr-functions for element-wise function application\nUnderstand and apply grouped supervised models to form nested model objects\nUnderstand and apply the broom-functions for tidying various model objects\nPerform a basic principal component analysis for dimension reduction of high dimensional data\nPerform a basic unsupervised k-means clustering of high dimensional data"
  },
  {
    "objectID": "lab07.html",
    "href": "lab07.html",
    "title": "Lab 7: Scripting in a Reproducible and Collaborative Framework using GitHub via RStudio",
    "section": "",
    "text": "Package(s)\n\nusethis\ngit (Actually not an R-package this time)"
  },
  {
    "objectID": "lab07.html#schedule",
    "href": "lab07.html#schedule",
    "title": "Lab 7: Scripting in a Reproducible and Collaborative Framework using GitHub via RStudio",
    "section": "Schedule",
    "text": "Schedule\n\n08.00 - 08.15: Recap of midway evaluation and exercises from last lab\n08.15 - 08.30: Assignment walk-through\n08.30 - 09.00: Introduction to Lab\n09.00 - 09.15: Break\n09.00 - 12.00: Exercises"
  },
  {
    "objectID": "lab07.html#learning-materials",
    "href": "lab07.html#learning-materials",
    "title": "Lab 7: Scripting in a Reproducible and Collaborative Framework using GitHub via RStudio",
    "section": "Learning Materials",
    "text": "Learning Materials\nPlease prepare the following materials\n\nBook: Happy Git and GitHub for the useR – Read chapters 1 (intro), 20 (basic terms), 22 (branching), 23 (remotes). Do not pay much attention to syntax of specific commands, because we are not going to use them during the exercises, focus on the idea.\nBook: Introduction to Data Science - Data Analysis and Prediction Algorithms with R by Rafael A. Irizarry: Chapter 40 Git and GitHub – Some of the information here is redundant with the previous book, but very important thing is a visualization of basic git actions and screenshots of how to perform them using RStudio.\nVideo: RStudio and Git - an Overview (Part 1) – Basic git concepts, for those who prefer listen rather than read. Books, however, contain more information.\nVideo: How to use Git and GitHub with R – Basic operating on git in RStudio. Complementary to second book. You can skip to 2:50, we are not going to link to git manually either way."
  },
  {
    "objectID": "lab07.html#learning-objectives",
    "href": "lab07.html#learning-objectives",
    "title": "Lab 7: Scripting in a Reproducible and Collaborative Framework using GitHub via RStudio",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nA student who has met the objectives of the session will be able to:\n\nExplain why reproducible data analysis is important\nIdentify associated relevant challenges\nExplain replicability versus reproducibility\nDescribe the components of a reproducible data analysis\nUse RStudio and GitHub (git) for collaborative bio data science projects"
  },
  {
    "objectID": "lab08.html#packages",
    "href": "lab08.html#packages",
    "title": "Lab 8: Creating a Simple R-package",
    "section": "Package(s)",
    "text": "Package(s)\n\ndevtools\nusethis\nroxygen2\ntestthat"
  },
  {
    "objectID": "lab08.html#schedule",
    "href": "lab08.html#schedule",
    "title": "Lab 8: Creating a Simple R-package",
    "section": "Schedule",
    "text": "Schedule\n\n08.00 - 08.15: Recap of exercises from last lab\n08.15 - 08.30: Assignment walk-through\n08.30 - 09.00: Introduction to Lab\n09.00 - 09.15: Break\n09.00 - 12.00: Exercises"
  },
  {
    "objectID": "lab08.html#learning-materials",
    "href": "lab08.html#learning-materials",
    "title": "Lab 8: Creating a Simple R-package",
    "section": "Learning Materials",
    "text": "Learning Materials\nPlease prepare the following materials:\n\nCheatsheet: Package development with devtools – When in doubt, check here first\nWeb: R Packages: A Beginner’s Tutorial – Read this before class\nWeb: Developing Packages with RStudio – Creating an R Package with RStudio\nWeb: R package primer a minimal tutorial – Brief but comprehensive R Package tutorial\nBook: R Packages - 1 Introduction – Everything you need to know about R Packages"
  },
  {
    "objectID": "lab08.html#learning-objectives",
    "href": "lab08.html#learning-objectives",
    "title": "Lab 8: Creating a Simple R-package",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nA student who has met the objectives of the session will be able to:\n\nPrepare a simple R package for distributing documented functions\nExplain the terms Repository, Dependencies, and Namespace\nImplement testing in an R package\nCollaboratively work on an R package on GitHub"
  },
  {
    "objectID": "lab09.html#packages",
    "href": "lab09.html#packages",
    "title": "Lab 9 Creating a Simple Shiny Application",
    "section": "Package(s)",
    "text": "Package(s)\n\nshiny\ngolem"
  },
  {
    "objectID": "lab09.html#schedule",
    "href": "lab09.html#schedule",
    "title": "Lab 9 Creating a Simple Shiny Application",
    "section": "Schedule",
    "text": "Schedule\n\n08.00 - 08.15: Recap of exercises from last lab\n08.15 - 08.30: Assignment walk-through\n08.30 - 09.00: Slides\n09.00 - 09.15: Break\n09.00 - 12.00: Exercises"
  },
  {
    "objectID": "lab09.html#learning-materials",
    "href": "lab09.html#learning-materials",
    "title": "Lab 9 Creating a Simple Shiny Application",
    "section": "Learning Materials",
    "text": "Learning Materials\nPlease prepare the following materials\n\nBook: Mastering Shiny by Hadley Wickham – Read Chapter 1 (Chapter 2 and 3 are good to read as well, if you want).\nBook: Engineering Production-Grade Shiny Apps – Read Chapter 2 - 5 (they are fairly short, but if you don’t find Shiny Apps super cool, feel free to skip Chapter 3 and 5 and Sections 2.2.2 and 4.2.3 - 4.2.4), the rest are quite important for the exercises.\nCheatsheet: Shiny – This cheatsheet is a bit cluttered, but useful\nCheatsheet: Golem – Look through this after reading the chapters in “Engineering Production-Grade Shiny Apps” - the exercises will remind you to look at the cheatsheet as well.\n\nNote: The following are suggested learning materials, i.e., do not go over everything, but poke around. You will use these materials as a point of reference for the group exercises\n\nShiny Input Gallery\nWeb: Shiny from RStudio\nWeb: RStudio tutorials on Shiny\nVideo: Playlist: Web Apps in R: Building your First Web Application in R | Shiny Tutorial\nExample: nnvizRt\nMore inspiration: Shiny Gallery"
  },
  {
    "objectID": "lab09.html#learning-objectives",
    "href": "lab09.html#learning-objectives",
    "title": "Lab 9 Creating a Simple Shiny Application",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nA student who has met the objectives of the session will be able to:\n\nPrepare a simple shiny application\nUsing relevant online ressources to autonomously identify and obtain new and expand on existing knowledge of R"
  },
  {
    "objectID": "lab10.html#schedule",
    "href": "lab10.html#schedule",
    "title": "Lab 10 Project Startup & Industry Talks",
    "section": "Schedule",
    "text": "Schedule\n\n08.00 - 08.15: Recap and Assignment\n08.15 - 08.45: Introduction to Project Period and Exam\n08.45 - 09.00: Break\n09.00 - 10.00: Mini Symposium (See below)"
  },
  {
    "objectID": "lab10.html#mini-symposium-applications-of-r-for-bio-data-science-in-industry",
    "href": "lab10.html#mini-symposium-applications-of-r-for-bio-data-science-in-industry",
    "title": "Lab 10 Project Startup & Industry Talks",
    "section": "Mini Symposium: Applications of R for Bio Data Science in Industry",
    "text": "Mini Symposium: Applications of R for Bio Data Science in Industry\nThis mini symposium on Applications of R for Bio Data Science in Industry aims to give students a glimpse into how modern data science is transforming value creation in the pharmaceutical industry and healthcare sector.\n\n2023\n\nCompanies Represented\n\nTBA\n\n\n\nSpeaker List\n\nTBA\n\n\n\n\n2022\n\nCompanies Represented\n\nAbzu\nBristol Myers Squibb\nClinical Microbiomics\nNovo Nordisk Bioinformatics\nNovo Nordisk Biostatistics\nSteno Diabetes Center Copenhagen\n\n\n\nSpeaker List\n\nAndrea Marquard, Head of Data Science and Automation, Clinical Microbiomics: “How we use internal R packages, and why you should learn to make one”\nAnders Gorst-Rasmussen, Statistical Director, Novo Nordisk Biostatistics, Novo Nordisk: “How we use R in Novo Nordisk Biostatistics”\nAnne-Mette Bjerregaard, Senior Scientist in Computational Biology, Novo Nordisk: “The Evolution of a Computational Biologist”\nSam Demharter, Bioinformatics Specialist, Abzu: “Explainable AI in Precision Medicine - Closing the Loop from Patient to Drug”\nLykke Pedersen, Head of RNA Therapeutics, Abzu: “Explainable AI in Precision Medicine - Closing the Loop from Patient to Drug”\nSimon Papillon-Cavanagh, Principal Scientist, Bristol Myers Squibb (USA): “A Career Built on Mistakes”\nSofie Olund Villumsen, Bioinformatician, Steno Diabetes Center Copenhagen: “Using R for Data Analysis in Clinical Studies”\nTarun Veer Singh Ahluwalia, Assoc. Prof., Steno Diabetes Center Copenhagen: “Using R for Data Analysis in Clinical Studies”\n\n\n\n\n2021\n\nCompanies Represented\n\nAbzu\nALK\nChr. Hansen\nLundbeck\nNovozymes\nTeraData\n\n\n\nSpeaker List\n\nSamuel Demharter, Senior Bioinformatician, Abzu\nLykke Pedersen, Senior Bioinformatician, Abzu\nMarie-Catherine Le Bihan, Senior Data Scientist, Chr. Hansen\nThomas Strantzl, Head of Bioinformatics, ALK\nMaria Dalby, Postdoctoral Researcher, Lundbeck\nThomas Poulsen, Science Manager, Novozymes\nMikkel Freltoft Krogsholm, Team lead, Senior Data Scientist, TeraData"
  },
  {
    "objectID": "project_faq.html",
    "href": "project_faq.html",
    "title": "Project FAQ",
    "section": "",
    "text": "Where can I find data? Rethink the question: Discuss in your group what are your interests and then find data related to your problem, there are literally terabytes of publicly available data, i.e. don’t just google “data”, be specific\nIn order for you to demonstrate that you master the entire bio data science cycle, you must choose a bio data set, which requires cleaning and tidying\nIt would be good, if the data set requires joining, if not, consider artificially splitting it, to demonstrate that you master joining\nOne approach could be to work on reproducing results from a paper. Here, you can even consider improving the data visualisations or adding something extra\nDo not use a data set from one of the course exercises. Doing so would not allow you to demonstrate that you are independently capable of performing a bio data science analysis\nYou are 100% free to choose bio data from any resource as long as it meets the above requirements\n\n\n\n\n\nDepends, does your data set come with a readme, which allows you to make a decision regarding NAs?\nBe careful not to simply drop all NAs as you might drop observations, where columns of interest have complete data\n\n\n\n\n\nIn case your variable contains categories, i.e. values, where the question “Is one larger than the other” is nonsensical, then encode as factors\n\n\n\n\n\nIf you believe the data points are nonsensical, e.g. manual typing errors, then exclude them, but be very clear about which data (groups of) points were excluded and why\n\n\n\n\n\nYes, if you are particularly interested in a subset of the data, then that is perfectly fine. Just be aware, that any choice you take with the data, you must be able to account for why you took that choice\nYou should NOT just sample 100 observations as was done in the exercises to reduce runtime. However, if your data set is large, consider down-sampling either randomly or by some metric of association. For the latter e.g. perform a test and identify the top X observations, save those to file and continue from there.\nFor large data, try appending “.gz” to your files, when you write them using write_tsv(), this will invoke gzip-compression"
  },
  {
    "objectID": "project_faq.html#inputoutput-files",
    "href": "project_faq.html#inputoutput-files",
    "title": "Project FAQ",
    "section": "Input/output files",
    "text": "Input/output files\n\nHow can we get a better overview of the data file flow?\n\nConsider creating a flow chart of “your data journey”. It will force you to think about how files are connected and how input/output flows\n\n\n\nHow can we write a file with e.g. factor encoding or a nested tibble?\n\nThis can only be done by writing an R-object. However, this is for future reference - in this course stick to flat text files, e.g. .tsv or .csv\n\n\n\nHow do we handle different naming conventions?\n\nDO NOT do a manual search and replace in Excel. That defeats the whole purpose of this course\nFix names using a programmatic approach. The stringr-package is extremely useful in this context\n\n\n\nWhere should we place external files?\n\nConsider creating an “images” folder in the “doc” folder, from where you can input images to your presentation"
  },
  {
    "objectID": "project_faq.html#modelling",
    "href": "project_faq.html#modelling",
    "title": "Project FAQ",
    "section": "Modelling",
    "text": "Modelling\n\nWhat should we include in the modelling part?\n\nWe have worked with fitting a logistic regression, we have done a PCA and we have performed clustering using k-means. You could do something along those lines or something of similar complexity\nThis is not a modelling course. We briefly visited modelling to bridge the process of going from the raw data to analysis ready and then communication via data visualisation. Therefore, do not start fitting a full fledged machine/deep learning model, it is a time-void, which you cannot “afford” to get sucked into\nAlso, mind that the focus of this course is to make you realise that even though you have been trained in delivering results, then the process of arriving at the results in a reproducible manner is equally important\n\n\n\nDo we HAVE to do a PCA?\n\nDoes it make sense to do a PCA-analysis in your project? If you have group labels and you want to visualise to see if there is a separation, then a PCA is a good first step\n\n\n\nOur model is not performing very well. What should we do?\n\nLeave it as is. The focus of this course is not on the results, but on the reproducible process of arriving and communicating said results"
  },
  {
    "objectID": "project_faq.html#coding",
    "href": "project_faq.html#coding",
    "title": "Project FAQ",
    "section": "Coding",
    "text": "Coding\n\nWhat goes in the “augment” script?\n\nIf you google “Augment“, you will get “make (something) greater by adding to it; increase”, in other words, when you add e.g. variables to your data, which was not there initially, e.g. like we did, when we calculated the BMI from existing information on weight and height\nYou should think of the augment script as the place, where you create your database for everything that happens afterwards, i.e. all your analyses and ideas\nCreate that “database” and then load it into your downstream scripts\nAugment == Adding something\n\n\n\nCan we mix base R and tidyverse?\n\nNo, you might as well get used to it - Tidyverse all the way! (This is a tidyverse course)\n\n\n\nWhat if we can’t make it work in tidyverse but only in base R?\n\nIf you can make it work in base R, you can make it work in tidyverse\n\n\n\nIs it okay to use e.g. the base function sum()?\n\nYes, think of it this way: R has as core functionality to do statistics. Tidyverse is for performing the data manipulation surrounding these calculations. Therefore, using functions such as sum(), mean(), sd(), etc. is naturally fine\n\n\n\nHow do we know if there is a tidyverse function we should use rather than base?\n\nIdentify the general area of what you’re working with. E.g. if strings, then go to your RStudio session and find the console and type “stringr::” and hit tab, then you can look through the functions\nLook in the R-for-Data-Science book https://r4ds.had.co.nz\nAsk on the community pages https://community.rstudio.com\n\n\n\nCan we use package X for analysis/visualisation?\n\nIf the package performs a lot of the work, which you are to demonstrate that you can do, then no. Do not use packages, where you call a plot-my-data-function and the ggplot-magick happens that will not allow you to demonstrate that you have met the course learning objectives\n\n\n\nHow do we run the entire project incl. the presentation?\n\nMake sure to include a programmatic call to knitr at the end of your doit-script\n\n\n\nShould we create a Shiny app?\n\nThe project deliverables are the GitHub repo and your presentation. Remember, you do this project not for me as a teacher, but for you to internalize the knowledge you have been exposed to during the initial 10 weeks of teaching. If you find Shiny interesting/fun, then by all means, please do create an app. Shiny apps are optional\n\n\n\nShould we create a package?\n\nOptional, if you do, be careful with your time usage. You should focus on the data science cycle\n\n\n\nWhen should we create functions?\n\nRemember DRY (Dont-Repeat-Yourself), so generally, if you do something more than once, it is a function. However, we do not focus much on functions in this course, so don’t put too much effort into creating functions\nPlace functions in 99_proj_functions.R as illustrated in the overview\nDO NOT hide your code away in functions, so that your main script just becomes 10 function calls. For this process-oriented course, show the code in your main scripts, i.e. 01_, 02_, …\n\n\n\nCan we use loops?\n\nNo, you should instead embrace functional programming and use functions from the “purrr”-package. Revisit lab 6, if needed\n\n\n\nCan we directly copy/paste a code chunk from an online source?\n\nNo, that would be plagiarism. Understand the steps in the chunk and make the code your own\nI acknowledge that for coding this is not completely black and white, but please refrain from a direct copy/paste Coding style\n\n\n\nHow should we comment on our code?\n\nRemember, the point of writing verbose tidyverse code is that the code-becomes-the-comments. Think of it this way: The pipeline is the text on a page in a book, so before your pipeline, put a header/title on what is happening below, just as a title/header in a book\nThe title/header will be what is generally going on, e.g. “Normalise all gene expression values using standard score approach” and the pipeline will be how that is actually done\nThe pipe “%>%” is pronounced as “then”, when you “read” your code\n\n\n\nHow should we style our code?\n\nUse the tidyverse style guide as introduced in the course: https://style.tidyverse.org/index.html\nMake sure that all scripts are styled the same way and be consistent in your coding style\nYour code should not be >80 chars wide, follow the vertical line in your editor\n\n\n\nHow should we style our plots?\n\nBe concise, “less is more”\nMake some nice and relevant plots. Show us that you’ve learned data visualisation. Remember legends, titles etc.\nDo not put 3 messages in 1 plot. Instead put each message into a different plot\nBe careful with matching the text size in your plots to that of your presentation (trial-and-error)"
  },
  {
    "objectID": "project_faq.html#github",
    "href": "project_faq.html#github",
    "title": "Project FAQ",
    "section": "GitHub",
    "text": "GitHub\n\nShould our GitHub be public or private?\n\nThat is completely up to you. As students, you “own” anything you create while studying. The teaching staff must however have complete access.\n\n\n\nShould we keep all the data on GitHub?\n\nYes, for this course. However, be aware that GitHub is meant for code, not data.\n\n\n\nWhat goes in the “doc” folder?\n\nThe project organisation chart is a generic figure. You should not hand in a report. Your deliverable/product outcome for the project period is: 1) Your GitHub repository and 2) A presentation. Therefore, the “doc” folder would in this case contain your presentation\n\n\n\nWhy are there multiple “reports” in the “doc” folder?\n\nIn case you have a computationally intensive part of the project it can be an advantage to split into sub-reports and then collect in a master report (think large LaTeX reports)\nOverview, even if your report is not computationally intensive, then it may be long and splitting into sub-reports facilitate better overview\n\n\n\nShould we include a README on GitHub?\n\nThat would be a good way to briefly introduce what the contents of this repo is and something one would usually do\n\n\n\nShould everything be on Github, also plots we don’t present?\n\nYes, everything!"
  },
  {
    "objectID": "project_faq.html#examhand-in-deliverables",
    "href": "project_faq.html#examhand-in-deliverables",
    "title": "Project FAQ",
    "section": "Exam/hand-in deliverables",
    "text": "Exam/hand-in deliverables\n\nWhat is the final product?\n\nA GitHub repository organised according to principles of reproducible data analysis\nA ioslides/rmarkdown HTML-presentation following the IMRAD structure as elaborated in the project introduction slides (see lab 10)\nThis final presentation in HTML-format should be uploaded to DTU Learn\n\n\n\nDo we need to hand in a report?\n\nNo, no report is required!"
  },
  {
    "objectID": "project_faq.html#presentation",
    "href": "project_faq.html#presentation",
    "title": "Project FAQ",
    "section": "Presentation",
    "text": "Presentation\n\nShould we include code in our presentation?\n\nYour presentation should follow the standard scientific IMRAD-structure, i.e. introduction, materials-and-methods, results, and discussion.\nInclude certain decisions you took with the data and your reasoning herfore.\nIf you found a particular challenging problem in coding, to which you found an elegant solution, include that in your presentation as an example\nThe presentation is your chance to practice communicating insights to stakeholders\nYour audience will be same-level bioinformaticians\nPerhaps consider a graphical representation of your process going from raw to analysis-ready data\n\n\n\nShould we include tables or plots?\n\nWhat makes sense? If you only have two numerical values, then perhaps a table is fine. If you have 100 observations, then a plot is likely better\nRemember, we are as humans evolutionary encoded to interpret visual information, not numbers\n\n\n\nHow do we add plots to the rmarkdown presentation?\n\nOutput the plot as a png file using the function ggsave and include that png in your presentation. Think dynamically, we don’t want to type anything manually in our presentation\n\n\n\nHow do we get the presentation in wide-/full screen?\n\nHit w and f while the HTML presentation is loaded\n\n\n\nShould we split our presentation into sub-presentations?\n\nNo, this is not necessary given the extend/size of this project. Just create one Rmd file, which outputs an HTML-presentation\n\n\n\nWe are working on re-creating paper results. Should we re-create the exact same plots?\n\nIdeally, you re-create the plots and then you create your own improved version of the visualisation.\n\n\n\nWhere should we “place” our Shiny app in our presentation?\n\nDemo it briefly at the end\n\n\n\nHow can we illustrate our data handling?\n\nConsider creating a flow chart, what are input files and how are they connected to final output?\n\n\n\nHow much code should we include in the presentation?\n\nThe exam deliverables are two-fold. Code is the GitHub repo and your ability to communicate biological insights is in the presentation. Therefore, code could be included in the presentation if you faced and solved a particularly challenging problem\n\n\n\nHow do we include data numbers in the presentation?\n\nYou could from your script output a results table with relevant numbers as a .tsv file and then read that into the presentation and extract the numbers\nRemember, think dynamical reporting, what if your input data changes and you manually entered the numbers in your presentation? Then you wouldn’t be much farther than a powerpoint\n\n\n\nWhat goes into the materials and methods section?\n\nMaterials: What data did you use and where did you get it from?\nMethods: Which modelling did you use? Think of the methods section as a recipe for how to go from raw to results => Flow chart?\n\n\n\nShould we interpret our results?\n\nYes, you have to think about it as a “normal” project presentation\n\n\n\nWhat about all the stuff we tried, which did not work?\n\nIn the presentation, you should focus on what worked and what results you arrived at\nExclude dead-ends from the presentation, but… Leave them in the repo, perhaps with an initial comment signifying that the following turned out to be a dead-end\nThink about this - Scenario: You’re working in a company and you and your team of 3 spend 6 months on a project, which turns out to be a dead-end. For future reference: Would the company be interested in knowing that this project was a dead end or should you delete everything and never speak of it again?"
  },
  {
    "objectID": "project_faq.html#project-check-up-and-summary",
    "href": "project_faq.html#project-check-up-and-summary",
    "title": "Project FAQ",
    "section": "Project Check Up and Summary",
    "text": "Project Check Up and Summary\n\nIMPORTANT: Ask yourselves:\n\n\n“Does our presentation follow the IMRAD structure?”\n\nIs the presentation created as one ioslides Rmd file and output to a HTML?\nIs the presentation clear and concise?\nAre we doing good data communication via good visualisations?\nDo we present a clear overview of the data process incl. any decisions made, e.g. using a flow chart?\nAre we clearly communicating a biological insight?\nAre we following std guidelines? Sources, references, etc.\n\n\n\n\n\n\n\n\n“Does our project include all components of the data science cycle?”\n\n\n\n\n\n\n\n“Are we aware of and have included learning objectives as appropriate in the project?”\n\n\n\n\n\n\n\n“Is our project-GitHub organised as instructed and can it run end-to-end via doit?”\n(Note, this is a generic representation, your doc folder will contain your presentation)\n\n\n\n\n\n\n\n“Does our code in all our scripts follow the Tidyverse style guide?”\n\nRecall what we discussed in the course on styling\nAlso, see: https://style.tidyverse.org/index.html\nE.g.:\n\n\n\n\n\n\n\n\n“Are we using base-R, where we should use tidyverse-R?”\n\nE.g. think about the following:\n\n\n\n\n\n\n\n\n“Can we explain and justify the data decisions in the project?”\n\nIMPORTANT: In essence it does not matter which decision you took, what matters is your ability to explain and justify why you decided on that particular path in your analysis"
  },
  {
    "objectID": "exam.html",
    "href": "exam.html",
    "title": "Exam",
    "section": "",
    "text": "Please make sure to read the description of the exam and exam times on the course base."
  },
  {
    "objectID": "exam.html#design",
    "href": "exam.html#design",
    "title": "Exam",
    "section": "Design",
    "text": "Design\nThe exam consists of 3 components:\n\nA group project, where all members are responsible for all parts of the project. This is handed in as a code base on GitHub\nAn oral group presentation of the project\n2 hour MCQ exam, where general course learning objectives are examined\n\nPlease note that active participation in the group work and timely submission of project and code base are both indispensable prerequisites for exam participation. The final grade is based on an overall assessment of all three components.\n\nThe Group Project\n\nBe sure that everyone understands ALL code in the project as all group members are responsible for ALL code\nThe point of the project is to cover more or less the entire course cycle, so if you have decided to leave out some parts, then you are also expected to be able to answer questions relating to these\nExpect a few overall questions regarding the decisions you have made throughout your project\n\n\n\nThe Presentation\n\nThe format is a 10-slides-in-10-mins and everyone in the group must present a part\nThe group presentations will be on the last day of the course, i.e. lab 13\n\n\n\nThe MCQ\n\nA 2-hour individual multiple choice exam\nIn 2022 the exam contained 60 questions, expect a similar number of questions\nAll aids are allowed, but no open internet\nEach question will have 4 possible answers and only 1 is the right one and you can only choose one answer per question"
  }
]